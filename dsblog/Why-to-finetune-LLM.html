<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My various blogs on Datascience, Management, Software Engineering, Philosophy, Vedanta, Sanskrit, Current Affair, History. "><meta name=author content="Hari Thapliyaal"><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Why-to-finetune-LLM.html><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.11"><title>Why to Finetune LLM? - DasarpAI</title><link rel=stylesheet href=../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","{{ config.extra.GOOGLE_ANALYTICS }}"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","{{ config.extra.GOOGLE_ANALYTICS }}",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id={{ config.extra.GOOGLE_ANALYTICS }}",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta name=author content="Hari Thapliyaal"><meta name=description content="Learn why and how to fine-tune Large Language Models. Understand the benefits, techniques, and best practices for customizing AI models to specific use cases and requirements."><meta name=keywords content="LLM Fine-tuning, Model Training, AI Model Customization, Transfer Learning, Language Model Adaptation, Few-Shot Learning, Model Optimization, AI Training"><meta property=og:type content=article><meta property=og:locale content=en_US><meta property=og:site_name content=DasarpAI><meta property=og:title content="Why to Finetune LLM?"><meta property=og:description content="Learn why and how to fine-tune Large Language Models. Understand the benefits, techniques, and best practices for customizing AI models to specific use cases and requirements."><meta property=og:url content=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Why-to-finetune-LLM.html><meta property=og:image content=../../assets/images/dspost/dsp6115-why-to-finetune-llm.jpg><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=@dasarpai><meta name=twitter:title content="Why to Finetune LLM?"><meta name=twitter:description content="Learn why and how to fine-tune Large Language Models. Understand the benefits, techniques, and best practices for customizing AI models to specific use cases and requirements."><meta name=twitter:image content=../../assets/images/dspost/dsp6115-why-to-finetune-llm.jpg><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Why-to-finetune-LLM.html><link rel=stylesheet href=../assets/stylesheets/custom.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#finetuning-fewshot-learning-why-and-how class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@harithapliyal</strong> on <a rel=me href=https://linkedin.com/in/harithapliyal> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </span> <strong>Fosstodon</strong> </a> and <a href=https://x.com/dasarpai> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=DasarpAI class="md-header__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DasarpAI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Why to Finetune LLM? </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=index.html class=md-tabs__link> Data Science </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/pmlogy-home.html class=md-tabs__link> Project Management </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/wia-home.html class=md-tabs__link> SpiritualDrops </a> </li> <li class=md-tabs__item> <a href=../samskrutyatra/index.html class=md-tabs__link> Samskrut </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=DasarpAI class="md-nav__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> DasarpAI </label> <div class=md-nav__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../index.html class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/aboutme.html class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> <li class=md-nav__item> <a href=../dscourses/index.html class=md-nav__link> <span class=md-ellipsis> DS/AI Courses/Services </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Project/Work Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Project/Work Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/project-index-page.html class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-al-ml-projects.md class=md-nav__link> <span class=md-ellipsis> Business Domain </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-my-technology-stacks.md class=md-nav__link> <span class=md-ellipsis> Technology Stack </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-management-projects.md class=md-nav__link> <span class=md-ellipsis> Project Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../management/index.html class=md-nav__link> <span class=md-ellipsis> PM Courses/Services </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/clients.html class=md-nav__link> <span class=md-ellipsis> Clients </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/testimonials.md class=md-nav__link> <span class=md-ellipsis> Testimonial </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/publications-home.html class=md-nav__link> <span class=md-ellipsis> Publications </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/corpus-home.html class=md-nav__link> <span class=md-ellipsis> History Corpus </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=index.html class="md-nav__link "> <span class=md-ellipsis> Data Science </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Data Science </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dsresources/index.html class=md-nav__link> <span class=md-ellipsis> DS Resources </span> </a> </li> <li class=md-nav__item> <a href=../news/index.html class=md-nav__link> <span class=md-ellipsis> AI and Business News </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-books.md class=md-nav__link> <span class=md-ellipsis> Data Science-Books </span> </a> </li> <li class=md-nav__item> <a href=data-science-cheatsheets.md class=md-nav__link> <span class=md-ellipsis> Data Science Cheatsheets </span> </a> </li> <li class=md-nav__item> <a href=best-youtube-channels-for-ds.md class=md-nav__link> <span class=md-ellipsis> Video Channels to Learn DS </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-interview-resources.md class=md-nav__link> <span class=md-ellipsis> DS Interview Questions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../pmblog/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Project Management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-home.html class=md-nav__link> <span class=md-ellipsis> PMLOGY Home </span> </a> </li> <li class=md-nav__item> <a href=../pmglossary.md class=md-nav__link> <span class=md-ellipsis> PM Glossary </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-tags.md class=md-nav__link> <span class=md-ellipsis> PM Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-tags.md class=md-nav__link> <span class=md-ellipsis> PMBOK6 Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-summary.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 </span> </a> </li> <li class=md-nav__item> <a href=../pmbok6/index.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Explorer </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> PM Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> PM Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmi-templates.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Templates </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/prince2-templates.html class=md-nav__link> <span class=md-ellipsis> PRINCE2 Templates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../pmbok6hi/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management Hindi </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Project Management Hindi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmbok6hi-summary.html class=md-nav__link> <span class=md-ellipsis> PMBoK6 Hindi </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../wiaposts/index.html class="md-nav__link "> <span class=md-ellipsis> SpiritualDrops </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> SpiritualDrops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/wia-home.html class=md-nav__link> <span class=md-ellipsis> WIA Home </span> </a> </li> <li class=md-nav__item> <a href=../quotations/index.html class=md-nav__link> <span class=md-ellipsis> WIA Quotes </span> </a> </li> <li class=md-nav__item> <a href=../gk/index.html class=md-nav__link> <span class=md-ellipsis> GK Blog </span> </a> </li> <li class=md-nav__item> <a href=../booksummary/index.html class=md-nav__link> <span class=md-ellipsis> Book Summary </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../samskrutyatra/index.html class="md-nav__link "> <span class=md-ellipsis> Samskrut </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Samskrut </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/samskrut-home.html class=md-nav__link> <span class=md-ellipsis> SamskrutYatra Home </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#why-to-finetune-a-llm class=md-nav__link> <span class=md-ellipsis> Why to finetune a LLM? </span> </a> </li> <li class=md-nav__item> <a href=#what-is-fewshot-learning class=md-nav__link> <span class=md-ellipsis> What is fewshot learning? </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-meaning-of-this-1-shot-3-shot-5-shot-7-shot-learing class=md-nav__link> <span class=md-ellipsis> What is the meaning of this 1-shot, 3-shot, 5-shot, 7-shot learing? </span> </a> <nav class=md-nav aria-label="What is the meaning of this 1-shot, 3-shot, 5-shot, 7-shot learing?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-use-few-shot-learning class=md-nav__link> <span class=md-ellipsis> Why Use Few-Shot Learning? </span> </a> </li> <li class=md-nav__item> <a href=#examples-in-context class=md-nav__link> <span class=md-ellipsis> Examples in Context </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#what-happens-in-the-model-during-few-shot-learning class=md-nav__link> <span class=md-ellipsis> What happens in the model during few shot learning? </span> </a> <nav class=md-nav aria-label="What happens in the model during few shot learning?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#contextual-understanding class=md-nav__link> <span class=md-ellipsis> Contextual Understanding </span> </a> </li> <li class=md-nav__item> <a href=#example-processing class=md-nav__link> <span class=md-ellipsis> Example Processing </span> </a> </li> <li class=md-nav__item> <a href=#generalization class=md-nav__link> <span class=md-ellipsis> Generalization </span> </a> </li> <li class=md-nav__item> <a href=#application class=md-nav__link> <span class=md-ellipsis> Application </span> </a> </li> <li class=md-nav__item> <a href=#example-workflow class=md-nav__link> <span class=md-ellipsis> Example Workflow </span> </a> <nav class=md-nav aria-label="Example Workflow"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#few-shot-prompt class=md-nav__link> <span class=md-ellipsis> Few-Shot Prompt </span> </a> </li> <li class=md-nav__item> <a href=#model-process class=md-nav__link> <span class=md-ellipsis> Model Process </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#key-points class=md-nav__link> <span class=md-ellipsis> Key Points </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#fewshot-learning-with-prompt-engineering-and-finetuing-with-machine-learning class=md-nav__link> <span class=md-ellipsis> Fewshot learning with prompt engineering and finetuing with machine learning. </span> </a> <nav class=md-nav aria-label="Fewshot learning with prompt engineering and finetuing with machine learning."> <ul class=md-nav__list> <li class=md-nav__item> <a href=#few-shot-learning class=md-nav__link> <span class=md-ellipsis> Few-Shot Learning </span> </a> </li> <li class=md-nav__item> <a href=#fine-tuning class=md-nav__link> <span class=md-ellipsis> Fine-Tuning </span> </a> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#after-we-finetune-chatgpt35-model-can-we-download-the-finetued-model class=md-nav__link> <span class=md-ellipsis> After we finetune chatgpt3.5 model can we download the finetued model? </span> </a> <nav class=md-nav aria-label="After we finetune chatgpt3.5 model can we download the finetued model?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-custom-gpts class=md-nav__link> <span class=md-ellipsis> 1. Custom GPTs </span> </a> </li> <li class=md-nav__item> <a href=#2-few-shot-learning class=md-nav__link> <span class=md-ellipsis> 2. Few-Shot Learning </span> </a> </li> <li class=md-nav__item> <a href=#3-combination-of-methods class=md-nav__link> <span class=md-ellipsis> 3. Combination of Methods </span> </a> </li> <li class=md-nav__item> <a href=#examples-of-custom-gpt-creation class=md-nav__link> <span class=md-ellipsis> Examples of Custom GPT Creation </span> </a> </li> <li class=md-nav__item> <a href=#summary_1 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#can-we-finetune-gpt35-gpt40-or-gemini-model class=md-nav__link> <span class=md-ellipsis> Can we finetune GPT3.5, GPT4.0 or Gemini Model? </span> </a> <nav class=md-nav aria-label="Can we finetune GPT3.5, GPT4.0 or Gemini Model?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#fine-tuning-gpt-35 class=md-nav__link> <span class=md-ellipsis> Fine-Tuning GPT-3.5 </span> </a> </li> <li class=md-nav__item> <a href=#fine-tuning-gpt-40 class=md-nav__link> <span class=md-ellipsis> Fine-Tuning GPT-4.0 </span> </a> </li> <li class=md-nav__item> <a href=#fine-tuning-gemini-models class=md-nav__link> <span class=md-ellipsis> Fine-Tuning Gemini Models </span> </a> </li> <li class=md-nav__item> <a href=#summary_2 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> <li class=md-nav__item> <a href=#alternative-approaches class=md-nav__link> <span class=md-ellipsis> Alternative Approaches </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#after-we-finetune-chatgpt35-model-can-we-download-the-finetued-model_1 class=md-nav__link> <span class=md-ellipsis> After we finetune chatgpt3.5 model can we download the finetued model? </span> </a> <nav class=md-nav aria-label="After we finetune chatgpt3.5 model can we download the finetued model?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#fine-tuning-and-model-access class=md-nav__link> <span class=md-ellipsis> Fine-Tuning and Model Access </span> </a> </li> <li class=md-nav__item> <a href=#alternative-approaches_1 class=md-nav__link> <span class=md-ellipsis> Alternative Approaches </span> </a> </li> <li class=md-nav__item> <a href=#summary_3 class=md-nav__link> <span class=md-ellipsis> Summary </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <article class="md-content__inner md-typeset"> <p><img alt="Why to Finetune LLM?" src=../assets/images/dspost/dsp6115-why-to-finetune-llm.jpg></p> <h1 id=finetuning-fewshot-learning-why-and-how>Finetuning, Fewshot Learning, Why and How?<a class=headerlink href=#finetuning-fewshot-learning-why-and-how title="Permanent link">&para;</a></h1> <h2 id=why-to-finetune-a-llm>Why to finetune a LLM?<a class=headerlink href=#why-to-finetune-a-llm title="Permanent link">&para;</a></h2> <p>Fine-tuning a large language model (LLM) can provide several benefits, depending on your specific needs and objectives. Here are some key reasons to consider fine-tuning an LLM:</p> <ol> <li><strong>Domain Specialization</strong>:</li> <li> <p>Fine-tuning allows the model to become more proficient in specific domains, such as medical, legal, or technical fields, by training it on domain-specific data.</p> </li> <li> <p><strong>Task Adaptation</strong>:</p> </li> <li> <p>Customize the model to perform better on particular tasks such as sentiment analysis, summarization, question-answering, translation, or other NLP tasks that require specialized knowledge.</p> </li> <li> <p><strong>Improved Performance</strong>:</p> </li> <li> <p>Enhance the model's performance by fine-tuning it on high-quality, relevant data, reducing errors and increasing accuracy for specific applications.</p> </li> <li> <p><strong>Personalization</strong>:</p> </li> <li> <p>Adapt the model to align with specific user preferences, company guidelines, or industry standards, providing more personalized responses and outputs.</p> </li> <li> <p><strong>Cost Efficiency</strong>:</p> </li> <li>Fine-tuning can be more cost-effective than training a new model from scratch, especially when computational resources are limited.</li> <li> <p>Entering long context and instruction everytime in the prompt is costly because you are paying for input tokens.</p> </li> <li> <p><strong>Language and Cultural Adaptation</strong>:</p> </li> <li> <p>Tailor the model to better understand and generate text in specific languages, dialects, or cultural contexts, improving its relevance and usability for particular user bases.</p> </li> <li> <p><strong>Handling Biases</strong>:</p> </li> <li> <p>Address and mitigate biases present in the base model by fine-tuning it on balanced and representative datasets, promoting fairness and inclusivity in its outputs.</p> </li> <li> <p><strong>Updating Knowledge</strong>:</p> </li> <li> <p>Incorporate the latest information and data, ensuring the model remains up-to-date with recent developments, trends, and knowledge.</p> </li> <li> <p><strong>Regulatory Compliance</strong>:</p> </li> <li> <p>Ensure that the model complies with specific regulatory or legal requirements by fine-tuning it on compliant datasets and guidelines.</p> </li> <li> <p><strong>Enhanced Security and Privacy</strong>:</p> <ul> <li>Fine-tune the model on proprietary or sensitive datasets in a secure environment to maintain data privacy and security.</li> </ul> </li> <li> <p><strong>Brand Voice and Style</strong>:</p> <ul> <li>Adapt the model to reflect a specific brand's voice, tone, and style, ensuring consistency in communication and content generation.</li> </ul> </li> </ol> <p>Fine-tuning an LLM involves training the pre-trained model on a new dataset specific to your needs while adjusting its weights to improve performance on the target tasks. This process leverages the vast knowledge the model has already acquired, enhancing it with specific information and capabilities relevant to your use case.</p> <h2 id=what-is-fewshot-learning>What is fewshot learning?<a class=headerlink href=#what-is-fewshot-learning title="Permanent link">&para;</a></h2> <p>Assume I have a task where I want large langue model to convert words of different languages or different script into english 1,2,3 etc. For that I am using gpt4.0 with 20 shots. After this whatever number I give to the model it is able to translate correctly. This is a good example of few-shot learning. No weight is adjusted during the fewshot learning.</p> <h2 id=what-is-the-meaning-of-this-1-shot-3-shot-5-shot-7-shot-learing>What is the meaning of this 1-shot, 3-shot, 5-shot, 7-shot learing?<a class=headerlink href=#what-is-the-meaning-of-this-1-shot-3-shot-5-shot-7-shot-learing title="Permanent link">&para;</a></h2> <p>The terms "1-shot", "3-shot", "5-shot", "7-shot", etc., refer to the number of examples provided to the model during the evaluation phase of few-shot learning. Few-shot learning is a technique where a model is given a small number of examples to understand the task before being evaluated. Here's a brief explanation of each term:</p> <ul> <li> <p><strong>1-shot Learning</strong>: The model is given one example of the task to learn from before being tested. This helps in assessing how well the model can generalize from a single instance.</p> </li> <li> <p><strong>3-shot Learning</strong>: The model is provided with three examples to learn from before the evaluation. This gives a bit more context than 1-shot but still requires strong generalization capabilities.</p> </li> <li> <p><strong>5-shot Learning</strong>: The model is given five examples to understand the task before being tested. This allows the model to see a variety of instances to better understand the task requirements.</p> </li> <li> <p><strong>7-shot Learning</strong>: The model learns from seven examples before being evaluated. This provides more context and helps the model to generalize better than lower-shot scenarios.</p> </li> <li> <p><strong>25-shot Learning</strong>: The model is provided with twenty-five examples to learn from. This is typically used in more complex tasks where more examples are needed to grasp the nuances.</p> </li> </ul> <h3 id=why-use-few-shot-learning>Why Use Few-Shot Learning?<a class=headerlink href=#why-use-few-shot-learning title="Permanent link">&para;</a></h3> <p>Few-shot learning is valuable because it assesses a model's ability to generalize from a small number of examples. This mimics real-world scenarios where large labeled datasets may not be available. It helps in understanding the model's capability to adapt to new tasks with minimal guidance, which is crucial for versatile AI systems. </p> <h3 id=examples-in-context>Examples in Context<a class=headerlink href=#examples-in-context title="Permanent link">&para;</a></h3> <ul> <li><strong>MMLU (5-shot)</strong>: The model is shown five examples of each academic subject before being tested.</li> <li><strong>AGIEval English (3-5 shot)</strong>: The model learns from three to five examples for each English proficiency task.</li> <li><strong>CommonSenseQA (7-shot)</strong>: Seven examples are given to the model to teach common sense reasoning before evaluation.</li> <li><strong>Winogrande (5-shot)</strong>: The model receives five examples to resolve sentence ambiguities before being tested.</li> <li><strong>BIG-Bench Hard (3-shot, CoT)</strong>: The model is provided with three examples for each challenging task, using chain-of-thought prompting.</li> </ul> <p>This approach helps to benchmark how well language models can adapt to new tasks with limited information.</p> <h2 id=what-happens-in-the-model-during-few-shot-learning>What happens in the model during few shot learning?<a class=headerlink href=#what-happens-in-the-model-during-few-shot-learning title="Permanent link">&para;</a></h2> <p>During few-shot learning, a pre-trained model uses a small number of examples provided as part of the prompt to understand how to perform a specific task. Here’s a detailed breakdown of what happens in the model during this process:</p> <h3 id=contextual-understanding>Contextual Understanding<a class=headerlink href=#contextual-understanding title="Permanent link">&para;</a></h3> <ol> <li> <p><strong>Pre-Trained Knowledge</strong>: The model, having been pre-trained on a large corpus of data, already possesses a vast amount of general knowledge about language, facts, and various tasks. This foundational knowledge is crucial for few-shot learning.</p> </li> <li> <p><strong>Task Presentation</strong>: When the model is presented with a few-shot task, it receives a prompt that includes a few examples (shots) of input-output pairs. These examples are intended to illustrate the task the model is expected to perform.</p> </li> </ol> <h3 id=example-processing>Example Processing<a class=headerlink href=#example-processing title="Permanent link">&para;</a></h3> <ol> <li> <p><strong>Pattern Recognition</strong>: The model analyzes the provided examples to recognize patterns and relationships between inputs and outputs. For instance, in a question-answering task, it observes how questions are structured and how answers are formulated.</p> </li> <li> <p><strong>Contextual Embedding</strong>: The model generates embeddings (dense vector representations) for the inputs and outputs in the examples. These embeddings capture the semantic information and context of the examples, helping the model understand the task.</p> </li> </ol> <h3 id=generalization>Generalization<a class=headerlink href=#generalization title="Permanent link">&para;</a></h3> <ol> <li><strong>Inference</strong>: Using its pre-trained knowledge and the patterns identified from the few examples, the model generalizes to infer the rules or the method required to perform the task. This step relies heavily on the model’s ability to generalize from limited data.</li> </ol> <h3 id=application>Application<a class=headerlink href=#application title="Permanent link">&para;</a></h3> <ol> <li><strong>Prediction</strong>: Once the model has inferred the task’s rules, it applies this understanding to make predictions on new, unseen inputs. It uses the context from the examples to guide its responses.</li> </ol> <h3 id=example-workflow>Example Workflow<a class=headerlink href=#example-workflow title="Permanent link">&para;</a></h3> <p>Let’s consider a few-shot learning task where the model is required to perform sentiment analysis:</p> <h4 id=few-shot-prompt>Few-Shot Prompt<a class=headerlink href=#few-shot-prompt title="Permanent link">&para;</a></h4> <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>Example 1:
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>Input: &quot;The movie was fantastic and very entertaining.&quot;
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>Output: &quot;Positive&quot;
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>Example 2:
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>Input: &quot;I did not enjoy the film; it was too long and boring.&quot;
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>Output: &quot;Negative&quot;
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>Example 3:
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>Input: &quot;The acting was mediocre, but the plot was interesting.&quot;
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>Output: &quot;Neutral&quot;
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>New Input: &quot;The visuals were stunning, but the story lacked depth.&quot;
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>Output:
</span></code></pre></div> <h4 id=model-process>Model Process<a class=headerlink href=#model-process title="Permanent link">&para;</a></h4> <ol> <li> <p><strong>Analyze Examples</strong>: The model reads the examples and identifies that they are instances of sentiment analysis, where the task is to determine whether the sentiment expressed in each sentence is positive, negative, or neutral.</p> </li> <li> <p><strong>Generate Embeddings</strong>: It creates embeddings for the inputs and outputs of the examples, capturing the semantic information and sentiment expressed in each sentence.</p> </li> <li> <p><strong>Infer Rules</strong>: The model uses the examples to infer that it needs to classify the sentiment of the new input sentence based on the patterns it recognized (e.g., words like "fantastic" indicate positive sentiment, while "boring" indicates negative sentiment).</p> </li> <li> <p><strong>Predict Output</strong>: The model applies its understanding to the new input ("The visuals were stunning, but the story lacked depth.") and predicts the output based on the context and rules inferred from the examples. In this case, it might predict "Neutral" or "Mixed" sentiment.</p> </li> </ol> <h3 id=key-points>Key Points<a class=headerlink href=#key-points title="Permanent link">&para;</a></h3> <ul> <li><strong>No Fine-Tuning</strong>: During few-shot learning, the model's weights are not updated. Instead, it leverages its pre-trained knowledge and the few provided examples to make predictions.</li> <li><strong>Flexibility</strong>: Few-shot learning showcases the model’s flexibility and adaptability to new tasks with minimal data.</li> <li><strong>Efficiency</strong>: It is an efficient way to evaluate and utilize large language models without requiring extensive additional training data.</li> </ul> <p>In essence, few-shot learning allows a model to quickly adapt to new tasks by understanding and generalizing from a few examples, leveraging its pre-trained knowledge and powerful pattern recognition capabilities.</p> <h2 id=fewshot-learning-with-prompt-engineering-and-finetuing-with-machine-learning>Fewshot learning with prompt engineering and finetuing with machine learning.<a class=headerlink href=#fewshot-learning-with-prompt-engineering-and-finetuing-with-machine-learning title="Permanent link">&para;</a></h2> <h3 id=few-shot-learning>Few-Shot Learning<a class=headerlink href=#few-shot-learning title="Permanent link">&para;</a></h3> <p><strong>Definition</strong>: Few-shot learning involves providing a pre-trained model with a few examples (shots) of a task at evaluation time to help the model understand and perform the task.</p> <p><strong>Required Skills</strong>: 1. <strong>Prompt Engineering</strong>: This involves designing effective prompts that guide the model to perform the desired task accurately. Skills in crafting clear, concise, and informative prompts are crucial. - <strong>Example Selection</strong>: Choosing representative examples that effectively illustrate the task. - <strong>Contextualization</strong>: Structuring the prompt to provide sufficient context for the model to understand the task. - <strong>Instruction Design</strong>: Writing clear instructions that help the model understand what it is supposed to do.</p> <p><strong>Usage</strong>: Few-shot learning is typically used when: - You need to quickly adapt a model to new tasks without extensive data or computational resources. - You want to leverage a pre-trained model’s existing capabilities with minimal additional input. - You are working in environments where collecting large datasets is impractical or impossible.</p> <h3 id=fine-tuning>Fine-Tuning<a class=headerlink href=#fine-tuning title="Permanent link">&para;</a></h3> <p><strong>Definition</strong>: Fine-tuning involves training a pre-trained model further on a specific dataset to adjust its weights for improved performance on a particular task.</p> <p><strong>Required Skills</strong>: 1. <strong>Machine Learning</strong>: A strong understanding of machine learning principles and practices. - <strong>Model Training</strong>: Knowledge of how to train models, including setting hyperparameters, managing training loops, and handling overfitting. - <strong>Data Preprocessing</strong>: Skills in cleaning, normalizing, and preparing data for training. - <strong>Evaluation Metrics</strong>: Understanding and selecting appropriate metrics to evaluate model performance. - <strong>Optimization</strong>: Familiarity with optimization techniques and algorithms used in training models. - <strong>Programming</strong>: Proficiency in programming languages and frameworks used for machine learning, such as Python with TensorFlow, PyTorch, or Hugging Face Transformers.</p> <ol> <li><strong>Domain Knowledge</strong>: Understanding the specific domain or task for which the model is being fine-tuned.</li> <li><strong>Dataset Curation</strong>: Ability to gather and curate datasets that are representative of the task.</li> <li><strong>Task-Specific Adjustments</strong>: Making task-specific modifications to the model or training process.</li> </ol> <p><strong>Usage</strong>: Fine-tuning is typically used when: - You have access to a substantial amount of task-specific data. - You need to significantly improve a model’s performance on a specific task. - You want to adapt a pre-trained model to specialized domains or tasks that require more than just few-shot examples.</p> <h3 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h3> <ul> <li><strong>Few-Shot Learning</strong>: Relies on prompt engineering skills to craft effective examples and instructions for the model to perform tasks with minimal additional data.</li> <li><strong>Fine-Tuning</strong>: Requires machine learning expertise to further train a pre-trained model on a specific dataset, adjusting its weights to optimize performance for a particular task.</li> </ul> <p>Both approaches leverage pre-trained models but are used in different contexts and require different sets of skills to implement effectively.</p> <h2 id=after-we-finetune-chatgpt35-model-can-we-download-the-finetued-model>After we finetune chatgpt3.5 model can we download the finetued model?<a class=headerlink href=#after-we-finetune-chatgpt35-model-can-we-download-the-finetued-model title="Permanent link">&para;</a></h2> <p>Now a days we see there are many gpt under the explore gpt section in chatgpt app. All these gpts are created using fewshot learning?</p> <p>The GPTs you see under the "Explore GPT" section in the ChatGPT app are not all created using few-shot learning in the traditional sense. Instead, they can be created and customized through different methods that involve varying degrees of training and fine-tuning. Here’s a breakdown of how these GPTs are generally created and customized:</p> <h3 id=1-custom-gpts>1. <strong>Custom GPTs</strong><a class=headerlink href=#1-custom-gpts title="Permanent link">&para;</a></h3> <p><strong>Custom GPTs</strong> are created using the following approaches:</p> <ul> <li> <p><strong>Prompt Engineering</strong>: Some GPTs use advanced prompt engineering to guide the model’s behavior. This involves designing detailed prompts or instructions that tailor the model's responses to specific types of queries or tasks. It can include examples, templates, or structured prompts that help the model handle particular kinds of interactions.</p> </li> <li> <p><strong>Instruction Tuning</strong>: Custom GPTs can be tuned to follow specific instructions or behave in a particular way based on the provided guidelines. This involves designing prompts and guidelines that instruct the model on how to respond to various inputs.</p> </li> <li> <p><strong>Fine-Tuning</strong>: Some GPTs may undergo fine-tuning on task-specific datasets to improve their performance on particular tasks or domains. Fine-tuning adjusts the model's weights based on additional training data that is relevant to the intended use case.</p> </li> </ul> <h3 id=2-few-shot-learning>2. <strong>Few-Shot Learning</strong><a class=headerlink href=#2-few-shot-learning title="Permanent link">&para;</a></h3> <p><strong>Few-Shot Learning</strong> involves providing a few examples in the prompt to guide the model's responses. This technique is useful for:</p> <ul> <li> <p><strong>Providing Examples</strong>: Showing the model a few examples of the type of responses or behavior you expect, which helps it generate similar responses to new inputs.</p> </li> <li> <p><strong>Task Adaptation</strong>: Adapting the model to handle specific types of queries or tasks based on the examples provided in the prompt.</p> </li> </ul> <h3 id=3-combination-of-methods>3. <strong>Combination of Methods</strong><a class=headerlink href=#3-combination-of-methods title="Permanent link">&para;</a></h3> <ul> <li><strong>Hybrid Approach</strong>: Many custom GPTs use a combination of prompt engineering and fine-tuning. For instance, they might use few-shot examples within the prompt for specific interactions while also being fine-tuned on additional data to improve their performance in a particular domain.</li> </ul> <h3 id=examples-of-custom-gpt-creation>Examples of Custom GPT Creation<a class=headerlink href=#examples-of-custom-gpt-creation title="Permanent link">&para;</a></h3> <ul> <li> <p><strong>Customer Support GPT</strong>: A custom GPT designed for customer support might use prompt engineering to include specific examples of common customer queries and appropriate responses. It might also be fine-tuned on historical customer service data.</p> </li> <li> <p><strong>Creative Writing GPT</strong>: A GPT for creative writing might be prompted with examples of different writing styles and genres, and it could be fine-tuned on a corpus of literary texts to better handle creative tasks.</p> </li> </ul> <h3 id=summary_1>Summary<a class=headerlink href=#summary_1 title="Permanent link">&para;</a></h3> <ul> <li><strong>Few-Shot Learning</strong>: Involves using examples in the prompt to guide the model's behavior without changing the model's weights.</li> <li><strong>Custom GPTs</strong>: Can be created using a variety of methods, including prompt engineering, instruction tuning, and fine-tuning.</li> <li><strong>Explore GPT Section</strong>: Features GPTs that may use different combinations of these techniques to cater to specific use cases or tasks.</li> </ul> <p>In essence, while few-shot learning is one method used to create and customize GPTs, many of the GPTs in the "Explore GPT" section may also involve additional techniques and customizations beyond just few-shot learning.</p> <h2 id=can-we-finetune-gpt35-gpt40-or-gemini-model>Can we finetune GPT3.5, GPT4.0 or Gemini Model?<a class=headerlink href=#can-we-finetune-gpt35-gpt40-or-gemini-model title="Permanent link">&para;</a></h2> <p>As of the latest available information:</p> <h3 id=fine-tuning-gpt-35><strong>Fine-Tuning GPT-3.5</strong><a class=headerlink href=#fine-tuning-gpt-35 title="Permanent link">&para;</a></h3> <p>Yes, you can fine-tune GPT-3.5 through OpenAI's platform. Fine-tuning allows you to customize the model on specific datasets to better suit your particular needs. Here's how it typically works:</p> <ol> <li><strong>Prepare Data</strong>: Create a dataset with examples of the inputs and desired outputs.</li> <li><strong>Upload Data</strong>: Use the OpenAI API to upload your dataset.</li> <li><strong>Fine-Tune</strong>: Use the API to initiate the fine-tuning process, which adjusts the model's weights based on your data.</li> <li><strong>Access</strong>: Once fine-tuned, you can access the customized model via the OpenAI API for your specific use cases.</li> </ol> <h3 id=fine-tuning-gpt-40><strong>Fine-Tuning GPT-4.0</strong><a class=headerlink href=#fine-tuning-gpt-40 title="Permanent link">&para;</a></h3> <p>Currently, OpenAI does not provide public access to fine-tune GPT-4. This model is typically used in a "few-shot" or "zero-shot" manner where the model is prompted with examples or tasks without adjusting its internal weights.</p> <h3 id=fine-tuning-gemini-models><strong>Fine-Tuning Gemini Models</strong><a class=headerlink href=#fine-tuning-gemini-models title="Permanent link">&para;</a></h3> <p>As of now, fine-tuning capabilities for Gemini models (developed by Google DeepMind) have not been publicly disclosed. These models are generally accessed and used through APIs provided by Google, and any customization is usually done via prompt engineering or similar methods rather than direct fine-tuning.</p> <h3 id=summary_2><strong>Summary</strong><a class=headerlink href=#summary_2 title="Permanent link">&para;</a></h3> <ul> <li><strong>GPT-3.5</strong>: Fine-tuning is available through the OpenAI platform.</li> <li><strong>GPT-4.0</strong>: Fine-tuning is not publicly available. Usage is typically via prompt engineering.</li> <li><strong>Gemini Models</strong>: Fine-tuning capabilities are not publicly disclosed. Customization is typically done via prompt engineering or API configurations.</li> </ul> <h3 id=alternative-approaches><strong>Alternative Approaches</strong><a class=headerlink href=#alternative-approaches title="Permanent link">&para;</a></h3> <p>For models where direct fine-tuning is not available, consider:</p> <ol> <li><strong>Prompt Engineering</strong>: Designing detailed prompts to guide the model's behavior without changing its internal weights.</li> <li><strong>Embedding-Based Methods</strong>: Using vector embeddings to represent specific data and leveraging these embeddings for tasks like similarity search or classification.</li> <li><strong>Open-Source Models</strong>: Fine-tuning open-source models like GPT-2, GPT-3 (via EleutherAI), or other alternatives available through platforms like Hugging Face, which allows for more control over the training process and deployment.</li> </ol> <p>By leveraging these approaches, you can tailor the behavior of advanced models to better fit your specific needs, even if direct fine-tuning is not an option.</p> <h2 id=after-we-finetune-chatgpt35-model-can-we-download-the-finetued-model_1>After we finetune chatgpt3.5 model can we download the finetued model?<a class=headerlink href=#after-we-finetune-chatgpt35-model-can-we-download-the-finetued-model_1 title="Permanent link">&para;</a></h2> <p>As of the latest information available, when you fine-tune a model like ChatGPT-3.5 through OpenAI, you cannot download the fine-tuned model directly. Here’s how it typically works:</p> <h3 id=fine-tuning-and-model-access>Fine-Tuning and Model Access<a class=headerlink href=#fine-tuning-and-model-access title="Permanent link">&para;</a></h3> <ol> <li><strong>Fine-Tuning Process</strong>:</li> <li><strong>Training</strong>: You can use the OpenAI API to fine-tune a model on your specific dataset. During this process, the model’s weights are adjusted based on the training data you provide.</li> <li> <p><strong>Access</strong>: Once the fine-tuning process is complete, you receive access to the fine-tuned model through the OpenAI API. This allows you to use the model for inference (i.e., generating responses based on the fine-tuned knowledge) via API calls.</p> </li> <li> <p><strong>Model Availability</strong>:</p> </li> <li><strong>No Direct Download</strong>: OpenAI does not provide an option to download the fine-tuned model itself. Instead, you interact with the fine-tuned model through the API.</li> <li><strong>API-Based Usage</strong>: You can integrate the fine-tuned model into your applications or systems by making API requests. This way, you benefit from the fine-tuning without needing direct access to the model files.</li> </ol> <h3 id=alternative-approaches_1>Alternative Approaches<a class=headerlink href=#alternative-approaches_1 title="Permanent link">&para;</a></h3> <p>If you need direct access to a model for local usage or modification, consider the following alternatives:</p> <ol> <li><strong>Use Open-Source Models</strong>:</li> <li> <p><strong>Smaller Models</strong>: For local fine-tuning and model management, you can use open-source models like GPT-2 or GPT-3, which may be available through frameworks such as Hugging Face Transformers. These models allow you to fine-tune and download them for local use.</p> </li> <li> <p><strong>Custom Models</strong>:</p> </li> <li><strong>Local Training</strong>: For more control over the model and its deployment, consider training your models from scratch or fine-tuning open-source variants on your infrastructure.</li> </ol> <h3 id=summary_3>Summary<a class=headerlink href=#summary_3 title="Permanent link">&para;</a></h3> <ul> <li><strong>ChatGPT-3.5 Fine-Tuning</strong>: Fine-tuning is done via the OpenAI API, and you interact with the fine-tuned model through API requests.</li> <li><strong>Direct Download</strong>: Downloading the fine-tuned model itself is not supported by OpenAI.</li> <li><strong>Alternatives</strong>: Use open-source models or local training methods if direct access to the model is needed.</li> </ul> <div class=author-bio style="margin-top: 2rem; display: flex; gap: 1rem;"> <img src=../assets/images/myphotos/Profilephoto1.jpg alt="Hari Thapliyaal" style="border-radius: 50%; width: 80px; height: 80px;"> <div> <strong>Dr. Hari Thapliyaal</strong><br> <small>Dr. Hari Thapliyal is a prolific blogger and seasoned professional with an extensive background in Data Science, Project Management, and Advait-Vedanta Philosophy. He holds a Doctorate in AI/NLP from SSBM, Geneva, along with Master’s degrees in Computers, Business Management, Data Science, and Economics. With over three decades of experience in management and leadership, Hari has extensive expertise in training, consulting, and coaching within the technology sector. His specializations include Data Science, AI, Computer Vision, NLP, and machine learning. Hari is also passionate about meditation and nature, often retreating to secluded places for reflection and peace.</small> </div> </div> <div class=share-buttons style="margin-top: 2rem;"> <strong>Share this article:</strong><br> <a href="https://twitter.com/intent/tweet?text=Why%20to%20Finetune%20LLM%3F&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Why-to-finetune-LLM.html" target=_blank>Twitter</a> | <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Why-to-finetune-LLM.html" target=_blank>Facebook</a> | <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Why-to-finetune-LLM.html" target=_blank>LinkedIn</a> </div> <div id=comments style="margin-top: 3rem;"> <script src=https://giscus.app/client.js data-repo=dasarpai/dasarpai-comments data-repo-id=R_kgDOOGVFpA data-category=General data-category-id=DIC_kwDOOGVFpM4CnzHR data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async>
        </script> </div> </article> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Dr. Hari Thapliyaal </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dasarpai target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://hub.docker.com/r/harithapliyal target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://x.com/dasarpai target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../assets/javascripts/custom.js></script> </body> </html>