<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My various blogs on Datascience, Management, Software Engineering, Philosophy, Vedanta, Sanskrit, Current Affair, History. "><meta name=author content="Hari Thapliyaal"><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Machine-Learning-Metrics.html><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.11"><title>Machine Learning Metrics - DasarpAI</title><link rel=stylesheet href=../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","{{ config.extra.GOOGLE_ANALYTICS }}"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","{{ config.extra.GOOGLE_ANALYTICS }}",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id={{ config.extra.GOOGLE_ANALYTICS }}",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta name=author content="Hari Thapliyaal"><meta name=description content="A comprehensive guide to machine learning evaluation metrics. Learn about various metrics used to assess model performance, including accuracy, precision, recall, F1-score, and specialized metrics for different ML tasks."><meta name=keywords content="Machine Learning Metrics, Model Evaluation, Performance Measurement, ML Model Assessment, Evaluation Metrics, Model Performance, Statistical Metrics, ML Evaluation"><meta property=og:type content=article><meta property=og:locale content=en_US><meta property=og:site_name content=DasarpAI><meta property=og:title content="Machine Learning Metrics"><meta property=og:description content="A comprehensive guide to machine learning evaluation metrics. Learn about various metrics used to assess model performance, including accuracy, precision, recall, F1-score, and specialized metrics for different ML tasks."><meta property=og:url content=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Machine-Learning-Metrics.html><meta property=og:image content=../../assets/images/dspost/dsp6092-Machine-Learning-Metrics.jpg><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=@dasarpai><meta name=twitter:title content="Machine Learning Metrics"><meta name=twitter:description content="A comprehensive guide to machine learning evaluation metrics. Learn about various metrics used to assess model performance, including accuracy, precision, recall, F1-score, and specialized metrics for different ML tasks."><meta name=twitter:image content=../../assets/images/dspost/dsp6092-Machine-Learning-Metrics.jpg><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Machine-Learning-Metrics.html><link rel=stylesheet href=../assets/stylesheets/custom.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#machine-learning-metrics class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@harithapliyal</strong> on <a rel=me href=https://linkedin.com/in/harithapliyal> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </span> <strong>Fosstodon</strong> </a> and <a href=https://x.com/dasarpai> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=DasarpAI class="md-header__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DasarpAI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Machine Learning Metrics </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=index.html class=md-tabs__link> Data Science </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/pmlogy-home.html class=md-tabs__link> Project Management </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/wia-home.html class=md-tabs__link> SpiritualDrops </a> </li> <li class=md-tabs__item> <a href=../samskrutyatra/index.html class=md-tabs__link> Samskrut </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=DasarpAI class="md-nav__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> DasarpAI </label> <div class=md-nav__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../index.html class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/aboutme.html class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> <li class=md-nav__item> <a href=../dscourses/index.html class=md-nav__link> <span class=md-ellipsis> DS/AI Courses/Services </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Project/Work Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Project/Work Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/project-index-page.html class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-al-ml-projects.md class=md-nav__link> <span class=md-ellipsis> Business Domain </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-my-technology-stacks.md class=md-nav__link> <span class=md-ellipsis> Technology Stack </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-management-projects.md class=md-nav__link> <span class=md-ellipsis> Project Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../management/index.html class=md-nav__link> <span class=md-ellipsis> PM Courses/Services </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/clients.html class=md-nav__link> <span class=md-ellipsis> Clients </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/testimonials.md class=md-nav__link> <span class=md-ellipsis> Testimonial </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/publications-home.html class=md-nav__link> <span class=md-ellipsis> Publications </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/corpus-home.html class=md-nav__link> <span class=md-ellipsis> History Corpus </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=index.html class="md-nav__link "> <span class=md-ellipsis> Data Science </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Data Science </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dsresources/index.html class=md-nav__link> <span class=md-ellipsis> DS Resources </span> </a> </li> <li class=md-nav__item> <a href=../news/index.html class=md-nav__link> <span class=md-ellipsis> AI and Business News </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-books.md class=md-nav__link> <span class=md-ellipsis> Data Science-Books </span> </a> </li> <li class=md-nav__item> <a href=data-science-cheatsheets.md class=md-nav__link> <span class=md-ellipsis> Data Science Cheatsheets </span> </a> </li> <li class=md-nav__item> <a href=best-youtube-channels-for-ds.md class=md-nav__link> <span class=md-ellipsis> Video Channels to Learn DS </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-interview-resources.md class=md-nav__link> <span class=md-ellipsis> DS Interview Questions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../pmblog/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Project Management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-home.html class=md-nav__link> <span class=md-ellipsis> PMLOGY Home </span> </a> </li> <li class=md-nav__item> <a href=../pmglossary.md class=md-nav__link> <span class=md-ellipsis> PM Glossary </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-tags.md class=md-nav__link> <span class=md-ellipsis> PM Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-tags.md class=md-nav__link> <span class=md-ellipsis> PMBOK6 Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-summary.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 </span> </a> </li> <li class=md-nav__item> <a href=../pmbok6/index.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Explorer </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> PM Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> PM Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmi-templates.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Templates </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/prince2-templates.html class=md-nav__link> <span class=md-ellipsis> PRINCE2 Templates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../pmbok6hi/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management Hindi </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Project Management Hindi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmbok6hi-summary.html class=md-nav__link> <span class=md-ellipsis> PMBoK6 Hindi </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../wiaposts/index.html class="md-nav__link "> <span class=md-ellipsis> SpiritualDrops </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> SpiritualDrops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/wia-home.html class=md-nav__link> <span class=md-ellipsis> WIA Home </span> </a> </li> <li class=md-nav__item> <a href=../quotations/index.html class=md-nav__link> <span class=md-ellipsis> WIA Quotes </span> </a> </li> <li class=md-nav__item> <a href=../gk/index.html class=md-nav__link> <span class=md-ellipsis> GK Blog </span> </a> </li> <li class=md-nav__item> <a href=../booksummary/index.html class=md-nav__link> <span class=md-ellipsis> Book Summary </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../samskrutyatra/index.html class="md-nav__link "> <span class=md-ellipsis> Samskrut </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Samskrut </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/samskrut-home.html class=md-nav__link> <span class=md-ellipsis> SamskrutYatra Home </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#mrr class=md-nav__link> <span class=md-ellipsis> MRR </span> </a> </li> <li class=md-nav__item> <a href=#mapn class=md-nav__link> <span class=md-ellipsis> MAP@n </span> </a> </li> <li class=md-nav__item> <a href=#mean-average-precision-map class=md-nav__link> <span class=md-ellipsis> Mean average precision (mAP): </span> </a> </li> <li class=md-nav__item> <a href=#mapiou-thresholds class=md-nav__link> <span class=md-ellipsis> mAP@IoU thresholds </span> </a> </li> <li class=md-nav__item> <a href=#accuracy class=md-nav__link> <span class=md-ellipsis> Accuracy: </span> </a> <nav class=md-nav aria-label=Accuracy:> <ul class=md-nav__list> <li class=md-nav__item> <a href=#acc_norm class=md-nav__link> <span class=md-ellipsis> acc_norm </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_cardiffnlptweet_topic_multi class=md-nav__link> <span class=md-ellipsis> accuracy_cardiffnlp/tweet_topic_multi </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_cardiffnlptweet_topic_single class=md-nav__link> <span class=md-ellipsis> accuracy_cardiffnlp/tweet_topic_single </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_cosinus class=md-nav__link> <span class=md-ellipsis> accuracy_cosinus </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_euclidean class=md-nav__link> <span class=md-ellipsis> accuracy_euclidean </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_manhattan class=md-nav__link> <span class=md-ellipsis> accuracy_manhattan </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_tweet_evalemoji class=md-nav__link> <span class=md-ellipsis> accuracy_tweet_eval/emoji </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_tweet_evalemotion class=md-nav__link> <span class=md-ellipsis> accuracy_tweet_eval/emotion </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_tweet_evalhate class=md-nav__link> <span class=md-ellipsis> accuracy_tweet_eval/hate </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_tweet_evalirony class=md-nav__link> <span class=md-ellipsis> accuracy_tweet_eval/irony </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_tweet_evaloffensive class=md-nav__link> <span class=md-ellipsis> accuracy_tweet_eval/offensive </span> </a> </li> <li class=md-nav__item> <a href=#accuracy_tweet_evalsentiment class=md-nav__link> <span class=md-ellipsis> accuracy_tweet_eval/sentiment </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#precision class=md-nav__link> <span class=md-ellipsis> Precision: </span> </a> <nav class=md-nav aria-label=Precision:> <ul class=md-nav__list> <li class=md-nav__item> <a href=#precision_entity_span class=md-nav__link> <span class=md-ellipsis> precision_entity_span </span> </a> </li> <li class=md-nav__item> <a href=#precisionn class=md-nav__link> <span class=md-ellipsis> Precision@n </span> </a> </li> <li class=md-nav__item> <a href=#precision_macro class=md-nav__link> <span class=md-ellipsis> precision_macro </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#recall class=md-nav__link> <span class=md-ellipsis> Recall: </span> </a> <nav class=md-nav aria-label=Recall:> <ul class=md-nav__list> <li class=md-nav__item> <a href=#recall_entity_span class=md-nav__link> <span class=md-ellipsis> recall_entity_span </span> </a> </li> <li class=md-nav__item> <a href=#recalln class=md-nav__link> <span class=md-ellipsis> recall@n </span> </a> </li> <li class=md-nav__item> <a href=#recall_macro class=md-nav__link> <span class=md-ellipsis> recall_macro </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#rp class=md-nav__link> <span class=md-ellipsis> R@P </span> </a> <nav class=md-nav aria-label=R@P> <ul class=md-nav__list> <li class=md-nav__item> <a href=#rp50 class=md-nav__link> <span class=md-ellipsis> R@P=50 </span> </a> </li> <li class=md-nav__item> <a href=#rp75 class=md-nav__link> <span class=md-ellipsis> R@P=75 </span> </a> </li> <li class=md-nav__item> <a href=#rp90 class=md-nav__link> <span class=md-ellipsis> R@P=90 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#f1-score class=md-nav__link> <span class=md-ellipsis> F1 score: </span> </a> <nav class=md-nav aria-label="F1 score:"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#f1_entity_span class=md-nav__link> <span class=md-ellipsis> f1_entity_span </span> </a> </li> <li class=md-nav__item> <a href=#f1_macro class=md-nav__link> <span class=md-ellipsis> f1_macro </span> </a> </li> <li class=md-nav__item> <a href=#f1_micro class=md-nav__link> <span class=md-ellipsis> f1_micro </span> </a> </li> <li class=md-nav__item> <a href=#f1_weighted class=md-nav__link> <span class=md-ellipsis> f1_weighted </span> </a> </li> <li class=md-nav__item> <a href=#f1-seqeval class=md-nav__link> <span class=md-ellipsis> f1 (seqeval) </span> </a> </li> <li class=md-nav__item> <a href=#f1-macro class=md-nav__link> <span class=md-ellipsis> f1 macro </span> </a> </li> <li class=md-nav__item> <a href=#f1m class=md-nav__link> <span class=md-ellipsis> f1@m </span> </a> </li> <li class=md-nav__item> <a href=#f1m-absent class=md-nav__link> <span class=md-ellipsis> f1@m (absent) </span> </a> </li> <li class=md-nav__item> <a href=#f1m-present class=md-nav__link> <span class=md-ellipsis> f1@m (present) </span> </a> </li> <li class=md-nav__item> <a href=#f1o-absent class=md-nav__link> <span class=md-ellipsis> f1@o (absent) </span> </a> </li> <li class=md-nav__item> <a href=#f1o-present class=md-nav__link> <span class=md-ellipsis> f1@o (present) </span> </a> </li> <li class=md-nav__item> <a href=#f1neg class=md-nav__link> <span class=md-ellipsis> f1neg </span> </a> </li> <li class=md-nav__item> <a href=#f1pos class=md-nav__link> <span class=md-ellipsis> f1pos </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#hitn class=md-nav__link> <span class=md-ellipsis> Hit@n </span> </a> <nav class=md-nav aria-label=Hit@n> <ul class=md-nav__list> <li class=md-nav__item> <a href=#hit1 class=md-nav__link> <span class=md-ellipsis> Hit@1: </span> </a> </li> <li class=md-nav__item> <a href=#hit5 class=md-nav__link> <span class=md-ellipsis> Hit@5: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#log-loss class=md-nav__link> <span class=md-ellipsis> Log-loss: </span> </a> </li> <li class=md-nav__item> <a href=#brier-score class=md-nav__link> <span class=md-ellipsis> Brier score: </span> </a> </li> <li class=md-nav__item> <a href=#confusion-matrix class=md-nav__link> <span class=md-ellipsis> Confusion matrix: </span> </a> </li> <li class=md-nav__item> <a href=#mse class=md-nav__link> <span class=md-ellipsis> MSE </span> </a> </li> <li class=md-nav__item> <a href=#root-mean-squared-error-rmse class=md-nav__link> <span class=md-ellipsis> Root mean squared error (RMSE): </span> </a> </li> <li class=md-nav__item> <a href=#mean-absolute-error-mae class=md-nav__link> <span class=md-ellipsis> Mean absolute error (MAE): </span> </a> </li> <li class=md-nav__item> <a href=#r-squared class=md-nav__link> <span class=md-ellipsis> R-squared: </span> </a> </li> <li class=md-nav__item> <a href=#cohens-kappa class=md-nav__link> <span class=md-ellipsis> Cohen's kappa: </span> </a> </li> <li class=md-nav__item> <a href=#matthews-correlation-coefficient-mcc class=md-nav__link> <span class=md-ellipsis> Matthews correlation coefficient (MCC): </span> </a> </li> <li class=md-nav__item> <a href=#area-under-the-curve-auc class=md-nav__link> <span class=md-ellipsis> Area under the curve (AUC): </span> </a> </li> <li class=md-nav__item> <a href=#precision-recall-curve class=md-nav__link> <span class=md-ellipsis> Precision-recall curve: </span> </a> </li> <li class=md-nav__item> <a href=#roc-curve class=md-nav__link> <span class=md-ellipsis> ROC curve: </span> </a> </li> <li class=md-nav__item> <a href=#mean-squared-logarithmic-error-msle class=md-nav__link> <span class=md-ellipsis> Mean squared logarithmic error (MSLE): </span> </a> </li> <li class=md-nav__item> <a href=#mean-absolute-percentage-error-mape class=md-nav__link> <span class=md-ellipsis> Mean absolute percentage error (MAPE): </span> </a> </li> <li class=md-nav__item> <a href=#root-mean-square-logarithmic-error-rmsle class=md-nav__link> <span class=md-ellipsis> Root mean square logarithmic error (RMSLE): </span> </a> </li> <li class=md-nav__item> <a href=#precision-at-k-pk class=md-nav__link> <span class=md-ellipsis> Precision at k (P@k): </span> </a> </li> <li class=md-nav__item> <a href=#recall-at-k-rk class=md-nav__link> <span class=md-ellipsis> Recall at k (R@k): </span> </a> </li> <li class=md-nav__item> <a href=#f1-score-at-k-f1k class=md-nav__link> <span class=md-ellipsis> F1-score at k (F1@k): </span> </a> </li> <li class=md-nav__item> <a href=#interpretability class=md-nav__link> <span class=md-ellipsis> Interpretability: </span> </a> </li> <li class=md-nav__item> <a href=#fairness class=md-nav__link> <span class=md-ellipsis> Fairness: </span> </a> </li> <li class=md-nav__item> <a href=#inception-score class=md-nav__link> <span class=md-ellipsis> Inception score: </span> </a> </li> <li class=md-nav__item> <a href=#frechet-inception-distance class=md-nav__link> <span class=md-ellipsis> Frechet Inception distance: </span> </a> </li> <li class=md-nav__item> <a href=#wasserstein-distance class=md-nav__link> <span class=md-ellipsis> Wasserstein distance: </span> </a> </li> <li class=md-nav__item> <a href=#inception-score_1 class=md-nav__link> <span class=md-ellipsis> Inception score: </span> </a> </li> <li class=md-nav__item> <a href=#perplexity class=md-nav__link> <span class=md-ellipsis> Perplexity: </span> </a> </li> <li class=md-nav__item> <a href=#bleu-score class=md-nav__link> <span class=md-ellipsis> BLEU score: </span> </a> <nav class=md-nav aria-label="BLEU score:"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#bleu4 class=md-nav__link> <span class=md-ellipsis> BLEU4 </span> </a> </li> <li class=md-nav__item> <a href=#bleu4_answer_extraction class=md-nav__link> <span class=md-ellipsis> BLEU4_answer_extraction </span> </a> </li> <li class=md-nav__item> <a href=#bleu4_question_answer_generation class=md-nav__link> <span class=md-ellipsis> BLEU4_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#bleu4_question_answering class=md-nav__link> <span class=md-ellipsis> BLEU4_question_answering </span> </a> </li> <li class=md-nav__item> <a href=#bleu4_question_generation class=md-nav__link> <span class=md-ellipsis> BLEU4_question_generation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#intersection-over-union-iou class=md-nav__link> <span class=md-ellipsis> Intersection over union (IoU): </span> </a> </li> <li class=md-nav__item> <a href=#top-5-error-rate class=md-nav__link> <span class=md-ellipsis> Top-5 error rate: </span> </a> </li> <li class=md-nav__item> <a href=#em-exact-match class=md-nav__link> <span class=md-ellipsis> EM - Exact Match </span> </a> </li> <li class=md-nav__item> <a href=#rouge class=md-nav__link> <span class=md-ellipsis> ROUGE </span> </a> <nav class=md-nav aria-label=ROUGE> <ul class=md-nav__list> <li class=md-nav__item> <a href=#rouge-l class=md-nav__link> <span class=md-ellipsis> rouge-l </span> </a> </li> <li class=md-nav__item> <a href=#rouge-2 class=md-nav__link> <span class=md-ellipsis> rouge-2 </span> </a> </li> <li class=md-nav__item> <a href=#rouge-lsum class=md-nav__link> <span class=md-ellipsis> rouge-lsum </span> </a> </li> <li class=md-nav__item> <a href=#rouge_l_answer_extraction class=md-nav__link> <span class=md-ellipsis> rouge_l_answer_extraction </span> </a> </li> <li class=md-nav__item> <a href=#rouge_l_question_answer_generation class=md-nav__link> <span class=md-ellipsis> rouge_l_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#rouge_l_question_answering class=md-nav__link> <span class=md-ellipsis> rouge_l_question_answering </span> </a> </li> <li class=md-nav__item> <a href=#rouge_l_question_generation class=md-nav__link> <span class=md-ellipsis> rouge_l_question_generation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#meteor class=md-nav__link> <span class=md-ellipsis> METEOR </span> </a> <nav class=md-nav aria-label=METEOR> <ul class=md-nav__list> <li class=md-nav__item> <a href=#meteor_answer_extraction class=md-nav__link> <span class=md-ellipsis> meteor_answer_extraction </span> </a> </li> <li class=md-nav__item> <a href=#meteor_question_answer_generation class=md-nav__link> <span class=md-ellipsis> meteor_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#meteor_question_answering class=md-nav__link> <span class=md-ellipsis> meteor_question_answering </span> </a> </li> <li class=md-nav__item> <a href=#meteor_question_generation class=md-nav__link> <span class=md-ellipsis> meteor_question_generation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#heqd class=md-nav__link> <span class=md-ellipsis> HEQD </span> </a> </li> <li class=md-nav__item> <a href=#perplexity_1 class=md-nav__link> <span class=md-ellipsis> Perplexity </span> </a> </li> <li class=md-nav__item> <a href=#passn class=md-nav__link> <span class=md-ellipsis> Pass@n </span> </a> </li> <li class=md-nav__item> <a href=#answer-exact class=md-nav__link> <span class=md-ellipsis> Answer Exact </span> </a> <nav class=md-nav aria-label="Answer Exact"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#answer_exact_match_answer_extraction class=md-nav__link> <span class=md-ellipsis> answer_exact_match_answer_extraction </span> </a> </li> <li class=md-nav__item> <a href=#answer_exact_match_question_answering class=md-nav__link> <span class=md-ellipsis> answer_exact_match_question_answering </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#answer-f1 class=md-nav__link> <span class=md-ellipsis> Answer F1 </span> </a> <nav class=md-nav aria-label="Answer F1"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#answer_f1_score__answer_extraction class=md-nav__link> <span class=md-ellipsis> answer_f1_score__answer_extraction </span> </a> </li> <li class=md-nav__item> <a href=#answer_f1_score__question_answering class=md-nav__link> <span class=md-ellipsis> answer_f1_score__question_answering </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#bert-score class=md-nav__link> <span class=md-ellipsis> Bert Score </span> </a> <nav class=md-nav aria-label="Bert Score"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#bertscore class=md-nav__link> <span class=md-ellipsis> bertscore </span> </a> </li> <li class=md-nav__item> <a href=#bertscore_answer_extraction class=md-nav__link> <span class=md-ellipsis> bertscore_answer_extraction </span> </a> </li> <li class=md-nav__item> <a href=#bertscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> bertscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#bertscore_question_answering class=md-nav__link> <span class=md-ellipsis> bertscore_question_answering </span> </a> </li> <li class=md-nav__item> <a href=#bertscore_question_generation class=md-nav__link> <span class=md-ellipsis> bertscore_question_generation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#code class=md-nav__link> <span class=md-ellipsis> Code </span> </a> <nav class=md-nav aria-label=Code> <ul class=md-nav__list> <li class=md-nav__item> <a href=#code_eval class=md-nav__link> <span class=md-ellipsis> code_eval </span> </a> </li> <li class=md-nav__item> <a href=#code_eval_outputs class=md-nav__link> <span class=md-ellipsis> code_eval_outputs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#cosine class=md-nav__link> <span class=md-ellipsis> Cosine </span> </a> <nav class=md-nav aria-label=Cosine> <ul class=md-nav__list> <li class=md-nav__item> <a href=#cos_sim_accuracy class=md-nav__link> <span class=md-ellipsis> cos_sim_accuracy </span> </a> </li> <li class=md-nav__item> <a href=#cos_sim_f1 class=md-nav__link> <span class=md-ellipsis> cos_sim_f1 </span> </a> </li> <li class=md-nav__item> <a href=#cos_sim_precision class=md-nav__link> <span class=md-ellipsis> cos_sim_precision </span> </a> </li> <li class=md-nav__item> <a href=#cos_sim_recall class=md-nav__link> <span class=md-ellipsis> cos_sim_recall </span> </a> </li> <li class=md-nav__item> <a href=#cos_sim_ap class=md-nav__link> <span class=md-ellipsis> cos_sim_ap </span> </a> </li> <li class=md-nav__item> <a href=#cos_sim_pearson class=md-nav__link> <span class=md-ellipsis> cos_sim_pearson </span> </a> </li> <li class=md-nav__item> <a href=#cos_sim_spearman class=md-nav__link> <span class=md-ellipsis> cos_sim_spearman </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#dot class=md-nav__link> <span class=md-ellipsis> Dot </span> </a> <nav class=md-nav aria-label=Dot> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dot_accuracy class=md-nav__link> <span class=md-ellipsis> dot_accuracy </span> </a> </li> <li class=md-nav__item> <a href=#dot_ap class=md-nav__link> <span class=md-ellipsis> dot_ap </span> </a> </li> <li class=md-nav__item> <a href=#dot_f1 class=md-nav__link> <span class=md-ellipsis> dot_f1 </span> </a> </li> <li class=md-nav__item> <a href=#dot_pearson class=md-nav__link> <span class=md-ellipsis> dot_pearson </span> </a> </li> <li class=md-nav__item> <a href=#dot_precision class=md-nav__link> <span class=md-ellipsis> dot_precision </span> </a> </li> <li class=md-nav__item> <a href=#dot_recall class=md-nav__link> <span class=md-ellipsis> dot_recall </span> </a> </li> <li class=md-nav__item> <a href=#dot_spearman class=md-nav__link> <span class=md-ellipsis> dot_spearman </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#euclidean class=md-nav__link> <span class=md-ellipsis> Euclidean </span> </a> <nav class=md-nav aria-label=Euclidean> <ul class=md-nav__list> <li class=md-nav__item> <a href=#euclidean_accuracy class=md-nav__link> <span class=md-ellipsis> euclidean_accuracy </span> </a> </li> <li class=md-nav__item> <a href=#euclidean_ap class=md-nav__link> <span class=md-ellipsis> euclidean_ap </span> </a> </li> <li class=md-nav__item> <a href=#euclidean_f1 class=md-nav__link> <span class=md-ellipsis> euclidean_f1 </span> </a> </li> <li class=md-nav__item> <a href=#euclidean_pearson class=md-nav__link> <span class=md-ellipsis> euclidean_pearson </span> </a> </li> <li class=md-nav__item> <a href=#euclidean_precision class=md-nav__link> <span class=md-ellipsis> euclidean_precision </span> </a> </li> <li class=md-nav__item> <a href=#euclidean_recall class=md-nav__link> <span class=md-ellipsis> euclidean_recall </span> </a> </li> <li class=md-nav__item> <a href=#euclidean_spearman class=md-nav__link> <span class=md-ellipsis> euclidean_spearman </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#eval class=md-nav__link> <span class=md-ellipsis> Eval </span> </a> <nav class=md-nav aria-label=Eval> <ul class=md-nav__list> <li class=md-nav__item> <a href=#eval_accuracy class=md-nav__link> <span class=md-ellipsis> eval_accuracy </span> </a> </li> <li class=md-nav__item> <a href=#eval_exact class=md-nav__link> <span class=md-ellipsis> eval_exact </span> </a> </li> <li class=md-nav__item> <a href=#eval_f1 class=md-nav__link> <span class=md-ellipsis> eval_f1 </span> </a> </li> <li class=md-nav__item> <a href=#eval_hasans_exact class=md-nav__link> <span class=md-ellipsis> eval_hasans_exact </span> </a> </li> <li class=md-nav__item> <a href=#eval_hasans_f1 class=md-nav__link> <span class=md-ellipsis> eval_hasans_f1 </span> </a> </li> <li class=md-nav__item> <a href=#eval_noans_exact class=md-nav__link> <span class=md-ellipsis> eval_noans_exact </span> </a> </li> <li class=md-nav__item> <a href=#eval_noans_f1 class=md-nav__link> <span class=md-ellipsis> eval_noans_f1 </span> </a> </li> <li class=md-nav__item> <a href=#eval_precision class=md-nav__link> <span class=md-ellipsis> eval_precision </span> </a> </li> <li class=md-nav__item> <a href=#eval_recall class=md-nav__link> <span class=md-ellipsis> eval_recall </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#exact class=md-nav__link> <span class=md-ellipsis> Exact </span> </a> <nav class=md-nav aria-label=Exact> <ul class=md-nav__list> <li class=md-nav__item> <a href=#exact_1 class=md-nav__link> <span class=md-ellipsis> exact </span> </a> </li> <li class=md-nav__item> <a href=#exact_match class=md-nav__link> <span class=md-ellipsis> exact_match </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#gen class=md-nav__link> <span class=md-ellipsis> Gen </span> </a> <nav class=md-nav aria-label=Gen> <ul class=md-nav__list> <li class=md-nav__item> <a href=#gen_len class=md-nav__link> <span class=md-ellipsis> gen_len </span> </a> </li> <li class=md-nav__item> <a href=#gen-length class=md-nav__link> <span class=md-ellipsis> gen-length </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#joint-goal-accuracy class=md-nav__link> <span class=md-ellipsis> Joint Goal Accuracy </span> </a> <nav class=md-nav aria-label="Joint Goal Accuracy"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#joint-goal-accuracy_1 class=md-nav__link> <span class=md-ellipsis> joint goal accuracy </span> </a> </li> <li class=md-nav__item> <a href=#joint-goal-expected-calibration-error class=md-nav__link> <span class=md-ellipsis> joint goal expected calibration error </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#manhattan class=md-nav__link> <span class=md-ellipsis> Manhattan </span> </a> <nav class=md-nav aria-label=Manhattan> <ul class=md-nav__list> <li class=md-nav__item> <a href=#manhattan_accuracy class=md-nav__link> <span class=md-ellipsis> manhattan_accuracy </span> </a> </li> <li class=md-nav__item> <a href=#manhattan_ap class=md-nav__link> <span class=md-ellipsis> manhattan_ap </span> </a> </li> <li class=md-nav__item> <a href=#manhattan_f1 class=md-nav__link> <span class=md-ellipsis> manhattan_f1 </span> </a> </li> <li class=md-nav__item> <a href=#manhattan_precision class=md-nav__link> <span class=md-ellipsis> manhattan_precision </span> </a> </li> <li class=md-nav__item> <a href=#manhattan_recall class=md-nav__link> <span class=md-ellipsis> manhattan_recall </span> </a> </li> <li class=md-nav__item> <a href=#manhattan_spearman class=md-nav__link> <span class=md-ellipsis> manhattan_spearman </span> </a> </li> <li class=md-nav__item> <a href=#manhattan_pearson class=md-nav__link> <span class=md-ellipsis> manhattan_pearson </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#max class=md-nav__link> <span class=md-ellipsis> Max </span> </a> <nav class=md-nav aria-label=Max> <ul class=md-nav__list> <li class=md-nav__item> <a href=#max_accuracy class=md-nav__link> <span class=md-ellipsis> max_accuracy </span> </a> </li> <li class=md-nav__item> <a href=#max_ap class=md-nav__link> <span class=md-ellipsis> max_ap </span> </a> </li> <li class=md-nav__item> <a href=#max_f1 class=md-nav__link> <span class=md-ellipsis> max_f1 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mean class=md-nav__link> <span class=md-ellipsis> mean </span> </a> <nav class=md-nav aria-label=mean> <ul class=md-nav__list> <li class=md-nav__item> <a href=#mean_reciprocal_rank class=md-nav__link> <span class=md-ellipsis> mean_reciprocal_rank </span> </a> </li> <li class=md-nav__item> <a href=#mean_reward class=md-nav__link> <span class=md-ellipsis> mean_reward </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#macro class=md-nav__link> <span class=md-ellipsis> Macro </span> </a> <nav class=md-nav aria-label=Macro> <ul class=md-nav__list> <li class=md-nav__item> <a href=#macro_f1 class=md-nav__link> <span class=md-ellipsis> macro_f1 </span> </a> </li> <li class=md-nav__item> <a href=#macro_precision class=md-nav__link> <span class=md-ellipsis> macro_precision </span> </a> </li> <li class=md-nav__item> <a href=#macro_recall class=md-nav__link> <span class=md-ellipsis> macro_recall </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#micro class=md-nav__link> <span class=md-ellipsis> Micro </span> </a> <nav class=md-nav aria-label=Micro> <ul class=md-nav__list> <li class=md-nav__item> <a href=#micro_precision class=md-nav__link> <span class=md-ellipsis> micro_precision </span> </a> </li> <li class=md-nav__item> <a href=#micro_recall class=md-nav__link> <span class=md-ellipsis> micro_recall </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1 class=md-nav__link> <span class=md-ellipsis> micro_f1 </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1_cardiffnlp class=md-nav__link> <span class=md-ellipsis> micro_f1_cardiffnlp </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1_tweet_evalemoji class=md-nav__link> <span class=md-ellipsis> micro_f1_tweet_eval/emoji </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1_tweet_evalemotion class=md-nav__link> <span class=md-ellipsis> micro_f1_tweet_eval/emotion </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1_tweet_evalhate class=md-nav__link> <span class=md-ellipsis> micro_f1_tweet_eval/hate </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1_tweet_evalirony class=md-nav__link> <span class=md-ellipsis> micro_f1_tweet_eval/irony </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1_tweet_evaloffensive class=md-nav__link> <span class=md-ellipsis> micro_f1_tweet_eval/offensive </span> </a> </li> <li class=md-nav__item> <a href=#micro_f1_tweet_evalsentiment class=md-nav__link> <span class=md-ellipsis> micro_f1_tweet_eval/sentiment </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mover-score class=md-nav__link> <span class=md-ellipsis> Mover Score </span> </a> <nav class=md-nav aria-label="Mover Score"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#moverscore_answer_extraction class=md-nav__link> <span class=md-ellipsis> moverscore_answer_extraction </span> </a> </li> <li class=md-nav__item> <a href=#moverscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> moverscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#moverscore_question_answering class=md-nav__link> <span class=md-ellipsis> moverscore_question_answering </span> </a> </li> <li class=md-nav__item> <a href=#moverscore_question_generation class=md-nav__link> <span class=md-ellipsis> moverscore_question_generation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#normalized-discounted-cumulative-gain-ndcg class=md-nav__link> <span class=md-ellipsis> Normalized discounted cumulative gain (NDCG): </span> </a> </li> <li class=md-nav__item> <a href=#pearson class=md-nav__link> <span class=md-ellipsis> Pearson </span> </a> <nav class=md-nav aria-label=Pearson> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pearson_correlation class=md-nav__link> <span class=md-ellipsis> pearson_correlation </span> </a> </li> <li class=md-nav__item> <a href=#pearsons-r-distress class=md-nav__link> <span class=md-ellipsis> pearson's r (distress) </span> </a> </li> <li class=md-nav__item> <a href=#pearsons-r-empathy class=md-nav__link> <span class=md-ellipsis> pearson's r (empathy) </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#qa-aligned-f1 class=md-nav__link> <span class=md-ellipsis> QA Aligned F1 </span> </a> <nav class=md-nav aria-label="QA Aligned F1"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#qa_aligned_f1_score_bertscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> qa_aligned_f1_score_bertscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_f1_score_moverscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> qa_aligned_f1_score_moverscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_f1_score_moverscore_question_answer_generation_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_f1_score_moverscore_question_answer_generation_gold_answer </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#qa-aligned-precision class=md-nav__link> <span class=md-ellipsis> QA Aligned Precision </span> </a> <nav class=md-nav aria-label="QA Aligned Precision"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#qa_aligned_precision_bertscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> qa_aligned_precision_bertscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_precision_moverscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> qa_aligned_precision_moverscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer_gold_answer </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#qa-aligned-recall class=md-nav__link> <span class=md-ellipsis> QA Aligned Recall </span> </a> <nav class=md-nav aria-label="QA Aligned Recall"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#qa_aligned_recall_bertscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> qa_aligned_recall_bertscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_recall_moverscore_question_answer_generation class=md-nav__link> <span class=md-ellipsis> qa_aligned_recall_moverscore_question_answer_generation </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer </span> </a> </li> <li class=md-nav__item> <a href=#qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer_gold_answer class=md-nav__link> <span class=md-ellipsis> qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer_gold_answer </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#squad class=md-nav__link> <span class=md-ellipsis> SQUAD </span> </a> <nav class=md-nav aria-label=SQUAD> <ul class=md-nav__list> <li class=md-nav__item> <a href=#squad_1 class=md-nav__link> <span class=md-ellipsis> squad </span> </a> </li> <li class=md-nav__item> <a href=#squad_v2 class=md-nav__link> <span class=md-ellipsis> squad_v2 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#top-n-accuracy class=md-nav__link> <span class=md-ellipsis> Top-n Accuracy </span> </a> <nav class=md-nav aria-label="Top-n Accuracy"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#top-1-accuracy class=md-nav__link> <span class=md-ellipsis> top-1 accuracy </span> </a> </li> <li class=md-nav__item> <a href=#top-5-accuracy class=md-nav__link> <span class=md-ellipsis> top-5 accuracy </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#validation class=md-nav__link> <span class=md-ellipsis> Validation </span> </a> <nav class=md-nav aria-label=Validation> <ul class=md-nav__list> <li class=md-nav__item> <a href=#validation_accuracy class=md-nav__link> <span class=md-ellipsis> validation_accuracy </span> </a> </li> <li class=md-nav__item> <a href=#validation-loss class=md-nav__link> <span class=md-ellipsis> validation loss </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#weighted class=md-nav__link> <span class=md-ellipsis> Weighted </span> </a> <nav class=md-nav aria-label=Weighted> <ul class=md-nav__list> <li class=md-nav__item> <a href=#weighted_f1 class=md-nav__link> <span class=md-ellipsis> weighted_f1 </span> </a> </li> <li class=md-nav__item> <a href=#weighted_precision class=md-nav__link> <span class=md-ellipsis> weighted_precision </span> </a> </li> <li class=md-nav__item> <a href=#weighted_recall class=md-nav__link> <span class=md-ellipsis> weighted_recall </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#wer class=md-nav__link> <span class=md-ellipsis> WER </span> </a> <nav class=md-nav aria-label=WER> <ul class=md-nav__list> <li class=md-nav__item> <a href=#wer_without_norm class=md-nav__link> <span class=md-ellipsis> wer_without_norm </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#matthews class=md-nav__link> <span class=md-ellipsis> Matthews </span> </a> <nav class=md-nav aria-label=Matthews> <ul class=md-nav__list> <li class=md-nav__item> <a href=#matthews_correlation class=md-nav__link> <span class=md-ellipsis> matthews_correlation </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#accuracy-radius-1 class=md-nav__link> <span class=md-ellipsis> Accuracy-radius-1 </span> </a> </li> <li class=md-nav__item> <a href=#act_dcf-p001 class=md-nav__link> <span class=md-ellipsis> Act_dcf-p=0.01 </span> </a> </li> <li class=md-nav__item> <a href=#avgrank class=md-nav__link> <span class=md-ellipsis> Avgrank </span> </a> </li> <li class=md-nav__item> <a href=#arc class=md-nav__link> <span class=md-ellipsis> ARC </span> </a> </li> <li class=md-nav__item> <a href=#byte_perplexity class=md-nav__link> <span class=md-ellipsis> Byte_perplexity </span> </a> </li> <li class=md-nav__item> <a href=#cer class=md-nav__link> <span class=md-ellipsis> CER </span> </a> </li> <li class=md-nav__item> <a href=#cher class=md-nav__link> <span class=md-ellipsis> Cher </span> </a> </li> <li class=md-nav__item> <a href=#chrf class=md-nav__link> <span class=md-ellipsis> Chrf </span> </a> </li> <li class=md-nav__item> <a href=#cider class=md-nav__link> <span class=md-ellipsis> Cider </span> </a> </li> <li class=md-nav__item> <a href=#codebleu class=md-nav__link> <span class=md-ellipsis> Codebleu </span> </a> </li> <li class=md-nav__item> <a href=#conll class=md-nav__link> <span class=md-ellipsis> Conll </span> </a> </li> <li class=md-nav__item> <a href=#coval class=md-nav__link> <span class=md-ellipsis> Coval </span> </a> </li> <li class=md-nav__item> <a href=#cver class=md-nav__link> <span class=md-ellipsis> Cver </span> </a> </li> <li class=md-nav__item> <a href=#der class=md-nav__link> <span class=md-ellipsis> DER </span> </a> </li> <li class=md-nav__item> <a href=#bialog-acts-accuracy class=md-nav__link> <span class=md-ellipsis> Bialog acts accuracy </span> </a> </li> <li class=md-nav__item> <a href=#dialog-acts-f1 class=md-nav__link> <span class=md-ellipsis> Dialog acts f1 </span> </a> </li> <li class=md-nav__item> <a href=#diffbleu class=md-nav__link> <span class=md-ellipsis> Diffbleu </span> </a> </li> <li class=md-nav__item> <a href=#dvitelcodebleu class=md-nav__link> <span class=md-ellipsis> Dvitel/codebleu </span> </a> </li> <li class=md-nav__item> <a href=#eer class=md-nav__link> <span class=md-ellipsis> EER </span> </a> </li> <li class=md-nav__item> <a href=#em class=md-nav__link> <span class=md-ellipsis> EM </span> </a> </li> <li class=md-nav__item> <a href=#empos class=md-nav__link> <span class=md-ellipsis> Empos </span> </a> </li> <li class=md-nav__item> <a href=#fid class=md-nav__link> <span class=md-ellipsis> FID </span> </a> </li> <li class=md-nav__item> <a href=#hamming-score class=md-nav__link> <span class=md-ellipsis> Hamming score </span> </a> </li> <li class=md-nav__item> <a href=#jaccard-error-rate class=md-nav__link> <span class=md-ellipsis> Jaccard error rate </span> </a> </li> <li class=md-nav__item> <a href=#lambada class=md-nav__link> <span class=md-ellipsis> Lambada </span> </a> </li> <li class=md-nav__item> <a href=#language-model-loss class=md-nav__link> <span class=md-ellipsis> Language model loss </span> </a> </li> <li class=md-nav__item> <a href=#las class=md-nav__link> <span class=md-ellipsis> LAS </span> </a> </li> <li class=md-nav__item> <a href=#loss class=md-nav__link> <span class=md-ellipsis> Loss </span> </a> </li> <li class=md-nav__item> <a href=#mer class=md-nav__link> <span class=md-ellipsis> MER </span> </a> </li> <li class=md-nav__item> <a href=#mmlu class=md-nav__link> <span class=md-ellipsis> MMLU </span> </a> </li> <li class=md-nav__item> <a href=#nuclearity class=md-nav__link> <span class=md-ellipsis> Nuclearity </span> </a> </li> <li class=md-nav__item> <a href=#ovrl class=md-nav__link> <span class=md-ellipsis> OVRL </span> </a> </li> <li class=md-nav__item> <a href=#per class=md-nav__link> <span class=md-ellipsis> PER </span> </a> </li> <li class=md-nav__item> <a href=#perplexity_2 class=md-nav__link> <span class=md-ellipsis> Perplexity </span> </a> </li> <li class=md-nav__item> <a href=#pesq class=md-nav__link> <span class=md-ellipsis> PESQ </span> </a> </li> <li class=md-nav__item> <a href=#ppl class=md-nav__link> <span class=md-ellipsis> PPL </span> </a> </li> <li class=md-nav__item> <a href=#qwk class=md-nav__link> <span class=md-ellipsis> QWK </span> </a> </li> <li class=md-nav__item> <a href=#re-macro-f1 class=md-nav__link> <span class=md-ellipsis> RE+ macro f1 </span> </a> </li> <li class=md-nav__item> <a href=#roc-auc class=md-nav__link> <span class=md-ellipsis> ROC AUC </span> </a> </li> <li class=md-nav__item> <a href=#sacrebleu class=md-nav__link> <span class=md-ellipsis> Sacrebleu </span> </a> </li> <li class=md-nav__item> <a href=#sari class=md-nav__link> <span class=md-ellipsis> Sari </span> </a> </li> <li class=md-nav__item> <a href=#ser class=md-nav__link> <span class=md-ellipsis> SER </span> </a> </li> <li class=md-nav__item> <a href=#si-sdri class=md-nav__link> <span class=md-ellipsis> Si-sdri </span> </a> </li> <li class=md-nav__item> <a href=#si-snri class=md-nav__link> <span class=md-ellipsis> Si-snri </span> </a> </li> <li class=md-nav__item> <a href=#sig class=md-nav__link> <span class=md-ellipsis> SIG </span> </a> </li> <li class=md-nav__item> <a href=#slot-error-rate class=md-nav__link> <span class=md-ellipsis> Slot error rate </span> </a> </li> <li class=md-nav__item> <a href=#slot-f1 class=md-nav__link> <span class=md-ellipsis> Slot f1 </span> </a> </li> <li class=md-nav__item> <a href=#span class=md-nav__link> <span class=md-ellipsis> Span </span> </a> </li> <li class=md-nav__item> <a href=#spearmanr class=md-nav__link> <span class=md-ellipsis> Spearmanr </span> </a> </li> <li class=md-nav__item> <a href=#spice class=md-nav__link> <span class=md-ellipsis> Spice </span> </a> </li> <li class=md-nav__item> <a href=#spider class=md-nav__link> <span class=md-ellipsis> Spider </span> </a> </li> <li class=md-nav__item> <a href=#hellaswag class=md-nav__link> <span class=md-ellipsis> HellaSwag </span> </a> </li> <li class=md-nav__item> <a href=#ter class=md-nav__link> <span class=md-ellipsis> TER </span> </a> </li> <li class=md-nav__item> <a href=#text-image-similarity class=md-nav__link> <span class=md-ellipsis> Text-image-similarity </span> </a> </li> <li class=md-nav__item> <a href=#training-loss class=md-nav__link> <span class=md-ellipsis> Training loss </span> </a> </li> <li class=md-nav__item> <a href=#trueskill class=md-nav__link> <span class=md-ellipsis> Trueskill </span> </a> </li> <li class=md-nav__item> <a href=#uas class=md-nav__link> <span class=md-ellipsis> UAS </span> </a> </li> <li class=md-nav__item> <a href=#wikitext class=md-nav__link> <span class=md-ellipsis> Wikitext </span> </a> </li> <li class=md-nav__item> <a href=#wil class=md-nav__link> <span class=md-ellipsis> WIL </span> </a> </li> <li class=md-nav__item> <a href=#wip class=md-nav__link> <span class=md-ellipsis> WIP </span> </a> </li> <li class=md-nav__item> <a href=#zero-shot-transfer class=md-nav__link> <span class=md-ellipsis> Zero-shot transfer </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <article class="md-content__inner md-typeset"> <p><img alt="Comprehensive Glossary of LLM" src=../assets/images/dspost/dsp6092-Machine-Learning-Metrics.jpg></p> <h1 id=machine-learning-metrics>Machine Learning Metrics<a class=headerlink href=#machine-learning-metrics title="Permanent link">&para;</a></h1> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">&para;</a></h2> <p>In Machine Learning projects whether classical machine learning, deep learning, computer vision, speech processing, NLP, or any other ML project we keep building different models with different datasets. But how to know that for a particular problem model X is the best one? For that, we need to evaluate these models against certain metrics. What metrics we pick, depends upon the problem statement, data imbalance, type of data, etc. In this article, we will explore an exhaustive list of ML Metrics.</p> <p>From various sources, benchmarking platforms, and research papers, I have noted 330+ metrics for evaluating Machine Learning models. I keep working on this page, expanding and defining these terms on a regular basis. Some of these metrics go over my head but I am keeping it here on this page because they have been used by the practitioners in some of their projects. After experimenting with those I will expand them here. Some of the metrics are obvious to Data Scientists. But, even if you are new to Data science it gives you an idea about these metrics.</p> <hr> <h2 id=mrr>MRR<a class=headerlink href=#mrr title="Permanent link">&para;</a></h2> <p>MRR stands for "Mean Reciprocal Rank," and it is a metric commonly used in information retrieval and evaluation tasks, including those in natural language processing (NLP). MRR is used to assess the effectiveness of ranking algorithms or systems in presenting relevant information to users. MRR is often applied to tasks such as question answering, search engines, and recommendation systems. A higher MRR indicates that relevant results tend to appear higher in the ranked lists, which suggests better user experience.</p> <p>Step1: Ranking of Results: Imagine you have a system that retrieves a list of possible answers or documents in response to a user's query or question. These results are usually ranked based on their perceived relevance to the query.</p> <p>Step2: Reciprocal Rank: For each query or question, the reciprocal rank of the first correct (relevant) result in the ranked list is calculated as 1 divided by the position of that correct result. If the correct result is the second item, the reciprocal rank would be &frac12;; if it's the fifth, the reciprocal rank would be &#8533;, and so on.</p> <p>Step3: Mean Reciprocal Rank (MRR): To calculate the MRR, you take the average of the reciprocal ranks across all queries or questions in your evaluation dataset. The formula for MRR is:</p> <p>MRR = (1/N) * ∑(1/rank_i)</p> <p>N is the total number of queries or questions. <br> rank_i is the position of the correct result for the i-th query.</p> <p>Commonly used MRR@n metrics are MRR@1, MRR@3, MRR@5, MRR@10, MRR@100, MRR@1000 </p> <hr> <h2 id=mapn>MAP@n<a class=headerlink href=#mapn title="Permanent link">&para;</a></h2> <p>MAP stands for "Mean Average Precision". MAP focuses on evaluating the effectiveness of ranking algorithms or systems</p> <p>Step1: Ranking of Results: You have a system that retrieves a ranked list of possible answers or documents in response to a user's query or question.</p> <p>Step2: Precision and Recall: Precision is the ratio of relevant items retrieved to the total number of items retrieved. Recall is the ratio of relevant items retrieved to the total number of relevant items in the dataset. These two metrics are often in tension with each other; increasing precision might result in lower recall and vice versa.</p> <p>Step3: Average Precision (AP) for Each Query: For each query or question, you calculate the precision at each position in the ranked list where a relevant item is retrieved. You then calculate the average of these precision values, resulting in the Average Precision (AP) for that query.</p> <p>Step4: Mean Average Precision (MAP): To calculate the MAP, you take the average of the Average Precision values across all queries or questions in your evaluation dataset. The formula for MAP is:</p> <p>MAP = (1/N) * ∑(AP_i) </p> <p>N is the total number of queries or questions. <br> AP_i is the Average Precision for the i-th query. </p> <p>Commonly used MAP@n metrics are map@1, map@3, map@5, map@10, map@100, map@1000</p> <h2 id=mean-average-precision-map>Mean average precision (mAP):<a class=headerlink href=#mean-average-precision-map title="Permanent link">&para;</a></h2> <p>A measure of the average precision over a range of IoU thresholds. It is also used in object detection and segmentation tasks.</p> <h2 id=mapiou-thresholds>mAP@IoU thresholds<a class=headerlink href=#mapiou-thresholds title="Permanent link">&para;</a></h2> <p>The mean average precision over a range of intersection over union (IoU) thresholds.</p> <hr> <h2 id=accuracy>Accuracy:<a class=headerlink href=#accuracy title="Permanent link">&para;</a></h2> <p>The percentage of test samples that are correctly classified.</p> <h3 id=acc_norm>acc_norm<a class=headerlink href=#acc_norm title="Permanent link">&para;</a></h3> <h3 id=accuracy_cardiffnlptweet_topic_multi>accuracy_cardiffnlp/tweet_topic_multi<a class=headerlink href=#accuracy_cardiffnlptweet_topic_multi title="Permanent link">&para;</a></h3> <h3 id=accuracy_cardiffnlptweet_topic_single>accuracy_cardiffnlp/tweet_topic_single<a class=headerlink href=#accuracy_cardiffnlptweet_topic_single title="Permanent link">&para;</a></h3> <h3 id=accuracy_cosinus>accuracy_cosinus<a class=headerlink href=#accuracy_cosinus title="Permanent link">&para;</a></h3> <h3 id=accuracy_euclidean>accuracy_euclidean<a class=headerlink href=#accuracy_euclidean title="Permanent link">&para;</a></h3> <h3 id=accuracy_manhattan>accuracy_manhattan<a class=headerlink href=#accuracy_manhattan title="Permanent link">&para;</a></h3> <h3 id=accuracy_tweet_evalemoji>accuracy_tweet_eval/emoji<a class=headerlink href=#accuracy_tweet_evalemoji title="Permanent link">&para;</a></h3> <h3 id=accuracy_tweet_evalemotion>accuracy_tweet_eval/emotion<a class=headerlink href=#accuracy_tweet_evalemotion title="Permanent link">&para;</a></h3> <h3 id=accuracy_tweet_evalhate>accuracy_tweet_eval/hate<a class=headerlink href=#accuracy_tweet_evalhate title="Permanent link">&para;</a></h3> <h3 id=accuracy_tweet_evalirony>accuracy_tweet_eval/irony<a class=headerlink href=#accuracy_tweet_evalirony title="Permanent link">&para;</a></h3> <h3 id=accuracy_tweet_evaloffensive>accuracy_tweet_eval/offensive<a class=headerlink href=#accuracy_tweet_evaloffensive title="Permanent link">&para;</a></h3> <h3 id=accuracy_tweet_evalsentiment>accuracy_tweet_eval/sentiment<a class=headerlink href=#accuracy_tweet_evalsentiment title="Permanent link">&para;</a></h3> <hr> <h2 id=precision>Precision:<a class=headerlink href=#precision title="Permanent link">&para;</a></h2> <p>The fraction of predicted positive samples that are actually positive.</p> <h3 id=precision_entity_span>precision_entity_span<a class=headerlink href=#precision_entity_span title="Permanent link">&para;</a></h3> <h3 id=precisionn>Precision@n<a class=headerlink href=#precisionn title="Permanent link">&para;</a></h3> <p>Commonly used precision@n metrics are Recall@1, Precision@3, Precision@5, Precision@10, Precision@100, Precision@1000</p> <h3 id=precision_macro>precision_macro<a class=headerlink href=#precision_macro title="Permanent link">&para;</a></h3> <hr> <h2 id=recall>Recall:<a class=headerlink href=#recall title="Permanent link">&para;</a></h2> <p>The fraction of actual positive samples that are predicted positive.</p> <h3 id=recall_entity_span>recall_entity_span<a class=headerlink href=#recall_entity_span title="Permanent link">&para;</a></h3> <h3 id=recalln>recall@n<a class=headerlink href=#recalln title="Permanent link">&para;</a></h3> <p>Commonly used recall@n metrics are recall@1, recall@3, recall@5, recall@10, recall@100, recall@1000</p> <h3 id=recall_macro>recall_macro<a class=headerlink href=#recall_macro title="Permanent link">&para;</a></h3> <hr> <h2 id=rp>R@P<a class=headerlink href=#rp title="Permanent link">&para;</a></h2> <p>"R@P" stands for "Recall at Precision." It's a metric used to evaluate the performance of information retrieval systems, such as search engines or question-answering models, in terms of their ability to retrieve relevant documents or answers.</p> <p>R@P is a combination of recall and precision. It evaluates how well a system can maintain a specified precision level while retrieving relevant items. It's typically expressed as "R@X," where "X" represents the desired precision level.</p> <p>For example, R@5 measures the recall when precision is equal to 0.5 (50%). It calculates the percentage of relevant items retrieved when the system is limited to a precision level of 50%.</p> <p>Mathematically, R@X is calculated by finding the recall at the point where precision reaches the specified level X. This is done by examining the retrieved items in descending order of relevance until the desired precision level is achieved.</p> <p>R@P is a useful metric in tasks where both recall (finding all relevant items) and precision (avoiding irrelevant items) are important. It provides insights into how well a system balances these two aspects when retrieving information.</p> <h3 id=rp50>R@P=50<a class=headerlink href=#rp50 title="Permanent link">&para;</a></h3> <h3 id=rp75>R@P=75<a class=headerlink href=#rp75 title="Permanent link">&para;</a></h3> <h3 id=rp90>R@P=90<a class=headerlink href=#rp90 title="Permanent link">&para;</a></h3> <hr> <h2 id=f1-score>F1 score:<a class=headerlink href=#f1-score title="Permanent link">&para;</a></h2> <p>The harmonic mean of precision and recall.</p> <h3 id=f1_entity_span>f1_entity_span<a class=headerlink href=#f1_entity_span title="Permanent link">&para;</a></h3> <h3 id=f1_macro>f1_macro<a class=headerlink href=#f1_macro title="Permanent link">&para;</a></h3> <h3 id=f1_micro>f1_micro<a class=headerlink href=#f1_micro title="Permanent link">&para;</a></h3> <h3 id=f1_weighted>f1_weighted<a class=headerlink href=#f1_weighted title="Permanent link">&para;</a></h3> <h3 id=f1-seqeval>f1 (seqeval)<a class=headerlink href=#f1-seqeval title="Permanent link">&para;</a></h3> <h3 id=f1-macro>f1 macro<a class=headerlink href=#f1-macro title="Permanent link">&para;</a></h3> <h3 id=f1m>f1<a class="magiclink magiclink-github magiclink-mention" href=https://github.com/m title="GitHub User: m">@m</a><a class=headerlink href=#f1m title="Permanent link">&para;</a></h3> <h3 id=f1m-absent>f1<a class="magiclink magiclink-github magiclink-mention" href=https://github.com/m title="GitHub User: m">@m</a> (absent)<a class=headerlink href=#f1m-absent title="Permanent link">&para;</a></h3> <h3 id=f1m-present>f1<a class="magiclink magiclink-github magiclink-mention" href=https://github.com/m title="GitHub User: m">@m</a> (present)<a class=headerlink href=#f1m-present title="Permanent link">&para;</a></h3> <h3 id=f1o-absent>f1<a class="magiclink magiclink-github magiclink-mention" href=https://github.com/o title="GitHub User: o">@o</a> (absent)<a class=headerlink href=#f1o-absent title="Permanent link">&para;</a></h3> <h3 id=f1o-present>f1<a class="magiclink magiclink-github magiclink-mention" href=https://github.com/o title="GitHub User: o">@o</a> (present)<a class=headerlink href=#f1o-present title="Permanent link">&para;</a></h3> <h3 id=f1neg>f1neg<a class=headerlink href=#f1neg title="Permanent link">&para;</a></h3> <h3 id=f1pos>f1pos<a class=headerlink href=#f1pos title="Permanent link">&para;</a></h3> <hr> <h2 id=hitn>Hit@n<a class=headerlink href=#hitn title="Permanent link">&para;</a></h2> <h3 id=hit1>Hit@1:<a class=headerlink href=#hit1 title="Permanent link">&para;</a></h3> <ul> <li>The percentage of queries for which the correct document is ranked first.</li> <li>The percentage of images for which the correct class is in the top k predictions. It is also used in image classification tasks.</li> </ul> <h3 id=hit5>Hit@5:<a class=headerlink href=#hit5 title="Permanent link">&para;</a></h3> <p>The percentage of queries for which the correct document is ranked among the top 5 documents.</p> <hr> <h2 id=log-loss>Log-loss:<a class=headerlink href=#log-loss title="Permanent link">&para;</a></h2> <p>The negative log likelihood of the predicted labels.</p> <h2 id=brier-score>Brier score:<a class=headerlink href=#brier-score title="Permanent link">&para;</a></h2> <p>The mean squared difference between the predicted probabilities and the actual labels.</p> <h2 id=confusion-matrix>Confusion matrix:<a class=headerlink href=#confusion-matrix title="Permanent link">&para;</a></h2> <p>A table that shows the true and predicted labels for each class.</p> <h2 id=mse>MSE<a class=headerlink href=#mse title="Permanent link">&para;</a></h2> <h2 id=root-mean-squared-error-rmse>Root mean squared error (RMSE):<a class=headerlink href=#root-mean-squared-error-rmse title="Permanent link">&para;</a></h2> <p>A measure of the average squared difference between the predicted and actual values.</p> <h2 id=mean-absolute-error-mae>Mean absolute error (MAE):<a class=headerlink href=#mean-absolute-error-mae title="Permanent link">&para;</a></h2> <p>A measure of the average absolute difference between the predicted and actual values.</p> <h2 id=r-squared>R-squared:<a class=headerlink href=#r-squared title="Permanent link">&para;</a></h2> <p>A measure of the proportion of the variance in the target variable that is explained by the model.</p> <h2 id=cohens-kappa>Cohen's kappa:<a class=headerlink href=#cohens-kappa title="Permanent link">&para;</a></h2> <p>A measure of agreement between two raters, taking into account chance agreement.</p> <h2 id=matthews-correlation-coefficient-mcc>Matthews correlation coefficient (MCC):<a class=headerlink href=#matthews-correlation-coefficient-mcc title="Permanent link">&para;</a></h2> <p>A measure of the accuracy of a binary classifier that takes into account both the true positive rate and the false positive rate.</p> <h2 id=area-under-the-curve-auc>Area under the curve (AUC):<a class=headerlink href=#area-under-the-curve-auc title="Permanent link">&para;</a></h2> <p>A measure of the performance of a binary classifier at all possible thresholds.</p> <h2 id=precision-recall-curve>Precision-recall curve:<a class=headerlink href=#precision-recall-curve title="Permanent link">&para;</a></h2> <p>A graphical representation of the precision and recall of a binary classifier at all possible thresholds.</p> <h2 id=roc-curve>ROC curve:<a class=headerlink href=#roc-curve title="Permanent link">&para;</a></h2> <p>A graphical representation of the true positive rate and the false positive rate of a binary classifier at all possible thresholds.</p> <h2 id=mean-squared-logarithmic-error-msle>Mean squared logarithmic error (MSLE):<a class=headerlink href=#mean-squared-logarithmic-error-msle title="Permanent link">&para;</a></h2> <p>A measure of the average squared difference between the logarithms of the predicted and actual values.</p> <h2 id=mean-absolute-percentage-error-mape>Mean absolute percentage error (MAPE):<a class=headerlink href=#mean-absolute-percentage-error-mape title="Permanent link">&para;</a></h2> <p>A measure of the average percentage difference between the predicted and actual values.</p> <h2 id=root-mean-square-logarithmic-error-rmsle>Root mean square logarithmic error (RMSLE):<a class=headerlink href=#root-mean-square-logarithmic-error-rmsle title="Permanent link">&para;</a></h2> <p>A measure of the average squared difference between the logarithms of the predicted and actual values, after taking the square root.</p> <h2 id=precision-at-k-pk>Precision at k (P@k):<a class=headerlink href=#precision-at-k-pk title="Permanent link">&para;</a></h2> <p>The percentage of the top k predictions that are correct.</p> <p>The percentage of predicted positive samples that are ranked among the top k predictions. <br> Precision@k = (# of relevant items retrieved among top-k recommendations) / (# of total predicted relevant items)</p> <p>For example, if a system retrieves 5 relevant items among the top-10 recommendations out of a total of 25 predicted relevant items, then the recall@10 would be 0.20 or 20%.</p> <p>In other words, precision@k measures how well the system performs in predicting relevant items among the top-k recommendations. It is useful when we are interested in evaluating the ranking quality of recommendations rather than their absolute number.</p> <h2 id=recall-at-k-rk>Recall at k (R@k):<a class=headerlink href=#recall-at-k-rk title="Permanent link">&para;</a></h2> <p>The percentage of actual positive samples that are ranked among the top k predictions. <br> Recall@k = (# of relevant items retrieved among top-k recommendations) / (# of total relevant items)</p> <p>For example, if a system retrieves 5 relevant items among the top-10 recommendations out of a total of 20 relevant items, then the recall@10 would be 0.25 or 25%.</p> <p>In other words, recall@k measures how well the system performs in retrieving relevant items among the top-k recommendations. It is useful when we are interested in evaluating the ranking quality of recommendations rather than their absolute number.</p> <h2 id=f1-score-at-k-f1k>F1-score at k (F1<a class="magiclink magiclink-github magiclink-mention" href=https://github.com/k title="GitHub User: k">@k</a>):<a class=headerlink href=#f1-score-at-k-f1k title="Permanent link">&para;</a></h2> <p>The harmonic mean of precision at k and recall at k.</p> <h2 id=interpretability>Interpretability:<a class=headerlink href=#interpretability title="Permanent link">&para;</a></h2> <p>A measure of how easy it is to understand and explain the predictions of a model.</p> <h2 id=fairness>Fairness:<a class=headerlink href=#fairness title="Permanent link">&para;</a></h2> <p>A measure of how the model treats different groups of people.</p> <h2 id=inception-score>Inception score:<a class=headerlink href=#inception-score title="Permanent link">&para;</a></h2> <p>A measure of the diversity and quality of the generated images by a generative adversarial network (GAN).</p> <h2 id=frechet-inception-distance>Frechet Inception distance:<a class=headerlink href=#frechet-inception-distance title="Permanent link">&para;</a></h2> <p>A measure of the similarity between the generated images by a GAN and the real images.</p> <h2 id=wasserstein-distance>Wasserstein distance:<a class=headerlink href=#wasserstein-distance title="Permanent link">&para;</a></h2> <p>A measure of the distance between the distributions of the generated images and the real images.</p> <h2 id=inception-score_1>Inception score:<a class=headerlink href=#inception-score_1 title="Permanent link">&para;</a></h2> <p>A measure of the diversity and quality of the generated text by a language model.</p> <h2 id=perplexity>Perplexity:<a class=headerlink href=#perplexity title="Permanent link">&para;</a></h2> <p>A measure of how difficult it is to predict the next word in a sequence.</p> <hr> <h2 id=bleu-score>BLEU score:<a class=headerlink href=#bleu-score title="Permanent link">&para;</a></h2> <p>A measure of the similarity between the generated text and the reference text. <a href=/dsblog/ml-tasks-and-model-evaluation#what-is-blue-benchmark>BLEU More..</a></p> <h3 id=bleu4>BLEU4<a class=headerlink href=#bleu4 title="Permanent link">&para;</a></h3> <h3 id=bleu4_answer_extraction>BLEU4_answer_extraction<a class=headerlink href=#bleu4_answer_extraction title="Permanent link">&para;</a></h3> <h3 id=bleu4_question_answer_generation>BLEU4_question_answer_generation<a class=headerlink href=#bleu4_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=bleu4_question_answering>BLEU4_question_answering<a class=headerlink href=#bleu4_question_answering title="Permanent link">&para;</a></h3> <h3 id=bleu4_question_generation>BLEU4_question_generation<a class=headerlink href=#bleu4_question_generation title="Permanent link">&para;</a></h3> <hr> <h2 id=intersection-over-union-iou>Intersection over union (IoU):<a class=headerlink href=#intersection-over-union-iou title="Permanent link">&para;</a></h2> <p>A measure of the overlap between two regions. It is typically used in object detection and segmentation tasks.</p> <h2 id=top-5-error-rate>Top-5 error rate:<a class=headerlink href=#top-5-error-rate title="Permanent link">&para;</a></h2> <p>The percentage of images for which the correct class is not in the top 5 predictions. It is typically used in image classification tasks.</p> <h2 id=em-exact-match>EM - Exact Match<a class=headerlink href=#em-exact-match title="Permanent link">&para;</a></h2> <p>EM used in NLP task evaluation, particularly in tasks like question answering and text generation. The EM metric measures the percentage of predictions that exactly match the ground truth or reference answers.</p> <p>If the model's answer matches the reference answer word-for-word, then the EM score for that particular instance is 1. If the answers do not match exactly, the EM score is 0. The EM score is then calculated as the ratio of instances where the model's answer matches the reference answer exactly to the total number of instances in the evaluation dataset.</p> <hr> <h2 id=rouge>ROUGE<a class=headerlink href=#rouge title="Permanent link">&para;</a></h2> <p>ROUGE (Recall-Oriented Understudy for Gisting Evaluation): ROUGE is another metric used for evaluating text summarization and generation tasks. It measures the overlap of n-grams between the generated text and the reference text. <a href=/dsblog/ml-tasks-and-model-evaluation#what-is-rouge-score>ROUGE More..</a></p> <h3 id=rouge-l>rouge-l<a class=headerlink href=#rouge-l title="Permanent link">&para;</a></h3> <h3 id=rouge-2>rouge-2<a class=headerlink href=#rouge-2 title="Permanent link">&para;</a></h3> <h3 id=rouge-lsum>rouge-lsum<a class=headerlink href=#rouge-lsum title="Permanent link">&para;</a></h3> <h3 id=rouge_l_answer_extraction>rouge_l_answer_extraction<a class=headerlink href=#rouge_l_answer_extraction title="Permanent link">&para;</a></h3> <h3 id=rouge_l_question_answer_generation>rouge_l_question_answer_generation<a class=headerlink href=#rouge_l_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=rouge_l_question_answering>rouge_l_question_answering<a class=headerlink href=#rouge_l_question_answering title="Permanent link">&para;</a></h3> <h3 id=rouge_l_question_generation>rouge_l_question_generation<a class=headerlink href=#rouge_l_question_generation title="Permanent link">&para;</a></h3> <hr> <h2 id=meteor>METEOR<a class=headerlink href=#meteor title="Permanent link">&para;</a></h2> <p>Metric for Evaluation of Translation with Explicit ORdering: METEOR is a metric that combines multiple measures including precision, recall, stemming, and synonymy. It aims to provide a balanced evaluation of machine translation quality.<a href=/dsblog/ml-tasks-and-model-evaluation#what-is-meteor-score>METEOR More..</a></p> <h3 id=meteor_answer_extraction>meteor_answer_extraction<a class=headerlink href=#meteor_answer_extraction title="Permanent link">&para;</a></h3> <h3 id=meteor_question_answer_generation>meteor_question_answer_generation<a class=headerlink href=#meteor_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=meteor_question_answering>meteor_question_answering<a class=headerlink href=#meteor_question_answering title="Permanent link">&para;</a></h3> <h3 id=meteor_question_generation>meteor_question_generation<a class=headerlink href=#meteor_question_generation title="Permanent link">&para;</a></h3> <h2 id=heqd>HEQD<a class=headerlink href=#heqd title="Permanent link">&para;</a></h2> <p>HEQD stands for Hierarchical Edit Distance. It is a metric used to evaluate the quality of text summarization. It is based on the edit distance between the ground truth summary and the generated summary, taking into account the hierarchical structure of the summary.</p> <p>The HEQD metric is calculated as follows:</p> <p>HEQD = 1 - (ED / L) where</p> <p>ED is the edit distance between the ground truth summary and the generated summary.<br> L is the length of the ground truth summary.<br> The HEQD metric is a more accurate measure of the quality of text summarization than the BLEU metric, as it takes into account the hierarchical structure of the summary. </p> <p>Example:</p> <p>Ground truth summary:</p> <ul> <li>The cat is on the mat.</li> <li>The dog is chasing the ball.</li> </ul> <p>Generated summary:</p> <ul> <li>The cat and the dog are playing.</li> </ul> <p>The HEQD metric for this example would be:</p> <p>HEQD = 1 - (2 / 2) = 0.5</p> <p>This means that the generated summary is 50% similar to the ground truth summary.</p> <p>The HEQD metric is a relatively new metric, and it is not yet as widely used as the BLEU metric. However, it is a promising metric for evaluating the quality of text summarization.</p> <h2 id=perplexity_1>Perplexity<a class=headerlink href=#perplexity_1 title="Permanent link">&para;</a></h2> <p>In NLP and machine learning, perplexity is a measure of how well a language model predicts the next word in a sequence. It is calculated as the inverse of the probability of the model's predictions. A lower perplexity indicates that the model is better at predicting the next word.</p> <p>The perplexity is calculated as follows:</p> <p>Perplexity = <span class=arithmatex>\(<span class=arithmatex>\(exp( \frac{-1}{N * \sum(log(p(w_i)))})\)</span>\)</span> <br> where</p> <p>N is the number of words in the test set. <br> <span class=arithmatex>\(<span class=arithmatex>\(w_i\)</span>\)</span> is the i-th word in the test set. <br> <span class=arithmatex>\(<span class=arithmatex>\(p(w_i)\)</span>\)</span> is the probability of the model predicting word <span class=arithmatex>\(<span class=arithmatex>\(w_i\)</span>\)</span>.</p> <p>The perplexity metric is a more robust measure of the quality of a language model than the accuracy metric. This is because the accuracy metric only measures how well the model predicts the correct word, while the perplexity metric also takes into account the probability of the model's predictions.</p> <p>Here is an example of how the perplexity metric can be used to evaluate the quality of a language model:</p> <p>Let's say we have a language model that is trained on a corpus of text. We want to evaluate the quality of the model by using the perplexity metric. We take a test set of text and calculate the perplexity of the model's predictions on the test set. If the perplexity is low, then the model is good at predicting the next word. If the perplexity is high, then the model is not good at predicting the next word.</p> <p>The perplexity metric is a useful tool for evaluating the quality of language models. It is a more robust measure of quality than the accuracy metric, and it can be used to compare the performance of different language models.</p> <hr> <h2 id=passn>Pass@n<a class=headerlink href=#passn title="Permanent link">&para;</a></h2> <p>The Pass@100 metric is calculated by measuring the percentage of queries for which the correct answer is among the top 100 candidates retrieved by the foundation language model (FLM) from a large corpus of documents. It reflects the ability of the FLM to retrieve relevant information from a large-scale knowledge source, which is essential for downstream tasks such as question answering, summarization, and dialogue. The higher the Pass@100 score, the better the FLM is at retrieving knowledge 1.</p> <p>If you are interested in calculating Pass@100 for your own data, you can use binomial distribution. The formula for calculating Pass@100 using binomial distribution is as follows:</p> <div class=arithmatex>\[P(X &gt;= k) = 1 - \sum_{i=0}^{k-1} [nCi * p^i * (1-p)^{n-i}]\]</div> <p>where X is a binomial random variable representing the number of correct answers in the top 100 candidates, n is the total number of queries, p is the probability of getting a correct answer in one query, and k is the minimum number of correct answers required to achieve Pass@100.</p> <p>Commonly used Pass@n metrics are pass@1, pass@10, Pass@100</p> <hr> <h2 id=answer-exact>Answer Exact<a class=headerlink href=#answer-exact title="Permanent link">&para;</a></h2> <h3 id=answer_exact_match_answer_extraction>answer_exact_match_answer_extraction<a class=headerlink href=#answer_exact_match_answer_extraction title="Permanent link">&para;</a></h3> <h3 id=answer_exact_match_question_answering>answer_exact_match_question_answering<a class=headerlink href=#answer_exact_match_question_answering title="Permanent link">&para;</a></h3> <hr> <h2 id=answer-f1>Answer F1<a class=headerlink href=#answer-f1 title="Permanent link">&para;</a></h2> <h3 id=answer_f1_score__answer_extraction>answer_f1_score__answer_extraction<a class=headerlink href=#answer_f1_score__answer_extraction title="Permanent link">&para;</a></h3> <h3 id=answer_f1_score__question_answering>answer_f1_score__question_answering<a class=headerlink href=#answer_f1_score__question_answering title="Permanent link">&para;</a></h3> <hr> <h2 id=bert-score>Bert Score<a class=headerlink href=#bert-score title="Permanent link">&para;</a></h2> <h3 id=bertscore>bertscore<a class=headerlink href=#bertscore title="Permanent link">&para;</a></h3> <h3 id=bertscore_answer_extraction>bertscore_answer_extraction<a class=headerlink href=#bertscore_answer_extraction title="Permanent link">&para;</a></h3> <h3 id=bertscore_question_answer_generation>bertscore_question_answer_generation<a class=headerlink href=#bertscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=bertscore_question_answering>bertscore_question_answering<a class=headerlink href=#bertscore_question_answering title="Permanent link">&para;</a></h3> <h3 id=bertscore_question_generation>bertscore_question_generation<a class=headerlink href=#bertscore_question_generation title="Permanent link">&para;</a></h3> <hr> <h2 id=code>Code<a class=headerlink href=#code title="Permanent link">&para;</a></h2> <h3 id=code_eval>code_eval<a class=headerlink href=#code_eval title="Permanent link">&para;</a></h3> <h3 id=code_eval_outputs>code_eval_outputs<a class=headerlink href=#code_eval_outputs title="Permanent link">&para;</a></h3> <hr> <h2 id=cosine>Cosine<a class=headerlink href=#cosine title="Permanent link">&para;</a></h2> <h3 id=cos_sim_accuracy>cos_sim_accuracy<a class=headerlink href=#cos_sim_accuracy title="Permanent link">&para;</a></h3> <p><div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>threshold = 0.9  # Define your threshold
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a>true_positives = 0
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>false_positives = 0
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>false_negatives = 0
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>for question in questions:
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>    predicted_answer = model.predict(question)
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>    reference_answer = get_reference_answer(question)
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a>    cosine_similarity = calculate_cosine_similarity(predicted_answer, reference_answer)
</span><span id=__span-0-12><a id=__codelineno-0-12 name=__codelineno-0-12 href=#__codelineno-0-12></a>
</span><span id=__span-0-13><a id=__codelineno-0-13 name=__codelineno-0-13 href=#__codelineno-0-13></a>    if cosine_similarity &gt;= threshold:
</span><span id=__span-0-14><a id=__codelineno-0-14 name=__codelineno-0-14 href=#__codelineno-0-14></a>        if predicted_answer == reference_answer:
</span><span id=__span-0-15><a id=__codelineno-0-15 name=__codelineno-0-15 href=#__codelineno-0-15></a>            true_positives += 1
</span><span id=__span-0-16><a id=__codelineno-0-16 name=__codelineno-0-16 href=#__codelineno-0-16></a>        else:
</span><span id=__span-0-17><a id=__codelineno-0-17 name=__codelineno-0-17 href=#__codelineno-0-17></a>            false_positives += 1
</span><span id=__span-0-18><a id=__codelineno-0-18 name=__codelineno-0-18 href=#__codelineno-0-18></a>    else:
</span><span id=__span-0-19><a id=__codelineno-0-19 name=__codelineno-0-19 href=#__codelineno-0-19></a>        if predicted_answer == reference_answer:
</span><span id=__span-0-20><a id=__codelineno-0-20 name=__codelineno-0-20 href=#__codelineno-0-20></a>            true_negative += 1
</span><span id=__span-0-21><a id=__codelineno-0-21 name=__codelineno-0-21 href=#__codelineno-0-21></a>        else: 
</span><span id=__span-0-22><a id=__codelineno-0-22 name=__codelineno-0-22 href=#__codelineno-0-22></a>            false_negatives += 1 
</span><span id=__span-0-23><a id=__codelineno-0-23 name=__codelineno-0-23 href=#__codelineno-0-23></a>
</span><span id=__span-0-24><a id=__codelineno-0-24 name=__codelineno-0-24 href=#__codelineno-0-24></a>cos_sim_precision = true_positives / (true_positives + false_positives)
</span><span id=__span-0-25><a id=__codelineno-0-25 name=__codelineno-0-25 href=#__codelineno-0-25></a>cos_sim_recall = true_positives / (true_positives + false_negatives)
</span><span id=__span-0-26><a id=__codelineno-0-26 name=__codelineno-0-26 href=#__codelineno-0-26></a>cos_sim_accuracy = (true_positive + true_negative)/len(quetions)
</span><span id=__span-0-27><a id=__codelineno-0-27 name=__codelineno-0-27 href=#__codelineno-0-27></a>cos_sim_f1 = 2 * cos_sim_precision * cos_sim_recall / (cos_sim_precision +cos_sim_recall)
</span></code></pre></div> <strong>Example Data</strong> <br> Threshold : 0.65</p> <table> <thead> <tr> <th>Actual</th> <th>Predicted Cosine</th> <th>Pred&gt;Threshold</th> <th>Pred&gt;Threshold =Actual</th> <th>Prediction_Type</th> <th>Remark</th> </tr> </thead> <tbody> <tr> <td>TRUE</td> <td>0.98</td> <td>TRUE</td> <td>TRUE</td> <td>TP</td> <td>Pred Cosine&gt;=Threshold</td> </tr> <tr> <td>TRUE</td> <td>0.79</td> <td>TRUE</td> <td>TRUE</td> <td>TP</td> <td>Pred Cosine&gt;=Threshold</td> </tr> <tr> <td>FALSE</td> <td>0.7</td> <td>TRUE</td> <td>FALSE</td> <td>FP</td> <td>Pred Cosine&gt;=Threshold</td> </tr> <tr> <td>TRUE</td> <td>0.6</td> <td>FALSE</td> <td>FALSE</td> <td>TN</td> <td>Pred Cosine&lt;Threshold</td> </tr> <tr> <td>TRUE</td> <td>0.5</td> <td>FALSE</td> <td>FALSE</td> <td>TN</td> <td>Pred Cosine&lt;Threshold</td> </tr> <tr> <td>FALSE</td> <td>0.2</td> <td>FALSE</td> <td>TRUE</td> <td>FN</td> <td>Pred Cosine&lt;Threshold</td> </tr> <tr> <td>FALSE</td> <td>0.4</td> <td>FALSE</td> <td>TRUE</td> <td>FN</td> <td>Pred Cosine&lt;Threshold</td> </tr> <tr> <td>FALSE</td> <td>0.66</td> <td>TRUE</td> <td>FALSE</td> <td>FN</td> <td>Pred Cosine&lt;Threshold</td> </tr> </tbody> </table> <h3 id=cos_sim_f1>cos_sim_f1<a class=headerlink href=#cos_sim_f1 title="Permanent link">&para;</a></h3> <p>Check cos_sim_accuracy</p> <h3 id=cos_sim_precision>cos_sim_precision<a class=headerlink href=#cos_sim_precision title="Permanent link">&para;</a></h3> <p>Check cos_sim_accuracy</p> <h3 id=cos_sim_recall>cos_sim_recall<a class=headerlink href=#cos_sim_recall title="Permanent link">&para;</a></h3> <p>Check cos_sim_accuracy</p> <h3 id=cos_sim_ap>cos_sim_ap<a class=headerlink href=#cos_sim_ap title="Permanent link">&para;</a></h3> <h3 id=cos_sim_pearson>cos_sim_pearson<a class=headerlink href=#cos_sim_pearson title="Permanent link">&para;</a></h3> <h3 id=cos_sim_spearman>cos_sim_spearman<a class=headerlink href=#cos_sim_spearman title="Permanent link">&para;</a></h3> <hr> <h2 id=dot>Dot<a class=headerlink href=#dot title="Permanent link">&para;</a></h2> <h3 id=dot_accuracy>dot_accuracy<a class=headerlink href=#dot_accuracy title="Permanent link">&para;</a></h3> <h3 id=dot_ap>dot_ap<a class=headerlink href=#dot_ap title="Permanent link">&para;</a></h3> <h3 id=dot_f1>dot_f1<a class=headerlink href=#dot_f1 title="Permanent link">&para;</a></h3> <h3 id=dot_pearson>dot_pearson<a class=headerlink href=#dot_pearson title="Permanent link">&para;</a></h3> <h3 id=dot_precision>dot_precision<a class=headerlink href=#dot_precision title="Permanent link">&para;</a></h3> <h3 id=dot_recall>dot_recall<a class=headerlink href=#dot_recall title="Permanent link">&para;</a></h3> <h3 id=dot_spearman>dot_spearman<a class=headerlink href=#dot_spearman title="Permanent link">&para;</a></h3> <hr> <h2 id=euclidean>Euclidean<a class=headerlink href=#euclidean title="Permanent link">&para;</a></h2> <h3 id=euclidean_accuracy>euclidean_accuracy<a class=headerlink href=#euclidean_accuracy title="Permanent link">&para;</a></h3> <h3 id=euclidean_ap>euclidean_ap<a class=headerlink href=#euclidean_ap title="Permanent link">&para;</a></h3> <h3 id=euclidean_f1>euclidean_f1<a class=headerlink href=#euclidean_f1 title="Permanent link">&para;</a></h3> <h3 id=euclidean_pearson>euclidean_pearson<a class=headerlink href=#euclidean_pearson title="Permanent link">&para;</a></h3> <h3 id=euclidean_precision>euclidean_precision<a class=headerlink href=#euclidean_precision title="Permanent link">&para;</a></h3> <h3 id=euclidean_recall>euclidean_recall<a class=headerlink href=#euclidean_recall title="Permanent link">&para;</a></h3> <h3 id=euclidean_spearman>euclidean_spearman<a class=headerlink href=#euclidean_spearman title="Permanent link">&para;</a></h3> <hr> <h2 id=eval>Eval<a class=headerlink href=#eval title="Permanent link">&para;</a></h2> <h3 id=eval_accuracy>eval_accuracy<a class=headerlink href=#eval_accuracy title="Permanent link">&para;</a></h3> <h3 id=eval_exact>eval_exact<a class=headerlink href=#eval_exact title="Permanent link">&para;</a></h3> <h3 id=eval_f1>eval_f1<a class=headerlink href=#eval_f1 title="Permanent link">&para;</a></h3> <h3 id=eval_hasans_exact>eval_hasans_exact<a class=headerlink href=#eval_hasans_exact title="Permanent link">&para;</a></h3> <h3 id=eval_hasans_f1>eval_hasans_f1<a class=headerlink href=#eval_hasans_f1 title="Permanent link">&para;</a></h3> <h3 id=eval_noans_exact>eval_noans_exact<a class=headerlink href=#eval_noans_exact title="Permanent link">&para;</a></h3> <h3 id=eval_noans_f1>eval_noans_f1<a class=headerlink href=#eval_noans_f1 title="Permanent link">&para;</a></h3> <h3 id=eval_precision>eval_precision<a class=headerlink href=#eval_precision title="Permanent link">&para;</a></h3> <h3 id=eval_recall>eval_recall<a class=headerlink href=#eval_recall title="Permanent link">&para;</a></h3> <hr> <h2 id=exact>Exact<a class=headerlink href=#exact title="Permanent link">&para;</a></h2> <h3 id=exact_1>exact<a class=headerlink href=#exact_1 title="Permanent link">&para;</a></h3> <h3 id=exact_match>exact_match<a class=headerlink href=#exact_match title="Permanent link">&para;</a></h3> <hr> <h2 id=gen>Gen<a class=headerlink href=#gen title="Permanent link">&para;</a></h2> <h3 id=gen_len>gen_len<a class=headerlink href=#gen_len title="Permanent link">&para;</a></h3> <h3 id=gen-length>gen-length<a class=headerlink href=#gen-length title="Permanent link">&para;</a></h3> <hr> <h2 id=joint-goal-accuracy>Joint Goal Accuracy<a class=headerlink href=#joint-goal-accuracy title="Permanent link">&para;</a></h2> <h3 id=joint-goal-accuracy_1>joint goal accuracy<a class=headerlink href=#joint-goal-accuracy_1 title="Permanent link">&para;</a></h3> <h3 id=joint-goal-expected-calibration-error>joint goal expected calibration error<a class=headerlink href=#joint-goal-expected-calibration-error title="Permanent link">&para;</a></h3> <hr> <h2 id=manhattan>Manhattan<a class=headerlink href=#manhattan title="Permanent link">&para;</a></h2> <h3 id=manhattan_accuracy>manhattan_accuracy<a class=headerlink href=#manhattan_accuracy title="Permanent link">&para;</a></h3> <h3 id=manhattan_ap>manhattan_ap<a class=headerlink href=#manhattan_ap title="Permanent link">&para;</a></h3> <h3 id=manhattan_f1>manhattan_f1<a class=headerlink href=#manhattan_f1 title="Permanent link">&para;</a></h3> <h3 id=manhattan_precision>manhattan_precision<a class=headerlink href=#manhattan_precision title="Permanent link">&para;</a></h3> <h3 id=manhattan_recall>manhattan_recall<a class=headerlink href=#manhattan_recall title="Permanent link">&para;</a></h3> <h3 id=manhattan_spearman>manhattan_spearman<a class=headerlink href=#manhattan_spearman title="Permanent link">&para;</a></h3> <h3 id=manhattan_pearson>manhattan_pearson<a class=headerlink href=#manhattan_pearson title="Permanent link">&para;</a></h3> <hr> <h2 id=max>Max<a class=headerlink href=#max title="Permanent link">&para;</a></h2> <h3 id=max_accuracy>max_accuracy<a class=headerlink href=#max_accuracy title="Permanent link">&para;</a></h3> <h3 id=max_ap>max_ap<a class=headerlink href=#max_ap title="Permanent link">&para;</a></h3> <h3 id=max_f1>max_f1<a class=headerlink href=#max_f1 title="Permanent link">&para;</a></h3> <h2 id=mean>mean<a class=headerlink href=#mean title="Permanent link">&para;</a></h2> <h3 id=mean_reciprocal_rank>mean_reciprocal_rank<a class=headerlink href=#mean_reciprocal_rank title="Permanent link">&para;</a></h3> <h3 id=mean_reward>mean_reward<a class=headerlink href=#mean_reward title="Permanent link">&para;</a></h3> <hr> <h2 id=macro>Macro<a class=headerlink href=#macro title="Permanent link">&para;</a></h2> <h3 id=macro_f1>macro_f1<a class=headerlink href=#macro_f1 title="Permanent link">&para;</a></h3> <h3 id=macro_precision>macro_precision<a class=headerlink href=#macro_precision title="Permanent link">&para;</a></h3> <h3 id=macro_recall>macro_recall<a class=headerlink href=#macro_recall title="Permanent link">&para;</a></h3> <hr> <h2 id=micro>Micro<a class=headerlink href=#micro title="Permanent link">&para;</a></h2> <h3 id=micro_precision>micro_precision<a class=headerlink href=#micro_precision title="Permanent link">&para;</a></h3> <h3 id=micro_recall>micro_recall<a class=headerlink href=#micro_recall title="Permanent link">&para;</a></h3> <h3 id=micro_f1>micro_f1<a class=headerlink href=#micro_f1 title="Permanent link">&para;</a></h3> <h3 id=micro_f1_cardiffnlp>micro_f1_cardiffnlp<a class=headerlink href=#micro_f1_cardiffnlp title="Permanent link">&para;</a></h3> <h3 id=micro_f1_tweet_evalemoji>micro_f1_tweet_eval/emoji<a class=headerlink href=#micro_f1_tweet_evalemoji title="Permanent link">&para;</a></h3> <h3 id=micro_f1_tweet_evalemotion>micro_f1_tweet_eval/emotion<a class=headerlink href=#micro_f1_tweet_evalemotion title="Permanent link">&para;</a></h3> <h3 id=micro_f1_tweet_evalhate>micro_f1_tweet_eval/hate<a class=headerlink href=#micro_f1_tweet_evalhate title="Permanent link">&para;</a></h3> <h3 id=micro_f1_tweet_evalirony>micro_f1_tweet_eval/irony<a class=headerlink href=#micro_f1_tweet_evalirony title="Permanent link">&para;</a></h3> <h3 id=micro_f1_tweet_evaloffensive>micro_f1_tweet_eval/offensive<a class=headerlink href=#micro_f1_tweet_evaloffensive title="Permanent link">&para;</a></h3> <h3 id=micro_f1_tweet_evalsentiment>micro_f1_tweet_eval/sentiment<a class=headerlink href=#micro_f1_tweet_evalsentiment title="Permanent link">&para;</a></h3> <hr> <h2 id=mover-score>Mover Score<a class=headerlink href=#mover-score title="Permanent link">&para;</a></h2> <h3 id=moverscore_answer_extraction>moverscore_answer_extraction<a class=headerlink href=#moverscore_answer_extraction title="Permanent link">&para;</a></h3> <h3 id=moverscore_question_answer_generation>moverscore_question_answer_generation<a class=headerlink href=#moverscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=moverscore_question_answering>moverscore_question_answering<a class=headerlink href=#moverscore_question_answering title="Permanent link">&para;</a></h3> <h3 id=moverscore_question_generation>moverscore_question_generation<a class=headerlink href=#moverscore_question_generation title="Permanent link">&para;</a></h3> <hr> <h2 id=normalized-discounted-cumulative-gain-ndcg>Normalized discounted cumulative gain (NDCG):<a class=headerlink href=#normalized-discounted-cumulative-gain-ndcg title="Permanent link">&para;</a></h2> <p>NDCG (Normalized Discounted Cumulative Gain) is a widely used metric in information retrieval and recommendation systems to evaluate the quality of ranked search results or recommendations. The "NDCG@n" metric is a variation of NDCG that focuses on a specific cutoff point, n, which represents the number of items or documents to consider in the evaluation. It assesses how well the top n items or documents in a ranked list match the relevance of the ground truth or expected results.</p> <p>Here's how NDCG@n is calculated:</p> <ol> <li> <p><strong>Rank the Items or Documents</strong>: Start by ranking the items or documents based on some relevance score. For example, in a search engine, documents may be ranked based on their relevance to a user's query.</p> </li> <li> <p><strong>Determine Relevance Scores</strong>: Assign relevance scores to each of the items or documents. These scores typically range from 0 (not relevant) to 1 (perfectly relevant). These scores represent how relevant each item or document is to the user's query or the context of the evaluation.</p> </li> <li> <p><strong>Calculate DCG@n (Discounted Cumulative Gain at n)</strong>: Calculate the Discounted Cumulative Gain at the cutoff point n. DCG@n is computed as the sum of the relevance scores of the top n items, with a logarithmic discount applied to the position of each item:</p> </li> </ol> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>DCG@n = rel(1) + (rel(2) / log2(2)) + (rel(3) / log2(3)) + ... + (rel(n) / log2(n))
</span></code></pre></div> <p>Where: - <code>rel(i)</code> is the relevance score of the item at position i. - <code>log2(i)</code> is the logarithm base 2 of i.</p> <ol> <li> <p><strong>Calculate IDCG@n (Ideal Discounted Cumulative Gain at n)</strong>: Calculate the Ideal Discounted Cumulative Gain at the cutoff point n. IDCG@n represents the best possible DCG@n that could be achieved if all the items were perfectly ranked. To calculate IDCG@n, sort the items by their true relevance scores and calculate DCG@n using the same formula.</p> </li> <li> <p><strong>Calculate NDCG@n (Normalized Discounted Cumulative Gain at n)</strong>: Calculate NDCG@n by dividing DCG@n by IDCG@n:</p> </li> </ol> <div class="language-text highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>NDCG@n = DCG@n / IDCG@n
</span></code></pre></div> <p>NDCG@n provides a normalized measure of the quality of the ranked list at the specified cutoff point. It ranges from 0 to 1, where higher values indicate better ranking quality. A value of 1 indicates that the top n items are perfectly ranked according to relevance.</p> <p>NDCG@n is particularly useful when you want to assess the performance of recommendation systems, search engines, or any system that presents ranked lists to users, and you are interested in evaluating the quality of the top n results.</p> <p>Popular NDCG@n metrics are NDCG@1, NDCG@3, NDGC@5, NDGC@10, NDCG@100, NDCG@1000</p> <hr> <h2 id=pearson>Pearson<a class=headerlink href=#pearson title="Permanent link">&para;</a></h2> <h3 id=pearson_correlation>pearson_correlation<a class=headerlink href=#pearson_correlation title="Permanent link">&para;</a></h3> <h3 id=pearsons-r-distress>pearson's r (distress)<a class=headerlink href=#pearsons-r-distress title="Permanent link">&para;</a></h3> <h3 id=pearsons-r-empathy>pearson's r (empathy)<a class=headerlink href=#pearsons-r-empathy title="Permanent link">&para;</a></h3> <hr> <h2 id=qa-aligned-f1>QA Aligned F1<a class=headerlink href=#qa-aligned-f1 title="Permanent link">&para;</a></h2> <h3 id=qa_aligned_f1_score_bertscore_question_answer_generation>qa_aligned_f1_score_bertscore_question_answer_generation<a class=headerlink href=#qa_aligned_f1_score_bertscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer>qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer<a class=headerlink href=#qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer_gold_answer>qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer_gold_answer<a class=headerlink href=#qa_aligned_f1_score_bertscore_question_answer_generation_with_gold_answer_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_f1_score_moverscore_question_answer_generation>qa_aligned_f1_score_moverscore_question_answer_generation<a class=headerlink href=#qa_aligned_f1_score_moverscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_f1_score_moverscore_question_answer_generation_gold_answer>qa_aligned_f1_score_moverscore_question_answer_generation_gold_answer<a class=headerlink href=#qa_aligned_f1_score_moverscore_question_answer_generation_gold_answer title="Permanent link">&para;</a></h3> <hr> <h2 id=qa-aligned-precision>QA Aligned Precision<a class=headerlink href=#qa-aligned-precision title="Permanent link">&para;</a></h2> <h3 id=qa_aligned_precision_bertscore_question_answer_generation>qa_aligned_precision_bertscore_question_answer_generation<a class=headerlink href=#qa_aligned_precision_bertscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer>qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer<a class=headerlink href=#qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer_gold_answer>qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer_gold_answer<a class=headerlink href=#qa_aligned_precision_bertscore_question_answer_generation_with_gold_answer_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_precision_moverscore_question_answer_generation>qa_aligned_precision_moverscore_question_answer_generation<a class=headerlink href=#qa_aligned_precision_moverscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer>qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer<a class=headerlink href=#qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer_gold_answer>qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer_gold_answer<a class=headerlink href=#qa_aligned_precision_moverscore_question_answer_generation_with_gold_answer_gold_answer title="Permanent link">&para;</a></h3> <hr> <h2 id=qa-aligned-recall>QA Aligned Recall<a class=headerlink href=#qa-aligned-recall title="Permanent link">&para;</a></h2> <h3 id=qa_aligned_recall_bertscore_question_answer_generation>qa_aligned_recall_bertscore_question_answer_generation<a class=headerlink href=#qa_aligned_recall_bertscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer>qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer<a class=headerlink href=#qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer_gold_answer>qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer_gold_answer<a class=headerlink href=#qa_aligned_recall_bertscore_question_answer_generation_with_gold_answer_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_recall_moverscore_question_answer_generation>qa_aligned_recall_moverscore_question_answer_generation<a class=headerlink href=#qa_aligned_recall_moverscore_question_answer_generation title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer>qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer<a class=headerlink href=#qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer title="Permanent link">&para;</a></h3> <h3 id=qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer_gold_answer>qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer_gold_answer<a class=headerlink href=#qa_aligned_recall_moverscore_question_answer_generation_with_gold_answer_gold_answer title="Permanent link">&para;</a></h3> <hr> <h2 id=squad>SQUAD<a class=headerlink href=#squad title="Permanent link">&para;</a></h2> <h3 id=squad_1>squad<a class=headerlink href=#squad_1 title="Permanent link">&para;</a></h3> <h3 id=squad_v2>squad_v2<a class=headerlink href=#squad_v2 title="Permanent link">&para;</a></h3> <hr> <h2 id=top-n-accuracy>Top-n Accuracy<a class=headerlink href=#top-n-accuracy title="Permanent link">&para;</a></h2> <h3 id=top-1-accuracy>top-1 accuracy<a class=headerlink href=#top-1-accuracy title="Permanent link">&para;</a></h3> <h3 id=top-5-accuracy>top-5 accuracy<a class=headerlink href=#top-5-accuracy title="Permanent link">&para;</a></h3> <hr> <h2 id=validation>Validation<a class=headerlink href=#validation title="Permanent link">&para;</a></h2> <h3 id=validation_accuracy>validation_accuracy<a class=headerlink href=#validation_accuracy title="Permanent link">&para;</a></h3> <h3 id=validation-loss>validation loss<a class=headerlink href=#validation-loss title="Permanent link">&para;</a></h3> <hr> <h2 id=weighted>Weighted<a class=headerlink href=#weighted title="Permanent link">&para;</a></h2> <h3 id=weighted_f1>weighted_f1<a class=headerlink href=#weighted_f1 title="Permanent link">&para;</a></h3> <h3 id=weighted_precision>weighted_precision<a class=headerlink href=#weighted_precision title="Permanent link">&para;</a></h3> <h3 id=weighted_recall>weighted_recall<a class=headerlink href=#weighted_recall title="Permanent link">&para;</a></h3> <hr> <h2 id=wer>WER<a class=headerlink href=#wer title="Permanent link">&para;</a></h2> <h3 id=wer_without_norm>wer_without_norm<a class=headerlink href=#wer_without_norm title="Permanent link">&para;</a></h3> <hr> <h2 id=matthews>Matthews<a class=headerlink href=#matthews title="Permanent link">&para;</a></h2> <h3 id=matthews_correlation>matthews_correlation<a class=headerlink href=#matthews_correlation title="Permanent link">&para;</a></h3> <hr> <h2 id=accuracy-radius-1>Accuracy-radius-1<a class=headerlink href=#accuracy-radius-1 title="Permanent link">&para;</a></h2> <h2 id=act_dcf-p001>Act_dcf-p=0.01<a class=headerlink href=#act_dcf-p001 title="Permanent link">&para;</a></h2> <h2 id=avgrank>Avgrank<a class=headerlink href=#avgrank title="Permanent link">&para;</a></h2> <h2 id=arc>ARC<a class=headerlink href=#arc title="Permanent link">&para;</a></h2> <p>The <strong>Abstraction and Reasoning Corpus (ARC)</strong> is a benchmark dataset designed to encourage research in advanced question answering and measure a human-like form of general fluid intelligence. It was built upon an explicit set of priors designed to be as close as possible to innate human priors. The ARC dataset requires far more powerful knowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC question set is partitioned into a Challenge Set and an Easy Set, where the Challenge Set contains only questions answered incorrectly by both a retrieval-based algorithm and a word co-occurence algorithm. The dataset contains only natural, grade-school science questions (authored for human tests), and is the largest public-domain set of this kind (7,787 questions</p> <h2 id=byte_perplexity>Byte_perplexity<a class=headerlink href=#byte_perplexity title="Permanent link">&para;</a></h2> <h2 id=cer>CER<a class=headerlink href=#cer title="Permanent link">&para;</a></h2> <h2 id=cher>Cher<a class=headerlink href=#cher title="Permanent link">&para;</a></h2> <h2 id=chrf>Chrf<a class=headerlink href=#chrf title="Permanent link">&para;</a></h2> <h2 id=cider>Cider<a class=headerlink href=#cider title="Permanent link">&para;</a></h2> <h2 id=codebleu>Codebleu<a class=headerlink href=#codebleu title="Permanent link">&para;</a></h2> <h2 id=conll>Conll<a class=headerlink href=#conll title="Permanent link">&para;</a></h2> <h2 id=coval>Coval<a class=headerlink href=#coval title="Permanent link">&para;</a></h2> <h2 id=cver>Cver<a class=headerlink href=#cver title="Permanent link">&para;</a></h2> <h2 id=der>DER<a class=headerlink href=#der title="Permanent link">&para;</a></h2> <h2 id=bialog-acts-accuracy>Bialog acts accuracy<a class=headerlink href=#bialog-acts-accuracy title="Permanent link">&para;</a></h2> <h2 id=dialog-acts-f1>Dialog acts f1<a class=headerlink href=#dialog-acts-f1 title="Permanent link">&para;</a></h2> <h2 id=diffbleu>Diffbleu<a class=headerlink href=#diffbleu title="Permanent link">&para;</a></h2> <h2 id=dvitelcodebleu>Dvitel/codebleu<a class=headerlink href=#dvitelcodebleu title="Permanent link">&para;</a></h2> <h2 id=eer>EER<a class=headerlink href=#eer title="Permanent link">&para;</a></h2> <h2 id=em>EM<a class=headerlink href=#em title="Permanent link">&para;</a></h2> <h2 id=empos>Empos<a class=headerlink href=#empos title="Permanent link">&para;</a></h2> <h2 id=fid>FID<a class=headerlink href=#fid title="Permanent link">&para;</a></h2> <h2 id=hamming-score>Hamming score<a class=headerlink href=#hamming-score title="Permanent link">&para;</a></h2> <h2 id=jaccard-error-rate>Jaccard error rate<a class=headerlink href=#jaccard-error-rate title="Permanent link">&para;</a></h2> <h2 id=lambada>Lambada<a class=headerlink href=#lambada title="Permanent link">&para;</a></h2> <h2 id=language-model-loss>Language model loss<a class=headerlink href=#language-model-loss title="Permanent link">&para;</a></h2> <h2 id=las>LAS<a class=headerlink href=#las title="Permanent link">&para;</a></h2> <h2 id=loss>Loss<a class=headerlink href=#loss title="Permanent link">&para;</a></h2> <h2 id=mer>MER<a class=headerlink href=#mer title="Permanent link">&para;</a></h2> <h2 id=mmlu>MMLU<a class=headerlink href=#mmlu title="Permanent link">&para;</a></h2> <p>The MMLU metric, or Massive Multitask Language Understanding, is a benchmark for evaluating the general knowledge and reasoning capabilities of large language models (LLMs). It was developed by Meta AI and released in 2022.</p> <p>The MMLU dataset consists of 15,908 multiple-choice questions covering a wide range of topics, including mathematics, US history, computer science, law, and more. The questions are designed to assess the model's understanding of the world and its ability to reason about complex concepts. The test covers 57 tasks, including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem-solving ability </p> <p>The MMLU metric is calculated by averaging the model's accuracy on all of the questions in the dataset. This makes it a comprehensive measure of the model's overall performance.</p> <p>The MMLU metric has been used to evaluate a number of different LLMs, including GPT-3, Jurassic-1 Jumbo, and LaMDA. As of October 2023, the highest MMLU score achieved by a public LLM is 86.7%, which was set by GPT-4.</p> <p>The MMLU metric is an important tool for evaluating the progress of LLMs and for identifying areas where they need improvement. It is also a useful tool for comparing the performance of different LLMs.</p> <p>Here are some of the benefits of using the MMLU metric:</p> <ul> <li>It is a comprehensive measure of the model's overall performance on a wide range of tasks.</li> <li>It is fair and unbiased, as it uses a standardized set of questions.</li> <li>It is easy to understand and interpret.</li> <li>It is reproducible, meaning that other researchers can easily obtain the same results by evaluating their models on the same dataset.</li> </ul> <p>Overall, the MMLU metric is a valuable tool for evaluating the performance of LLMs and for tracking their progress over time.</p> <h2 id=nuclearity>Nuclearity<a class=headerlink href=#nuclearity title="Permanent link">&para;</a></h2> <h2 id=ovrl>OVRL<a class=headerlink href=#ovrl title="Permanent link">&para;</a></h2> <h2 id=per>PER<a class=headerlink href=#per title="Permanent link">&para;</a></h2> <h2 id=perplexity_2>Perplexity<a class=headerlink href=#perplexity_2 title="Permanent link">&para;</a></h2> <h2 id=pesq>PESQ<a class=headerlink href=#pesq title="Permanent link">&para;</a></h2> <h2 id=ppl>PPL<a class=headerlink href=#ppl title="Permanent link">&para;</a></h2> <h2 id=qwk>QWK<a class=headerlink href=#qwk title="Permanent link">&para;</a></h2> <h2 id=re-macro-f1>RE+ macro f1<a class=headerlink href=#re-macro-f1 title="Permanent link">&para;</a></h2> <h2 id=roc-auc>ROC AUC<a class=headerlink href=#roc-auc title="Permanent link">&para;</a></h2> <h2 id=sacrebleu>Sacrebleu<a class=headerlink href=#sacrebleu title="Permanent link">&para;</a></h2> <h2 id=sari>Sari<a class=headerlink href=#sari title="Permanent link">&para;</a></h2> <h2 id=ser>SER<a class=headerlink href=#ser title="Permanent link">&para;</a></h2> <h2 id=si-sdri>Si-sdri<a class=headerlink href=#si-sdri title="Permanent link">&para;</a></h2> <h2 id=si-snri>Si-snri<a class=headerlink href=#si-snri title="Permanent link">&para;</a></h2> <h2 id=sig>SIG<a class=headerlink href=#sig title="Permanent link">&para;</a></h2> <h2 id=slot-error-rate>Slot error rate<a class=headerlink href=#slot-error-rate title="Permanent link">&para;</a></h2> <h2 id=slot-f1>Slot f1<a class=headerlink href=#slot-f1 title="Permanent link">&para;</a></h2> <h2 id=span>Span<a class=headerlink href=#span title="Permanent link">&para;</a></h2> <h2 id=spearmanr>Spearmanr<a class=headerlink href=#spearmanr title="Permanent link">&para;</a></h2> <h2 id=spice>Spice<a class=headerlink href=#spice title="Permanent link">&para;</a></h2> <h2 id=spider>Spider<a class=headerlink href=#spider title="Permanent link">&para;</a></h2> <h2 id=hellaswag>HellaSwag<a class=headerlink href=#hellaswag title="Permanent link">&para;</a></h2> <p>HellaSwag is a dataset for studying grounded commonsense inference. It consists of <strong>70k multiple choice questions</strong> about grounded situations, each question comes from one of two domains -- activitynet or wikihow -- with four answer choices about what might happen next in the scene. The dataset was designed to test commonsense natural language inference (NLI) about physical situations. </p> <p>The name <strong>HellaSwag</strong> is an acronym for Harder Endings, Longer contexts, and Low-shot Activities for Situations With Adversarial Generations ¹. The dataset was created by Zellers et al. in 2019 to evaluate common-sense reasoning in large language models (LLMs) ¹. </p> <p>The dataset is used to measure the performance of LLMs on commonsense reasoning tasks. The questions are segments of video captions describing some event in the physical world. A video caption segment provides an initial context for an LLM. Each context is then followed by four options for completing that context, with only one option being correct.</p> <h2 id=ter>TER<a class=headerlink href=#ter title="Permanent link">&para;</a></h2> <h2 id=text-image-similarity>Text-image-similarity<a class=headerlink href=#text-image-similarity title="Permanent link">&para;</a></h2> <h2 id=training-loss>Training loss<a class=headerlink href=#training-loss title="Permanent link">&para;</a></h2> <h2 id=trueskill>Trueskill<a class=headerlink href=#trueskill title="Permanent link">&para;</a></h2> <h2 id=uas>UAS<a class=headerlink href=#uas title="Permanent link">&para;</a></h2> <h2 id=wikitext>Wikitext<a class=headerlink href=#wikitext title="Permanent link">&para;</a></h2> <h2 id=wil>WIL<a class=headerlink href=#wil title="Permanent link">&para;</a></h2> <h2 id=wip>WIP<a class=headerlink href=#wip title="Permanent link">&para;</a></h2> <h2 id=zero-shot-transfer>Zero-shot transfer<a class=headerlink href=#zero-shot-transfer title="Permanent link">&para;</a></h2> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link">&para;</a></h2> <ul> <li><a href=https://huggingface.co/spaces/autoevaluate/leaderboards>Metrics at Huggingface</a></li> <li><a href=https://paperswithcode.com/sota>SOTA Paperwithcode</a></li> <li><a href=https://paperswithcode.com/task/question-answering>Question Answering Paperwithcode</a></li> <li><a href=https://opus.nlpl.eu/leaderboard/ >BLEU Score</a></li> <li><a href=https://gluebenchmark.com/leaderboard>GLUE Score</a></li> <li><a href=https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard>Open LLM Leaderboard</a></li> <li><a href=https://leaderboard.allenai.org/ >AllanAI Leaderboards</a></li> <li><a href=https://ai.google.com/research/NaturalQuestions/leaderboard>AI Google - NaturalQuestions/leaderboard</a></li> <li><a href=https://eval.ai/web/challenges/challenge-page/514/leaderboard/1386>Eval AI</a></li> <li><a href=https://quac.ai/ >QuAC- Question Answering in Context</a></li> </ul> <p><strong>Author</strong> <br> Dr Hari Thapliyaal <br> dasarpai.com <br> linkedin.com/in/harithapliyal </p> <div class=author-bio style="margin-top: 2rem; display: flex; gap: 1rem;"> <img src=../assets/images/myphotos/Profilephoto1.jpg alt="Hari Thapliyaal" style="border-radius: 50%; width: 80px; height: 80px;"> <div> <strong>Dr. Hari Thapliyaal</strong><br> <small>Dr. Hari Thapliyal is a prolific blogger and seasoned professional with an extensive background in Data Science, Project Management, and Advait-Vedanta Philosophy. He holds a Doctorate in AI/NLP from SSBM, Geneva, along with Master’s degrees in Computers, Business Management, Data Science, and Economics. With over three decades of experience in management and leadership, Hari has extensive expertise in training, consulting, and coaching within the technology sector. His specializations include Data Science, AI, Computer Vision, NLP, and machine learning. Hari is also passionate about meditation and nature, often retreating to secluded places for reflection and peace.</small> </div> </div> <div class=share-buttons style="margin-top: 2rem;"> <strong>Share this article:</strong><br> <a href="https://twitter.com/intent/tweet?text=Machine%20Learning%20Metrics&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Machine-Learning-Metrics.html" target=_blank>Twitter</a> | <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Machine-Learning-Metrics.html" target=_blank>Facebook</a> | <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Machine-Learning-Metrics.html" target=_blank>LinkedIn</a> </div> </article> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Dr. Hari Thapliyaal </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dasarpai target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://hub.docker.com/r/harithapliyal target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://x.com/dasarpai target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../assets/javascripts/custom.js></script> </body> </html>