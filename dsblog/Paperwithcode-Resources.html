<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My various blogs on Datascience, Management, Software Engineering, Philosophy, Vedanta, Sanskrit, Current Affair, History. "><meta name=author content="Hari Thapliyaal"><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Paperwithcode-Resources.html><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.11"><title>Paper with Code Resources - DasarpAI</title><link rel=stylesheet href=../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","{{ config.extra.GOOGLE_ANALYTICS }}"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","{{ config.extra.GOOGLE_ANALYTICS }}",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id={{ config.extra.GOOGLE_ANALYTICS }}",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../assets/stylesheets/custom.7c86dd97.min.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#paper-with-code-resources class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@squidfunk</strong> on <a rel=me href=https://fosstodon.org/@squidfunk> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </span> <strong>Fosstodon</strong> </a> and <a href=https://x.com/squidfunk> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=DasarpAI class="md-header__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DasarpAI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Paper with Code Resources </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=index.html class=md-tabs__link> Data Science </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/pmlogy-home.html class=md-tabs__link> Project Management </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/wia-home.html class=md-tabs__link> SpiritualDrops </a> </li> <li class=md-tabs__item> <a href=../samskrutyatra/index.html class=md-tabs__link> Samskrut </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=DasarpAI class="md-nav__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> DasarpAI </label> <div class=md-nav__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../index.html class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/aboutme.html class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> <li class=md-nav__item> <a href=../dscourses/index.html class=md-nav__link> <span class=md-ellipsis> DS/AI Courses/Services </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Project/Work Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Project/Work Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/project-index-page.html class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-al-ml-projects.md class=md-nav__link> <span class=md-ellipsis> Business Domain </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-my-technology-stacks.md class=md-nav__link> <span class=md-ellipsis> Technology Stack </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-management-projects.md class=md-nav__link> <span class=md-ellipsis> Project Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../management/index.html class=md-nav__link> <span class=md-ellipsis> PM Courses/Services </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/clients.html class=md-nav__link> <span class=md-ellipsis> Clients </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/testimonials.md class=md-nav__link> <span class=md-ellipsis> Testimonial </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/publications-home.html class=md-nav__link> <span class=md-ellipsis> Publications </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/corpus-home.html class=md-nav__link> <span class=md-ellipsis> History Corpus </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=index.html class="md-nav__link "> <span class=md-ellipsis> Data Science </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Data Science </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dsresources/index.html class=md-nav__link> <span class=md-ellipsis> DS Resources </span> </a> </li> <li class=md-nav__item> <a href=../news/index.html class=md-nav__link> <span class=md-ellipsis> AI and Business News </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-books.md class=md-nav__link> <span class=md-ellipsis> Data Science-Books </span> </a> </li> <li class=md-nav__item> <a href=data-science-cheatsheets.md class=md-nav__link> <span class=md-ellipsis> Data Science Cheatsheets </span> </a> </li> <li class=md-nav__item> <a href=best-youtube-channels-for-ds.md class=md-nav__link> <span class=md-ellipsis> Video Channels to Learn DS </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-interview-resources.md class=md-nav__link> <span class=md-ellipsis> DS Interview Questions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../pmblog/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Project Management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-home.html class=md-nav__link> <span class=md-ellipsis> PMLOGY Home </span> </a> </li> <li class=md-nav__item> <a href=../pmglossary.md class=md-nav__link> <span class=md-ellipsis> PM Glossary </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-tags.md class=md-nav__link> <span class=md-ellipsis> PM Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-tags.md class=md-nav__link> <span class=md-ellipsis> PMBOK6 Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-summary.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 </span> </a> </li> <li class=md-nav__item> <a href=../pmbok6/index.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Explorer </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> PM Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> PM Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmi-templates.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Templates </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/prince2-templates.html class=md-nav__link> <span class=md-ellipsis> PRINCE2 Templates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../pmbok6hi/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management Hindi </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Project Management Hindi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmbok6hi-summary.html class=md-nav__link> <span class=md-ellipsis> PMBoK6 Hindi </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../wiaposts/index.html class="md-nav__link "> <span class=md-ellipsis> SpiritualDrops </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> SpiritualDrops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/wia-home.html class=md-nav__link> <span class=md-ellipsis> WIA Home </span> </a> </li> <li class=md-nav__item> <a href=../quotations/index.html class=md-nav__link> <span class=md-ellipsis> WIA Quotes </span> </a> </li> <li class=md-nav__item> <a href=../gk/index.html class=md-nav__link> <span class=md-ellipsis> GK Blog </span> </a> </li> <li class=md-nav__item> <a href=../booksummary/index.html class=md-nav__link> <span class=md-ellipsis> Book Summary </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../samskrutyatra/index.html class="md-nav__link "> <span class=md-ellipsis> Samskrut </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Samskrut </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/samskrut-home.html class=md-nav__link> <span class=md-ellipsis> SamskrutYatra Home </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#trending-papers-of-2021 class=md-nav__link> <span class=md-ellipsis> Trending Papers of 2021 </span> </a> </li> <li class=md-nav__item> <a href=#trending-libaries-of-2021 class=md-nav__link> <span class=md-ellipsis> Trending Libaries of 2021 </span> </a> </li> <li class=md-nav__item> <a href=#top-dataset-2021 class=md-nav__link> <span class=md-ellipsis> Top Dataset - 2021 </span> </a> </li> <li class=md-nav__item> <a href=#papers-of-2022 class=md-nav__link> <span class=md-ellipsis> Papers of 2022 </span> </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> <span class=md-ellipsis> References </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/dasarpai/dasrapai-mkdocs/edit/master/docs/dsblog/Paperwithcode-Resources.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/dasarpai/dasrapai-mkdocs/raw/master/docs/dsblog/Paperwithcode-Resources.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <p><img alt="Paper with Code Resources" src=../assets/images/dspost/dsp6091-rps-Paperwithcode-Resources.jpg></p> <h1 id=paper-with-code-resources>Paper with Code Resources<a class=headerlink href=#paper-with-code-resources title="Permanent link">&para;</a></h1> <h2 id=trending-papers-of-2021>Trending Papers of 2021<a class=headerlink href=#trending-papers-of-2021 title="Permanent link">&para;</a></h2> <ol> <li>ADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — <a href=https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel>https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel</a></li> <li>The Bayesian Learning Rule —Khan et al <a href=https://paperswithcode.com/paper/the-bayesian-learning-rule>https://paperswithcode.com/paper/the-bayesian-learning-rule</a></li> <li>Program Synthesis with Large Language Models — Austin et al <a href=https://paperswithcode.com/paper/program-synthesis-with-large-language-models>https://paperswithcode.com/paper/program-synthesis-with-large-language-models</a></li> <li>Masked Autoencoders Are Scalable Vision Learners — He et al <a href=https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision>https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision</a></li> <li>8-bit Optimizers via Block-wise Quantization — Dettmers et al <a href=https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization>https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization</a></li> <li>Revisiting ResNets: Improved Training and Scaling Strategies — Bello et al <a href=https://paperswithcode.com/paper/revisiting-resnets-improved-training-and>https://paperswithcode.com/paper/revisiting-resnets-improved-training-and</a></li> <li>Image Super-Resolution via Iterative Refinement — Saharia et al <a href=https://paperswithcode.com/paper/image-super-resolution-via-iterative>https://paperswithcode.com/paper/image-super-resolution-via-iterative</a></li> <li>Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs — Jaegle et al <a href=https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for>https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for</a></li> <li>Do Vision Transformers See Like Convolutional Neural Networks? — Raghu et al <a href=https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional>https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional</a></li> <li>Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al <a href=https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete>https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete</a></li> </ol> <h2 id=trending-libaries-of-2021>Trending Libaries of 2021<a class=headerlink href=#trending-libaries-of-2021 title="Permanent link">&para;</a></h2> <ol> <li>PyTorch Image Models — Ross Wightman — <a href=https://github.com/rwightman/pytorch-image-models>https://github.com/rwightman/pytorch-image-models</a></li> <li>Transformers — Hugging Face — <a href=https://github.com/huggingface/transformers>https://github.com/huggingface/transformers</a></li> <li>PyTorch-GAN — Erik Linder-Norén — <a href=https://github.com/eriklindernoren/PyTorch-GAN>https://github.com/eriklindernoren/PyTorch-GAN</a></li> <li>MMDetection — OpenMMLab — <a href=https://github.com/open-mmlab/mmdetection>https://github.com/open-mmlab/mmdetection</a></li> <li>Darknet — AlexeyAB — <a href=https://github.com/AlexeyAB/darknet>https://github.com/AlexeyAB/darknet</a></li> <li>Vision Transformer PyTorch — lucidrains — <a href=https://github.com/lucidrains/vit-pytorch>https://github.com/lucidrains/vit-pytorch</a></li> <li>InsightFace — DeepInsight — <a href=https://github.com/deepinsight/insightface>https://github.com/deepinsight/insightface</a></li> <li>Detectron2 — Meta AI — <a href=https://github.com/facebookresearch/detectron2>https://github.com/facebookresearch/detectron2</a></li> <li>PaddleOCR — PaddlePaddle — <a href=https://github.com/PaddlePaddle/PaddleOCR>https://github.com/PaddlePaddle/PaddleOCR</a></li> <li>FairSeq — Meta AI — <a href=https://github.com/pytorch/fairseq>https://github.com/pytorch/fairseq</a></li> </ol> <h2 id=top-dataset-2021>Top Dataset - 2021<a class=headerlink href=#top-dataset-2021 title="Permanent link">&para;</a></h2> <ol> <li>MATH — Hendrycks et al <a href=https://paperswithcode.com/dataset/math>https://paperswithcode.com/dataset/math</a></li> <li>UAV-Human — Li et al <a href=https://paperswithcode.com/dataset/uav-human>https://paperswithcode.com/dataset/uav-human</a></li> <li>UPFD (User Preference-aware Fake News Detection) — Dou et al <a href=https://paperswithcode.com/dataset/upfd>https://paperswithcode.com/dataset/upfd</a></li> <li>OGB-LSC (OGB Large-Scale Challenge) — Hu et al <a href=https://paperswithcode.com/dataset/ogb-lsc>https://paperswithcode.com/dataset/ogb-lsc</a></li> <li>CodeXGLUE —Lu et al <a href=https://paperswithcode.com/dataset/codexglue>https://paperswithcode.com/dataset/codexglue</a></li> <li>AGORA — Patel et al <a href=https://paperswithcode.com/dataset/agora>https://paperswithcode.com/dataset/agora</a></li> <li>BEIR (Benchmarking IR) — Thakur et al <a href=https://paperswithcode.com/dataset/beir>https://paperswithcode.com/dataset/beir</a></li> <li>WikiGraphs — Wang et al <a href=https://paperswithcode.com/dataset/wikigraphs>https://paperswithcode.com/dataset/wikigraphs</a></li> <li>Few-NERD — Ding et al <a href=https://paperswithcode.com/dataset/few-nerd>https://paperswithcode.com/dataset/few-nerd</a></li> <li>PASS (Pictures without humAns for Self-Supervision) —Asano et al <a href=https://paperswithcode.com/dataset/pass>https://paperswithcode.com/dataset/pass</a></li> </ol> <h2 id=papers-of-2022>Papers of 2022<a class=headerlink href=#papers-of-2022 title="Permanent link">&para;</a></h2> <ol> <li>Controllable Animation of Fluid Elements in Still Images </li> <li>F-SfT: Shape-From-Template With A Physics-Based Deformation Model </li> <li>TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation </li> <li>Do Learned Representations Respect Causal Relationships? </li> <li>ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic </li> <li>3D Moments From Near-Duplicate Photos </li> <li>Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization </li> <li>Blind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots </li> <li>Balanced and Hierarchical Relation Learning for One-Shot Object Detection </li> <li>NICE-SLAM: Neural Implicit Scalable Encoding for SLAM </li> <li>Stochastic Trajectory Prediction Via Motion Indeterminacy Diffusion </li> <li>CLRNet: Cross Layer Refinement Network for Lane Detection </li> <li>Motion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging </li> <li>DINE: Domain Adaptation From Single and Multiple Black-Box Predictors </li> <li>FaceFormer: Speech-Driven 3D Facial Animation With Transformers </li> <li>Rotationally Equivariant 3D Object Detection </li> <li>Accelerating DETR Convergence Via Semantic-Aligned Matching </li> <li>Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification </li> <li>GeoNeRF: Generalizing NeRF With Geometry Priors </li> <li>ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo </li> <li>Expanding Low-Density Latent Regions for Open-Set Object Detection </li> <li>Uformer: A General U-Shaped Transformer for Image Restoration </li> <li>Exploring Dual-Task Correlation for Pose Guided Person Image Generation </li> <li>Portrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data </li> <li>Modeling 3D Layout for Group Re-Identification </li> <li>Toward Fast, Flexible, and Robust Low-Light Image Enhancement </li> <li>Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos </li> <li>HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network </li> <li>Modular Action Concept Grounding in Semantic Video Prediction </li> <li>StyleSwin: Transformer-Based GAN for High-Resolution Image Generation </li> <li>Discrete Cosine Transform Network for Guided Depth Map Super-Resolution </li> <li>Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing </li> <li>TransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization </li> <li>Contrastive Boundary Learning for Point Cloud Segmentation </li> <li>Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution </li> <li>CVNet: Contour Vibration Network for Building Extraction </li> <li>Swin Transformer V2: Scaling Up Capacity and Resolution </li> <li>Projective Manifold Gradient Layer for Deep Rotation Regression </li> <li>HCSC: Hierarchical Contrastive Selective Coding </li> <li>TransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition </li> <li>DiSparse: Disentangled Sparsification for Multitask Model Compression </li> <li>Pushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference </li> <li>Towards Efficient and Scalable Sharpness-Aware Minimization </li> <li>OSSO: Obtaining Skeletal Shape From Outside </li> <li>A Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models </li> <li>Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes </li> <li>Comparing Correspondences: Video Prediction With Correspondence-Wise Losses </li> <li>Towards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation </li> <li>CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding </li> <li>Few Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment </li> <li>Enhancing Adversarial Training With Second-Order Statistics of Weights </li> <li>Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo </li> <li>Moving Window Regression: A Novel Approach to Ordinal Regression </li> <li>Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection </li> <li>Robust Optimization As Data Augmentation for Large-Scale Graphs </li> <li>Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients </li> <li>Improving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input </li> <li>ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer </li> <li>360MonoDepth: High-Resolution 360deg Monocular Depth Estimation </li> <li>POCO: Point Convolution for Surface Reconstruction </li> <li>Neural Texture Extraction and Distribution for Controllable Person Image Synthesis </li> <li>Classification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs </li> <li>DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis </li> <li>ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes </li> <li>UNIST: Unpaired Neural Implicit Shape Translation Network </li> <li>APES: Articulated Part Extraction From Sprite Sheets </li> <li>SPAct: Self-Supervised Privacy Preservation for Action Recognition </li> <li>De-Rendering 3D Objects in The Wild </li> <li>Global Sensing and Measurements Reuse for Image Compressed Sensing </li> <li>Practical Evaluation of Adversarial Robustness Via Adaptive Auto Attack </li> <li>Cross-View Transformers for Real-Time Map-View Semantic Segmentation </li> <li>Controllable Dynamic Multi-Task Architectures </li> <li>FastDOG: Fast Discrete Optimization on GPU </li> <li>Focal and Global Knowledge Distillation for Detectors </li> <li>Learning To Prompt for Continual Learning </li> <li>Human Mesh Recovery From Multiple Shots </li> <li>Convolution of Convolution: Let Kernels Spatially Collaborate </li> <li>Make It Move: Controllable Image-to-Video Generation With Text Descriptions </li> <li>Neural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling </li> <li>Video-Text Representation Learning Via Differentiable Weak Temporal Alignment </li> <li>Bi-Directional Object-Context Prioritization Learning for Saliency Ranking </li> <li>Vehicle Trajectory Prediction Works, But Not Everywhere </li> <li>MonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer </li> <li>Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning </li> <li>Generalized Category Discovery </li> <li>Contour-Hugging Heatmaps for Landmark Detection </li> <li>Voxel Field Fusion for 3D Object Detection </li> <li>DisARM: Displacement Aware Relation Module for 3D Detection </li> <li>MixFormer: Mixing Features Across Windows and Dimensions </li> <li>FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment </li> <li>HEAT: Holistic Edge Attention Transformer for Structured Reconstruction </li> <li>Mobile-Former: Bridging MobileNet and Transformer </li> <li>CycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision </li> <li>VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution </li> <li>Towards End-to-End Unified Scene Text Detection and Layout Analysis </li> <li>AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation </li> <li>ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior </li> <li>End-to-End Referring Video Object Segmentation With Multimodal Transformers </li> <li>IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo </li> <li>Not All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds </li> <li>Detecting Camouflaged Object in Frequency Domain </li> <li>SelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video </li> <li>Equivariant Point Cloud Analysis Via Learning Orientations for Message Passing </li> <li>Node Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization </li> <li>Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction </li> <li>Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model </li> <li>How Well Do Sparse ImageNet Models Transfer? </li> <li>REX: Reasoning-Aware and Grounded Explanation </li> <li>Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes </li> <li>Object-Aware Video-Language Pre-Training for Retrieval </li> <li>MAT: Mask-Aware Transformer for Large Hole Image Inpainting </li> <li>Align and Prompt: Video-and-Language Pre-Training With Entity Prompts </li> <li>MSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens </li> <li>Cross Modal Retrieval With Querybank Normalisation </li> <li>Ray3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization </li> <li>ASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization </li> <li>Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs </li> <li>End-to-End Multi-Person Pose Estimation With Transformers </li> <li>REGTR: End-to-End Point Cloud Correspondences With Transformers </li> <li>Neural 3D Scene Reconstruction With The Manhattan-World Assumption </li> <li>V2C: Visual Voice Cloning </li> <li>Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection </li> <li>MAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions </li> <li>Gait Recognition in The Wild With Dense 3D Representations and A Benchmark </li> <li>ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis </li> <li>QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection </li> <li>IDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment </li> <li>BEHAVE: Dataset and Method for Tracking Human Object Interactions </li> <li>Revisiting Random Channel Pruning for Neural Network Compression </li> <li>Generating Diverse and Natural 3D Human Motions From Text </li> <li>E-CIR: Event-Enhanced Continuous Intensity Recovery </li> <li>Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond </li> <li>Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation </li> <li>AziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception </li> <li>Weakly Supervised Rotation-Invariant Aerial Object Detection Network </li> <li>Surface Reconstruction From Point Clouds By Learning Predictive Context Priors </li> <li>IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes </li> <li>DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation </li> <li>Weakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation </li> <li>E2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation </li> <li>BatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning </li> <li>Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation </li> <li>Learning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation </li> <li>PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition </li> <li>Clothes-Changing Person Re-Identification With RGB Modality Only </li> <li>Robust Image Forgery Detection Over Online Social Network Shared Images </li> <li>Representation Compensation Networks for Continual Semantic Segmentation </li> <li>Tracking People By Predicting 3D Appearance, Location and Pose </li> <li>Text2Mesh: Text-Driven Neural Stylization for Meshes </li> <li>C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image </li> <li>Forward Compatible Few-Shot Class-Incremental Learning </li> <li>Weakly Supervised Object Localization As Domain Adaption </li> <li>Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation </li> <li>Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching </li> <li>Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation </li> <li>MatteFormer: Transformer-Based Image Matting Via Prior-Tokens </li> <li>Video Shadow Detection Via Spatio-Temporal Interpolation Consistency Training </li> <li>Robust and Accurate Superquadric Recovery: A Probabilistic Approach </li> <li>Grounding Answers for Visual Questions Asked By Visually Impaired People </li> <li>Sparse Instance Activation for Real-Time Instance Segmentation </li> <li>VisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning </li> <li>MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation </li> <li>Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis </li> <li>Towards Implicit Text-Guided 3D Shape Generation </li> <li>SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage </li> <li>Query and Attention Augmentation for Knowledge-Based Explainable Reasoning </li> <li>Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality </li> <li>Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection </li> <li>Fine-Grained Object Classification Via Self-Supervised Pose Alignment </li> <li>Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding </li> <li>Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization </li> <li>Relieving Long-Tailed Instance Segmentation Via Pairwise Class Balance </li> <li>Online Convolutional Re-Parameterization </li> <li>Mimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning </li> <li>RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition </li> <li>Personalized Image Aesthetics Assessment With Rich Attributes </li> <li>Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification </li> <li>HDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging </li> <li>OW-DETR: Open-World Detection Transformer </li> <li>Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds </li> <li>Reversible Vision Transformers </li> <li>Amodal Panoptic Segmentation </li> <li>Correlation Verification for Image Retrieval </li> <li>Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation </li> <li>Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut </li> <li>Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection </li> <li>Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing </li> <li>Glass: Geometric Latent Augmentation for Shape Spaces </li> <li>DPICT: Deep Progressive Image Compression Using Trit-Planes </li> <li>Text to Image Generation With Semantic-Spatial Aware GAN </li> <li>Generalizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization </li> <li>Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model </li> <li>Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images </li> <li>Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture </li> <li>Surface Representation for Point Clouds </li> <li>Implicit Motion Handling for Video Camouflaged Object Detection </li> <li>DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides </li> <li>Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification </li> <li>Optical Flow Estimation for Spiking Camera </li> <li>GradViT: Gradient Inversion of Vision Transformers </li> <li>Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning </li> <li>Joint Global and Local Hierarchical Priors for Learned Image Compression </li> <li>Knowledge Distillation Via The Target-Aware Transformer </li> <li>Subspace Adversarial Training </li> <li>3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection </li> <li>Image Segmentation Using Text and Image Prompts </li> <li>AutoMine: An Unmanned Mine Dataset </li> <li>Background Activation Suppression for Weakly Supervised Object Localization </li> <li>Synthetic Generation of Face Videos With Plethysmograph Physiology </li> <li>Hallucinated Neural Radiance Fields in The Wild </li> <li>Global Tracking Transformers </li> <li>Backdoor Attacks on Self-Supervised Learning </li> <li>GMFlow: Learning Optical Flow Via Global Matching </li> <li>Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation </li> <li>Explore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline </li> <li>Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction </li> <li>Scanline Homographies for Rolling-Shutter Plane Absolute Pose </li> <li>AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement </li> <li>Recurrent Glimpse-Based Decoder for Detection With Transformer </li> <li>SimMIM: A Simple Framework for Masked Image Modeling </li> <li>Label Matching Semi-Supervised Object Detection </li> <li>RegionCLIP: Region-Based Language-Image Pretraining </li> <li>Video Frame Interpolation Transformer </li> <li>BCOT: A Markerless High-Precision 3D Object Tracking Benchmark </li> <li>Omni-DETR: Omni-Supervised Object Detection With Transformers </li> <li>Transferable Sparse Adversarial Attack </li> <li>CREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping </li> <li>VALHALLA: Visual Hallucination for Machine Translation </li> <li>HINT: Hierarchical Neuron Concept Explainer </li> <li>Neural Face Identification in A 2D Wireframe Projection of A Manifold Object </li> <li>Nonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation </li> <li>An Empirical Study of End-to-End Temporal Action Detection </li> <li>Object Localization Under Single Coarse Point Supervision </li> <li>Unsupervised Learning of Accurate Siamese Tracking </li> <li>Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo </li> <li>Equalized Focal Loss for Dense Long-Tailed Object Detection </li> <li>DeepDPM: Deep Clustering With An Unknown Number of Clusters </li> <li>ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation </li> <li>Unsupervised Domain Adaptation for Nighttime Aerial Tracking </li> <li>RestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs </li> <li>Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction </li> <li>A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration </li> <li>Not Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency </li> <li>Coupling Vision and Proprioception for Navigation of Legged Robots </li> <li>Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation </li> <li>EMOCA: Emotion Driven Monocular Face Capture and Animation </li> <li>Quarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free </li> <li>AlignQ: Alignment Quantization With ADMM-Based Correlation Preservation </li> <li>Interactive Multi-Class Tiny-Object Detection </li> <li>Learning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection </li> <li>Multi-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry </li> <li>Slimmable Domain Adaptation </li> <li>High-Resolution Image Harmonization Via Collaborative Dual Transformations </li> <li>MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation </li> <li>Self-Supervised Neural Articulated Shape and Appearance Models </li> <li>Topology Preserving Local Road Network Estimation From Single Onboard Camera Image </li> <li>Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes </li> <li>SwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition </li> <li>Deblur-NeRF: Neural Radiance Fields From Blurry Images </li> <li>Whose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction </li> <li>Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation </li> <li>Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning </li> <li>Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel </li> <li>Faithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations </li> <li>Proto2Proto: Can You Recognize The Car, The Way I Do? </li> <li>TVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing </li> <li>Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution </li> <li>Habitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale </li> <li>Simple But Effective: CLIP Embeddings for Embodied AI </li> <li>NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition </li> <li>Collaborative Transformers for Grounded Situation Recognition </li> <li>CPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild </li> <li>Continual Test-Time Domain Adaptation </li> <li>Dynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information </li> <li>MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering </li> <li>Fair Contrastive Learning for Facial Attribute Classification </li> <li>Directional Self-Supervised Learning for Heavy Image Augmentations </li> <li>No-Reference Point Cloud Quality Assessment Via Domain Adaptation </li> <li>Comprehending and Ordering Semantics for Image Captioning </li> <li>A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection </li> <li>Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification </li> <li>HeadNeRF: A Real-Time NeRF-Based Parametric Head Model </li> <li>Occlusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture </li> <li>IDR: Self-Supervised Image Denoising Via Iterative Data Refinement </li> <li>MogFace: Towards A Deeper Appreciation on Face Detection </li> <li>Learning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers </li> <li>CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation </li> <li>FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos </li> <li>Learning To Detect Mobile Objects From LiDAR Scans Without Labels </li> <li>WildNet: Learning Domain Generalized Semantic Segmentation From The Wild </li> <li>DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection </li> <li>Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation </li> <li>Generating Diverse 3D Reconstructions From A Single Occluded Face Image </li> <li>Stand-Alone Inter-Frame Attention in Video Models </li> <li>Large-Scale Pre-Training for Person Re-Identification With Noisy Labels </li> <li>Semantic Segmentation By Early Region Proxy </li> <li>LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition </li> <li>HVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture </li> <li>Rethinking Visual Geo-Localization for Large-Scale Applications </li> <li>The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy </li> <li>ViM: Out-of-Distribution With Virtual-Logit Matching </li> <li>Class-Aware Contrastive Semi-Supervised Learning </li> <li>Ditto: Building Digital Twins of Articulated Objects From Interaction </li> <li>Adaptive Early-Learning Correction for Segmentation From Noisy Annotations </li> <li>Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation </li> <li>RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution </li> <li>Partial Class Activation Attention for Semantic Segmentation </li> <li>Multi-Scale Memory-Based Video Deblurring </li> <li>A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching </li> <li>Geometric Structure Preserving Warp for Natural Image Stitching </li> <li>GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping </li> <li>Conditional Prompt Learning for Vision-Language Models </li> <li>Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification </li> <li>Undoing The Damage of Label Shift for Cross-Domain Semantic Segmentation </li> <li>FisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering </li> <li>Affine Medical Image Registration With Coarse-To-Fine Vision Transformer </li> <li>A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift </li> <li>Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes </li> <li>Restormer: Efficient Transformer for High-Resolution Image Restoration </li> <li>IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation </li> <li>Large Loss Matters in Weakly Supervised Multi-Label Classification </li> <li>Neural Inertial Localization </li> <li>GraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature </li> <li>VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning </li> <li>Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection </li> <li>MLSLT: Towards Multilingual Sign Language Translation </li> <li>Towards An End-to-End Framework for Flow-Guided Video Inpainting </li> <li>Contrastive Test-Time Adaptation </li> <li>MotionAug: Augmentation With Physical Correction for Human Motion Prediction </li> <li>Modeling Indirect Illumination for Inverse Rendering </li> <li>TransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions </li> <li>H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection </li> <li>P3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior </li> <li>GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection </li> <li>Simple Multi-Dataset Detection </li> <li>Proactive Image Manipulation Detection </li> <li>StyTr2: Image Style Transfer With Transformers </li> <li>Global Matching With Overlapping Attention for Optical Flow Estimation </li> <li>Language As Queries for Referring Video Object Segmentation </li> <li>MViTv2: Improved Multiscale Vision Transformers for Classification and Detection </li> <li>Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language </li> <li>Rethinking Efficient Lane Detection Via Curve Modeling </li> <li>Self-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation </li> <li>Co-Advise: Cross Inductive Bias Distillation </li> <li>AdaMixer: A Fast-Converging Query-Based Object Detector </li> <li>DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification </li> <li>BEVT: BERT Pretraining of Video Transformers </li> <li>Deep Generalized Unfolding Networks for Image Restoration </li> <li>VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation </li> <li>Deep Unlearning Via Randomized Conditionally Independent Hessians </li> <li>Revisiting Skeleton-Based Action Recognition </li> <li>Stereo Depth From Events Cameras: Concentrate and Focus on The Future </li> <li>A Simple Data Mixing Prior for Improving Self-Supervised Learning </li> <li>Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability </li> <li>BigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster </li> <li>Attentive Fine-Grained Structured Sparsity for Image Restoration </li> <li>Learning Fair Classifiers With Partially Annotated Group Labels </li> <li>NightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night </li> <li>Constrained Few-Shot Class-Incremental Learning </li> <li>Threshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds </li> <li>TransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers </li> <li>DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis </li> <li>The Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification </li> <li>IntentVizor: Towards Generic Query Guided Interactive Video Summarization </li> <li>Shape-Invariant 3D Adversarial Point Clouds </li> <li>Bootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training </li> <li>PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents </li> <li>Meta-Attention for ViT-Backed Continual Learning </li> <li>DST: Dynamic Substitute Training for Data-Free Black-Box Attack </li> <li>Unified Contrastive Learning in Image-Text-Label Space </li> <li>Unsupervised Pre-Training for Temporal Action Localization Tasks </li> <li>Look Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image </li> <li>High-Fidelity Human Avatars From A Single RGB Camera </li> <li>Multiview Transformers for Video Recognition </li> <li>How Good Is Aesthetic Ability of A Fashion Model? </li> <li>Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds </li> <li>Sequential Voting With Relational Box Fields for Active Object Detection </li> <li>Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning </li> <li>Consistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection </li> <li>Consistent Explanations By Contrastive Learning </li> <li>Hierarchical Modular Network for Video Captioning </li> <li>Depth Estimation By Combining Binocular Stereo and Monocular Structured-Light </li> <li>Salient-to-Broad Transition for Video Person Re-Identification </li> <li>DeeCap: Dynamic Early Exiting for Efficient Image Captioning </li> <li>RepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality </li> <li>DR.VIC: Decomposition and Reasoning for Video Individual Counting </li> <li>ARCS: Accurate Rotation and Correspondence Search </li> <li>Learning To Anticipate Future With Dynamic Context Removal </li> <li>GCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors </li> <li>On The Integration of Self-Attention and Convolution </li> <li>Domain Adaptation on Point Clouds Via Geometry-Aware Implicits </li> <li>GroupViT: Semantic Segmentation Emerges From Text Supervision </li> <li>DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation </li> <li>BppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning </li> <li>Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation </li> <li>Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector </li> <li>Topology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow </li> <li>Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection </li> <li>MAXIM: Multi-Axis MLP for Image Processing </li> <li>Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles </li> <li>PSTR: End-to-End One-Step Person Search With Transformers </li> <li>NFormer: Robust Person Re-Identification With Neighbor Transformer </li> <li>Bridging Global Context Interactions for High-Fidelity Image Completion </li> <li>SwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning </li> <li>Not All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer </li> <li>Temporally Efficient Vision Transformer for Video Instance Segmentation </li> <li>The Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration </li> <li>NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks </li> <li>WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation </li> <li>Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding </li> <li>E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition </li> <li>OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization </li> <li>OnePose: One-Shot Object Pose Estimation Without CAD Models </li> <li>Rethinking Minimal Sufficient Representation in Contrastive Learning </li> <li>Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels </li> <li>Federated Class-Incremental Learning </li> <li>Show, Deconfound and Tell: Image Captioning With Causal Inference </li> <li>MobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image </li> <li>Parameter-Free Online Test-Time Adaptation </li> <li>SIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection </li> <li>No Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces </li> <li>HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging </li> <li>Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space </li> <li>Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes </li> <li>Detecting Deepfakes With Self-Blended Images </li> <li>Implicit Sample Extension for Unsupervised Person Re-Identification </li> <li>Energy-Based Latent Aligner for Incremental Learning </li> <li>Towards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin </li> <li>Group R-CNN for Weakly Semi-Supervised Object Detection With Points </li> <li>Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction </li> <li>Hybrid Relation Guided Set Matching for Few-Shot Action Recognition </li> <li>Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images </li> <li>Generalized Binary Search Network for Highly-Efficient Multi-View Stereo </li> <li>SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation </li> <li>FlexIT: Towards Flexible Semantic Image Translation </li> <li>CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow </li> <li>BoxeR: Box-Attention for 2D and 3D Transformers </li> <li>Neural Architecture Search With Representation Mutual Information </li> <li>Can Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective </li> <li>Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction </li> <li>Multi-View Transformer for 3D Visual Grounding </li> <li>Structured Sparse R-CNN for Direct Scene Graph Generation </li> <li>BARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information </li> <li>PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models </li> <li>Towards Understanding Adversarial Robustness of Optical Flow Networks </li> <li>Lifelong Graph Learning </li> <li>Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning </li> <li>Computing Wasserstein-p Distance Between Images With Linear Cost </li> <li>Unsupervised Representation Learning for Binary Networks By Joint Classifier Learning </li> <li>Large-Scale Video Panoptic Segmentation in The Wild: A Benchmark </li> <li>GrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains </li> <li>Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification </li> <li>MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning </li> <li>Oriented RepPoints for Aerial Object Detection </li> <li>Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning </li> <li>Low-Resource Adaptation for Personalized Co-Speech Gesture Generation </li> <li>Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection </li> <li>MS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph </li> <li>Learning To Listen: Modeling Non-Deterministic Dyadic Facial Motion </li> <li>Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video </li> <li>MixFormer: End-to-End Tracking With Iterative Mixed Attention </li> <li>Plenoxels: Radiance Fields Without Neural Networks </li> <li>Selective-Supervised Contrastive Learning With Noisy Labels </li> <li>SimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation </li> <li>Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity </li> <li>Video Demoireing With Relation-Based Temporal Consistency </li> <li>Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation </li> <li>Modeling Image Composition for Complex Scene Generation </li> <li>Decoupling Zero-Shot Semantic Segmentation </li> <li>Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions </li> <li>Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability </li> <li>IFOR: Iterative Flow Minimization for Robotic Object Rearrangement </li> <li>Zero Experience Required: Plug &amp; Play Modular Transfer Learning for Semantic Visual Navigation </li> <li>TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation </li> <li>The Wanderings of Odysseus in 3D Scenes </li> <li>All-in-One Image Restoration for Unknown Corruption </li> <li>PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors </li> <li>MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video </li> <li>RCP: Recurrent Closest Point for Point Cloud </li> <li>A Dual Weighting Label Assignment Scheme for Object Detection </li> <li>Hyperbolic Vision Transformers: Combining Improvements in Metric Learning </li> <li>Instance-Aware Dynamic Neural Network Quantization </li> <li>Exploring Effective Data for Surrogate Training Towards Black-Box Attack </li> <li>JRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection </li> <li>Investigating Top-k White-Box and Transferable Black-Box Attack </li> <li>Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition </li> <li>A Self-Supervised Descriptor for Image Copy Detection </li> <li>Negative-Aware Attention Framework for Image-Text Matching </li> <li>An Image Patch Is A Wave: Phase-Aware Vision MLP </li> <li>Shunted Self-Attention Via Multi-Scale Token Aggregation </li> <li>Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression </li> <li>Recurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction </li> <li>Surpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning </li> <li>Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond </li> <li>TrackFormer: Multi-Object Tracking With Transformers </li> <li>3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow </li> <li>Feature Statistics Mixing Regularization for Generative Adversarial Networks </li> <li>OpenTAL: Towards Open Set Temporal Action Localization </li> <li>Self-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection </li> <li>Ego4D: Around The World in 3,000 Hours of Egocentric Video </li> <li>Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis </li> <li>Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data </li> <li>DAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image </li> <li>Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors </li> <li>VCLIMB: A Novel Video Class Incremental Learning Benchmark </li> <li>Robust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements </li> <li>ST++: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation </li> <li>Interacting Attention Graph for Single Image Two-Hand Reconstruction </li> <li>Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task </li> <li>Cross-Image Relational Knowledge Distillation for Semantic Segmentation </li> <li>Towards Layer-Wise Image Vectorization </li> <li>Scenic: A JAX Library for Computer Vision Research and Beyond </li> <li>Real-Time Object Detection for Streaming Perception </li> <li>VisualHow: Multimodal Problem Solving </li> <li>Spatial Commonsense Graph for Object Localisation in Partial Scenes </li> <li>OSSGAN: Open-Set Semi-Supervised Image Generation </li> <li>Bi-Level Alignment for Cross-Domain Crowd Counting </li> <li>ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation </li> <li>Efficient Multi-View Stereo By Iterative Dynamic Cost Volume </li> <li>TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing </li> <li>Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework </li> <li>SGTR: End-to-End Scene Graph Generation With Transformer </li> <li>Decoupled Knowledge Distillation </li> <li>DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection </li> <li>Reusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation </li> <li>Show Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning </li> <li>SIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks </li> <li>Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss </li> <li>CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings </li> <li>IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization </li> <li>I M Avatar: Implicit Morphable Head Avatars From Videos </li> <li>Weakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images </li> <li>A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution </li> <li>Multi-Modal Dynamic Graph Transformer for Visual Grounding </li> <li>Geometric Transformer for Fast and Robust Point Cloud Registration </li> <li>UMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection </li> <li>Demystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training? </li> <li>The Devil Is in The Details: Window-Based Attention for Image Compression </li> <li>DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation </li> <li>PolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images </li> <li>Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation </li> <li>Spatio-Temporal Relation Modeling for Few-Shot Action Recognition </li> <li>Multi-Person Extreme Motion Prediction </li> <li>B-DARTS: Beta-Decay Regularization for Differentiable Architecture Search </li> <li>CMT: Convolutional Neural Networks Meet Vision Transformers </li> <li>KNN Local Attention for Image Restoration </li> <li>Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model </li> <li>TransMix: Attend To Mix for Vision Transformers </li> <li>Inertia-Guided Flow Completion and Style Fusion for Video Inpainting </li> <li>Long-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment </li> <li>Image Animation With Perturbed Masks </li> <li>Domain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing </li> <li>OcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction </li> <li>MonoScene: Monocular 3D Semantic Scene Completion </li> <li>AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition </li> <li>Continuous Scene Representations for Embodied AI </li> <li>Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds </li> <li>Non-Probability Sampling Network for Stochastic Human Trajectory Prediction </li> <li>ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning </li> <li>Human-Aware Object Placement for Visual Environment Reconstruction </li> <li>X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval </li> <li>RAMA: A Rapid Multicut Algorithm on GPU </li> <li>Adversarial Parametric Pose Prior </li> <li>Mask Transfiner for High-Quality Instance Segmentation </li> <li>It Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection </li> <li>DiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis </li> <li>Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network </li> <li>YouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset </li> <li>DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation </li> <li>Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification </li> <li>Self-Supervised Video Transformer </li> <li>AutoRF: Learning 3D Object Radiance Fields From Single View Observations </li> <li>Coopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles </li> <li>TubeR: Tubelet Transformer for Video Action Detection </li> <li>MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection </li> <li>Learning Non-Target Knowledge for Few-Shot Semantic Segmentation </li> <li>UKPGAN: A General Self-Supervised Keypoint Detector </li> <li>Raw High-Definition Radar for Multi-Task Learning </li> <li>Coarse-To-Fine Feature Mining for Video Semantic Segmentation </li> <li>Compressing Models With Few Samples: Mimicking Then Replacing </li> <li>PokeBNN: A Binary Pursuit of Lightweight Accuracy </li> <li>Zoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection </li> <li>SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images </li> <li>EMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching </li> <li>PoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision </li> <li>Group Contextualization for Video Recognition </li> <li>Single-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation </li> <li>L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation </li> <li>Self-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition </li> <li>Neural 3D Video Synthesis From Multi-View Video </li> <li>SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation </li> <li>Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search </li> <li>HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening </li> <li>Structure-Aware Flow Generation for Human Body Reshaping </li> <li>Learning To Answer Questions in Dynamic Audio-Visual Scenarios </li> <li>Synthetic Aperture Imaging With Events and Frames </li> <li>MonoGround: Detecting Monocular 3D Objects From The Ground </li> <li>Deep Visual Geo-Localization Benchmark </li> <li>StyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2 </li> <li>LISA: Learning Implicit Shape and Appearance of Hands </li> <li>Iterative Deep Homography Estimation </li> <li>Learned Queries for Efficient Local Attention </li> <li>Colar: Effective and Efficient Online Action Detection By Consulting Exemplars </li> <li>SoftGroup for 3D Instance Segmentation on Point Clouds </li> <li>MVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions </li> <li>Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement </li> <li>Deep Constrained Least Squares for Blind Image Super-Resolution </li> <li>EDTER: Edge Detection With Transformer </li> <li>AirObject: A Temporally Evolving Graph Embedding for Object Identification </li> <li>From Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering </li> <li>Semantic-Aware Domain Generalized Segmentation </li> <li>DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion </li> <li>UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection </li> <li>AKB-48: A Real-World Articulated Object Knowledge Base </li> <li>Stratified Transformer for 3D Point Cloud Segmentation </li> <li>Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations </li> <li>Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis </li> <li>Day-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images.</li> </ol> <h2 id=references>References<a class=headerlink href=#references title="Permanent link">&para;</a></h2> <ul> <li><a href=https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/ >https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/</a></li> </ul> <p><strong>Author</strong> <br> Dr Hari Thapliyaal <br> dasarpai.com <br> linkedin.com/in/harithapliyal </p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Dr. Hari Thapliyaal </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dasarpai target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://hub.docker.com/r/harithapliyal target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://x.com/dasarpai target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../assets/javascripts/custom.9e5da760.min.js></script> </body> </html>