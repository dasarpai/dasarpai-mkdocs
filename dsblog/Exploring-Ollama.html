<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My various blogs on Datascience, Management, Software Engineering, Philosophy, Vedanta, Sanskrit, Current Affair, History. "><meta name=author content="Hari Thapliyaal"><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Exploring-Ollama.html><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.11"><title>Exploring Ollama & LM Studio - DasarpAI</title><link rel=stylesheet href=../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","{{ config.extra.GOOGLE_ANALYTICS }}"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","{{ config.extra.GOOGLE_ANALYTICS }}",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id={{ config.extra.GOOGLE_ANALYTICS }}",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../assets/stylesheets/custom.7c86dd97.min.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#exploring-ollama-lm-studio class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@squidfunk</strong> on <a rel=me href=https://fosstodon.org/@squidfunk> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </span> <strong>Fosstodon</strong> </a> and <a href=https://x.com/squidfunk> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=DasarpAI class="md-header__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DasarpAI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Exploring Ollama & LM Studio </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=index.html class=md-tabs__link> Data Science </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/pmlogy-home.html class=md-tabs__link> Project Management </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/wia-home.html class=md-tabs__link> SpiritualDrops </a> </li> <li class=md-tabs__item> <a href=../samskrutyatra/index.html class=md-tabs__link> Samskrut </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=DasarpAI class="md-nav__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> DasarpAI </label> <div class=md-nav__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../index.html class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/aboutme.html class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> <li class=md-nav__item> <a href=../dscourses/index.html class=md-nav__link> <span class=md-ellipsis> DS/AI Courses/Services </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Project/Work Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Project/Work Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/project-index-page.html class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-al-ml-projects.md class=md-nav__link> <span class=md-ellipsis> Business Domain </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-my-technology-stacks.md class=md-nav__link> <span class=md-ellipsis> Technology Stack </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-management-projects.md class=md-nav__link> <span class=md-ellipsis> Project Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../management/index.html class=md-nav__link> <span class=md-ellipsis> PM Courses/Services </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/clients.html class=md-nav__link> <span class=md-ellipsis> Clients </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/testimonials.md class=md-nav__link> <span class=md-ellipsis> Testimonial </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/publications-home.html class=md-nav__link> <span class=md-ellipsis> Publications </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/corpus-home.html class=md-nav__link> <span class=md-ellipsis> History Corpus </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=index.html class="md-nav__link "> <span class=md-ellipsis> Data Science </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Data Science </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dsresources/index.html class=md-nav__link> <span class=md-ellipsis> DS Resources </span> </a> </li> <li class=md-nav__item> <a href=../news/index.html class=md-nav__link> <span class=md-ellipsis> AI and Business News </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-books.md class=md-nav__link> <span class=md-ellipsis> Data Science-Books </span> </a> </li> <li class=md-nav__item> <a href=data-science-cheatsheets.md class=md-nav__link> <span class=md-ellipsis> Data Science Cheatsheets </span> </a> </li> <li class=md-nav__item> <a href=best-youtube-channels-for-ds.md class=md-nav__link> <span class=md-ellipsis> Video Channels to Learn DS </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-interview-resources.md class=md-nav__link> <span class=md-ellipsis> DS Interview Questions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../pmblog/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Project Management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-home.html class=md-nav__link> <span class=md-ellipsis> PMLOGY Home </span> </a> </li> <li class=md-nav__item> <a href=../pmglossary.md class=md-nav__link> <span class=md-ellipsis> PM Glossary </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-tags.md class=md-nav__link> <span class=md-ellipsis> PM Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-tags.md class=md-nav__link> <span class=md-ellipsis> PMBOK6 Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-summary.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 </span> </a> </li> <li class=md-nav__item> <a href=../pmbok6/index.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Explorer </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> PM Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> PM Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmi-templates.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Templates </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/prince2-templates.html class=md-nav__link> <span class=md-ellipsis> PRINCE2 Templates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../pmbok6hi/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management Hindi </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Project Management Hindi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmbok6hi-summary.html class=md-nav__link> <span class=md-ellipsis> PMBoK6 Hindi </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../wiaposts/index.html class="md-nav__link "> <span class=md-ellipsis> SpiritualDrops </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> SpiritualDrops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/wia-home.html class=md-nav__link> <span class=md-ellipsis> WIA Home </span> </a> </li> <li class=md-nav__item> <a href=../quotations/index.html class=md-nav__link> <span class=md-ellipsis> WIA Quotes </span> </a> </li> <li class=md-nav__item> <a href=../gk/index.html class=md-nav__link> <span class=md-ellipsis> GK Blog </span> </a> </li> <li class=md-nav__item> <a href=../booksummary/index.html class=md-nav__link> <span class=md-ellipsis> Book Summary </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../samskrutyatra/index.html class="md-nav__link "> <span class=md-ellipsis> Samskrut </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Samskrut </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/samskrut-home.html class=md-nav__link> <span class=md-ellipsis> SamskrutYatra Home </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#is-this-article-for-me class=md-nav__link> <span class=md-ellipsis> Is this article for me? </span> </a> </li> <li class=md-nav__item> <a href=#question-what-is-ollama-is-it-like-docker class=md-nav__link> <span class=md-ellipsis> Question: What is Ollama? Is it like Docker? </span> </a> <nav class=md-nav aria-label="Question: What is Ollama? Is it like Docker?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-features-of-ollama class=md-nav__link> <span class=md-ellipsis> Key Features of Ollama: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#question-how-is-ollama-different-from-docker class=md-nav__link> <span class=md-ellipsis> Question: How is Ollama different from Docker? </span> </a> </li> <li class=md-nav__item> <a href=#question-how-to-install-ollama-on-my-machine class=md-nav__link> <span class=md-ellipsis> Question: How to install ollama on my machine? </span> </a> </li> <li class=md-nav__item> <a href=#question-how-to-create-customized-llm-model-docker-like-image class=md-nav__link> <span class=md-ellipsis> Question: How to create customized LLM Model (docker like image)? </span> </a> </li> <li class=md-nav__item> <a href=#question-what-are-the-llm-available-on-ollama class=md-nav__link> <span class=md-ellipsis> Question: What are the LLM available on ollama? </span> </a> <nav class=md-nav aria-label="Question: What are the LLM available on ollama?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#chattingassistant class=md-nav__link> <span class=md-ellipsis> Chatting/Assistant/ </span> </a> </li> <li class=md-nav__item> <a href=#multimodal-vision class=md-nav__link> <span class=md-ellipsis> Multimodal &amp; Vision </span> </a> </li> <li class=md-nav__item> <a href=#math class=md-nav__link> <span class=md-ellipsis> Math </span> </a> </li> <li class=md-nav__item> <a href=#coding class=md-nav__link> <span class=md-ellipsis> Coding </span> </a> </li> <li class=md-nav__item> <a href=#embedding class=md-nav__link> <span class=md-ellipsis> Embedding </span> </a> </li> <li class=md-nav__item> <a href=#medical class=md-nav__link> <span class=md-ellipsis> Medical </span> </a> </li> <li class=md-nav__item> <a href=#function-calling class=md-nav__link> <span class=md-ellipsis> Function Calling </span> </a> </li> <li class=md-nav__item> <a href=#reasoning class=md-nav__link> <span class=md-ellipsis> Reasoning </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#question-can-we-integrate-these-hundreds-with-different-ui-like-chatgpt class=md-nav__link> <span class=md-ellipsis> Question: Can we integrate these hundreds with different UI like ChatGPT? </span> </a> </li> <li class=md-nav__item> <a href=#question-if-i-want-to-use-all-these-ollama-models-via-jupyter-notebook-then-what-to-do class=md-nav__link> <span class=md-ellipsis> Question: If I want to use all these Ollama models via Jupyter Notebook then what to do? </span> </a> </li> <li class=md-nav__item> <a href=#question-does-ollama-have-plugins-like-github-copilot-can-i-use-those-from-my-visual-code class=md-nav__link> <span class=md-ellipsis> Question: Does Ollama have plugins like github copilot? Can I use those from my visual code? </span> </a> </li> <li class=md-nav__item> <a href=#question-what-kind-of-software-are-lm-studio-or-ollama class=md-nav__link> <span class=md-ellipsis> Question: What kind of software are LM Studio or Ollama? </span> </a> </li> <li class=md-nav__item> <a href=#question-what-is-lm-studio-and-how-different-it-is-from-ollama class=md-nav__link> <span class=md-ellipsis> Question: What is LM Studio and how different it is from Ollama? </span> </a> <nav class=md-nav aria-label="Question: What is LM Studio and how different it is from Ollama?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#key-capabilities-of-ollama class=md-nav__link> <span class=md-ellipsis> Key Capabilities of Ollama: </span> </a> </li> <li class=md-nav__item> <a href=#key-capabilities-of-lm-studio class=md-nav__link> <span class=md-ellipsis> Key Capabilities of LM Studio: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#question-what-are-different-formats-to-save-model-specifically-llms class=md-nav__link> <span class=md-ellipsis> Question: What are different formats to save model, specifically LLMs? </span> </a> <nav class=md-nav aria-label="Question: What are different formats to save model, specifically LLMs?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-pytorch-pt-pth class=md-nav__link> <span class=md-ellipsis> 1. PyTorch (.pt, .pth) </span> </a> </li> <li class=md-nav__item> <a href=#2-tensorflow-pb-h5-tf class=md-nav__link> <span class=md-ellipsis> 2. TensorFlow (.pb, .h5, .tf) </span> </a> </li> <li class=md-nav__item> <a href=#3-onnx-onnx class=md-nav__link> <span class=md-ellipsis> 3. ONNX (.onnx) </span> </a> </li> <li class=md-nav__item> <a href=#4-openvino-bin-xml class=md-nav__link> <span class=md-ellipsis> 4. OpenVINO (.bin, .xml) </span> </a> </li> <li class=md-nav__item> <a href=#5-gguf-gguf class=md-nav__link> <span class=md-ellipsis> 5. GGUF (.gguf) </span> </a> </li> <li class=md-nav__item> <a href=#6-savedmodel-savedmodel class=md-nav__link> <span class=md-ellipsis> 6. SavedModel (SavedModel) </span> </a> </li> <li class=md-nav__item> <a href=#7-core-ml-mlmodel class=md-nav__link> <span class=md-ellipsis> 7. Core ML (.mlmodel) </span> </a> </li> <li class=md-nav__item> <a href=#8-tensorflow-lite-tflite class=md-nav__link> <span class=md-ellipsis> 8. TensorFlow Lite (.tflite) </span> </a> </li> <li class=md-nav__item> <a href=#9-hugging-face-bin-configjson-tokenizerjson class=md-nav__link> <span class=md-ellipsis> 9. Hugging Face (.bin, config.json, tokenizer.json) </span> </a> </li> <li class=md-nav__item> <a href=#10-hugging-face-safetensors class=md-nav__link> <span class=md-ellipsis> 10. Hugging Face (.safetensors) </span> </a> </li> <li class=md-nav__item> <a href=#summary-of-model-formats-including-safetensors class=md-nav__link> <span class=md-ellipsis> Summary of Model Formats Including SafeTensors: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#question-what-is-gguf-model-extention class=md-nav__link> <span class=md-ellipsis> Question: What is gguf model extention? </span> </a> </li> <li class=md-nav__item> <a href=#question-if-i-have-finetuned-my-models-using-clouds-like-aws-sagemaker-vertexai-azure-and-kept-there-then-can-i-use-them-inside-my-ollama-and-lm-studio class=md-nav__link> <span class=md-ellipsis> Question: If I have finetuned my models using clouds like aws sagemaker, vertexai, azure and kept there then can I use them inside my ollama and LM Studio? </span> </a> </li> <li class=md-nav__item> <a href=#references class=md-nav__link> <span class=md-ellipsis> References </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/dasarpai/dasrapai-mkdocs/edit/master/docs/dsblog/Exploring-Ollama.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/dasarpai/dasrapai-mkdocs/raw/master/docs/dsblog/Exploring-Ollama.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <p><img alt="Exploring Ollama & LM Studio" src=../assets/images/dspost/dsp6143-Exploring-Ollama.jpg></p> <h1 id=exploring-ollama-lm-studio>Exploring Ollama &amp; LM Studio<a class=headerlink href=#exploring-ollama-lm-studio title="Permanent link">&para;</a></h1> <h2 id=is-this-article-for-me>Is this article for me?<a class=headerlink href=#is-this-article-for-me title="Permanent link">&para;</a></h2> <p>If you are looking answers to the following questions, then this article is for you:</p> <ul> <li>Question: What is Ollama? Is it like Docker?</li> <li>Question: How is Ollama different from Docker?</li> <li>Question: How to install ollama on my machine?</li> <li>Question: How to create customized LLM Model (docker like image)?</li> <li>Question: What are the LLM available on ollama?</li> <li>Question: Can we integrate these hundreds with different UI like ChatGPT?</li> <li>Question: If I want to use all these Ollama models via Jupyter Notebook then what to do?</li> <li>Question: Does Ollama have plugins like github copilot? Can I use those from my visual code?</li> <li>Question: What kind of software are LM Studio or Ollama?</li> <li>Question: What is LM Studio and how different it is from Ollama?</li> <li>Question: What are different formats to save model, specifically LLMs?</li> <li>Question: What is gguf model extention?</li> <li>Question: If I have finetuned my models using clouds like aws sagemaker, vertexai, azure and kept there then can I use them inside my ollama and LM Studio?</li> </ul> <h2 id=question-what-is-ollama-is-it-like-docker>Question: What is Ollama? Is it like Docker?<a class=headerlink href=#question-what-is-ollama-is-it-like-docker title="Permanent link">&para;</a></h2> <p>Ollama is a platform designed to make running and interacting with large language models (LLMs) easier. It abstracts away the complexities of managing LLM models, GPU resources, and related configurations by offering a simple CLI interface. With Ollama, you can run, manage, and deploy LLMs locally or in various cloud environments without having to worry about the intricate details of setting up environments, downloading models, or configuring them.</p> <h3 id=key-features-of-ollama>Key Features of Ollama:<a class=headerlink href=#key-features-of-ollama title="Permanent link">&para;</a></h3> <ul> <li><strong>Model Management</strong>: Ollama can download and store LLMs in a local cache for you to run, typically in a format optimized for the hardware available (like your local GPU).</li> <li><strong>GPU/CPU Utilization</strong>: It detects hardware resources, such as your NVIDIA GPU, and automatically uses them for model acceleration without additional setup.</li> <li><strong>Service Setup</strong>: When you install Ollama, it sets up a service running in the background that serves models on an API, so you can interact with them programmatically.</li> </ul> <h2 id=question-how-is-ollama-different-from-docker>Question: How is Ollama different from Docker?<a class=headerlink href=#question-how-is-ollama-different-from-docker title="Permanent link">&para;</a></h2> <p>While Ollama and Docker both deal with isolated environments, they serve different purposes:</p> <ul> <li><strong>Ollama</strong> focuses specifically on running machine learning models, especially large language models, and optimizes resources to make them easily accessible and deployable.</li> <li><strong>Docker</strong> is a general-purpose containerization tool that allows you to package applications with their dependencies in isolated environments. It’s used for deploying a wide variety of applications, not just models.</li> </ul> <p>So, while Docker might also be used to set up machine learning environments or serve models, Ollama is specialized and optimized for the LLM use case.</p> <p>In Summary: <strong>Ollama</strong> = Model management platform for LLMs, with easy CLI and automatic resource optimization. <strong>Docker</strong> = General containerization tool for deploying all types of applications in isolated environments.</p> <h2 id=question-how-to-install-ollama-on-my-machine>Question: How to install ollama on my machine?<a class=headerlink href=#question-how-to-install-ollama-on-my-machine title="Permanent link">&para;</a></h2> <p>Refer: <a href=https://ollama.com/download/linux>https://ollama.com/download/linux</a>, and <a href=https://github.com/ollama/ollama>https://github.com/ollama/ollama</a>, and <a href=https://github.com/ollama/ollama-python>https://github.com/ollama/ollama-python</a> - To download Ollama on linux/wsl: <br> curl -fsSL <a href=https://ollama.com/install.sh>https://ollama.com/install.sh</a> | sh - To run <br> ollama run phi3 <br> <strong><font color=green><a href=http://127.0.0.1:11434/ >http://127.0.0.1:11434/</a> - ollama is running </font></strong></p> <h2 id=question-how-to-create-customized-llm-model-docker-like-image>Question: How to create customized LLM Model (docker like image)?<a class=headerlink href=#question-how-to-create-customized-llm-model-docker-like-image title="Permanent link">&para;</a></h2> <p>If you know the working of Docker image, container, docker hub, docker command then you will feel at home with ollama commands.</p> <p>Step 1: Create a ModelFile <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>FROM llama3.1
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a># set the temperature to 1 [higher is more creative, lower is more coherent]
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a>PARAMETER temperature 1
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a># set the system message
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a>SYSTEM &quot;&quot;&quot;
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a>You are Travel Advisor from Air India Airlines. Answer as AI Advisor, the assistant, only.
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>&quot;&quot;&quot;
</span></code></pre></div></p> <p>Step 2: Create and run the model <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>ollama create aiadvisor -f ./Modelfile
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>ollama run aiadvisor
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>&gt;&gt;&gt; hi
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>Hello! It&#39;s your friend AI Advisor.
</span></code></pre></div></p> <h2 id=question-what-are-the-llm-available-on-ollama>Question: What are the LLM available on ollama?<a class=headerlink href=#question-what-are-the-llm-available-on-ollama title="Permanent link">&para;</a></h2> <p>There are 100+ LLM available via ollama. They have different capabilities in terms of domain task like coding, embedding, reasoning, chatting, philosophy, medical, maths, function calling. And in terms of context window 8k, 16k, 24k, 128k etc. And in terms of hardware/gpu required or not to run these.</p> <h3 id=chattingassistant>Chatting/Assistant/<a class=headerlink href=#chattingassistant title="Permanent link">&para;</a></h3> <ol> <li>alfred: A robust conversational model designed to be used for both chat and instruct use cases.</li> <li>all-minilm: Embedding models on very large sentence level datasets.</li> <li>An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama.</li> <li>Aya 23, released by Cohere, is a new family of state-of-the-art, multilingual models that support 23 languages.</li> <li>bge-large: Embedding model from BAAI mapping texts to vectors.</li> <li>BGE-M3 is a new Embedding model from BAAI distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity.</li> <li>Command R is a Large Language Model optimized for conversational interaction and long context tasks.</li> <li>Command R+ is a powerful, scalable large language model purpose-built to excel at real-world enterprise use cases.</li> <li>DBRX is an open, general-purpose LLM created by Databricks.</li> <li>deepseek-llm: An advanced language model crafted with 2 trillion bilingual tokens.</li> <li>deepseek-v2: A strong, economical, and efficient Mixture-of-Experts language model.</li> <li>deepseek-v2.5: An upgraded version of DeekSeek-V2 that integrates the general and coding abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct.</li> <li>Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills.</li> <li>dolphin-mixtral: Uncensored, 8x7b and 8x22b fine-tuned models based on the Mixtral mixture of experts models that excels at coding tasks. Created by Eric Hartford.</li> <li>everythinglm: Uncensored Llama2 based model with support for a 16K context window.</li> <li>falcon: A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots.</li> <li>Gemma is a family of lightweight, state-of-the-art open models built by Google DeepMind.</li> <li>glm4: A strong multi-lingual general language model with competitive performance to Llama 3.</li> <li>goliath: A language model created by combining two fine-tuned Llama 2 70B models into one.</li> <li>Google Gemma 2 is a high-performing and efficient model available in three sizes: 2B, 9B, and 27B.</li> <li>Hermes 3 is the latest version of the flagship Hermes series of LLMs by Nous Research</li> <li>Llama 2 is a collection of foundation language models ranging from 7B to 70B parameters.</li> <li>Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.</li> <li>llama2-chinese: Llama 2 based model fine tuned to improve Chinese dialogue ability.</li> <li>llama3-chatqa: A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG).</li> <li>llama3-gradient: This model extends LLama-3 8B's context length from 8k to over 1m tokens.</li> <li>MegaDolphin-2.2-120b is a transformation of Dolphin-2.2-70b created by interleaving the model with itself.</li> <li>Meta Llama 3: The most capable openly available LLM to date</li> <li>Mistral OpenOrca is a 7 billion parameter model, fine-tuned on top of the Mistral 7B model using the OpenOrca dataset.</li> <li>mistral-nemo: A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.</li> <li>mistral-small: Mistral Small is a lightweight model designed for cost-effective use in tasks like translation and summarization.</li> <li>MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts.</li> <li>mixtral: A set of Mixture of Experts (MoE) model with open weights by Mistral AI in 8x7b and 8x22b parameter sizes.</li> <li>neural-chat: A fine-tuned model based on Mistral with good coverage of domain and language.</li> <li>notus: A 7B chat model fine-tuned with high-quality data and based on Zephyr.</li> <li>notux: A top-performing mixture of experts model, fine-tuned with high-quality data.</li> <li>nous-hermes: General use models based on Llama and Llama 2 from Nous Research.</li> <li>nous-hermes2: The powerful family of models by Nous Research that excels at scientific discussion and coding tasks.</li> <li>nuextract: A 3.8B model fine-tuned on a private high-quality synthetic dataset for information extraction, based on Phi-3.</li> <li>OpenHermes 2.5 is a 7B model fine-tuned by Teknium on Mistral with fully open datasets.</li> <li>orca-mini: A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware.</li> <li>Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.</li> <li>phi3.5: A lightweight AI model with 3.8 billion parameters with performance overtaking similarly and larger sized models.</li> <li>Qwen 1.5 is a series of large language models by Alibaba Cloud spanning from 0.5B to 110B parameters</li> <li>Qwen2 is a new series of large language models from Alibaba group</li> <li>reader-lm: A series of models that convert HTML content to Markdown content, which is useful for content conversion tasks.</li> <li>samantha-mistral: A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.</li> <li>smollm: A family of small models with 135M, 360M, and 1.7B parameters, trained on a new high-quality dataset.</li> <li>solar: A compact, yet powerful 10.7B large language model designed for single-turn conversation.</li> <li>Stable LM 2 is a state-of-the-art 1.6B and 12B parameter language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.</li> <li>stable-beluga: Llama 2 based model fine tuned on an Orca-style dataset. Originally called Free Willy.</li> <li>stablelm-zephyr: A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware.</li> <li>Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness.</li> <li>The Nous Hermes 2 model from Nous Research, now trained over Mixtral.</li> <li>The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.</li> <li>vicuna: General use chat model based on Llama and Llama 2 with 2K to 16K context sizes.</li> <li>Wizard Vicuna is a 13B parameter model based on Llama 2 trained by MelodysDreamj.</li> <li>Wizard Vicuna Uncensored is a 7B, 13B, and 30B parameter model based on Llama 2 uncensored by Eric Hartford.</li> <li>wizardlm-uncensored: Uncensored version of Wizard LM model</li> <li>xwinlm: Conversational model based on Llama 2 that performs competitively on various benchmarks.</li> <li>yarn-llama2: An extension of Llama 2 that supports a context of up to 128k tokens.</li> <li>yarn-mistral: An extension of Mistral to support context windows of 64K or 128K.</li> <li>Yi 1.5 is a high-performing, bilingual language model.</li> <li>Zephyr is a series of fine-tuned versions of the Mistral and Mixtral models that are trained to act as helpful assistants.</li> </ol> <h3 id=multimodal-vision>Multimodal &amp; Vision<a class=headerlink href=#multimodal-vision title="Permanent link">&para;</a></h3> <ol> <li>BakLLaVA is a multimodal (vision) model consisting of the Mistral 7B base model augmented with the LLaVA architecture.</li> <li>minicpm-v: A series of multimodal LLMs (MLLMs) designed for vision-language understanding.</li> <li>LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding.</li> <li>llava-llama3: A LLaVA (vision) model fine-tuned from Llama 3 Instruct with better scores in several benchmarks.</li> <li>llava-phi3: A new small LLaVA (vision) model fine-tuned from Phi 3 Mini.</li> <li>moondream2 is a small vision language model designed to run efficiently on edge devices.</li> </ol> <h3 id=math>Math<a class=headerlink href=#math title="Permanent link">&para;</a></h3> <ol> <li>llama-pro: An expansion of Llama 2 that specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics.</li> <li>Qwen2 Math is a series of specialized math language models built upon the Qwen2 LLMs, which significantly outperforms the mathematical capabilities of open-source models and even closed-source models (e.g., GPT4o).</li> <li>wizard-math: Model focused on math and logic problems</li> </ol> <h3 id=coding>Coding<a class=headerlink href=#coding title="Permanent link">&para;</a></h3> <ol> <li>codellama: A large language model that can use text prompts to generate and discuss code.</li> <li>codegeex4: A versatile model for AI software development scenarios, including code completion.</li> <li>codeup: Great code generation model based on Llama2.</li> <li>codebooga: A high-performing code instruct model created by merging two existing code models.</li> <li>Magicoder is a family of 7B parameter models trained on 75K synthetic instruction data using OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets.</li> <li>wizardcoder: State-of-the-art code generation model</li> <li>phind-codellama: Code generation model based on Code Llama.</li> <li>dolphincoder: A 7B and 15B uncensored variant of the Dolphin model family that excels at coding, based on StarCoder2.</li> <li>granite-code: A family of open foundation models by IBM for Code Intelligence</li> <li>deepseek-coder-v2: An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks.</li> <li>SQLCoder is a code completion model fined-tuned on StarCoder for SQL generation tasks</li> <li>StarCoder is a code generation model trained on 80+ programming languages.</li> <li>Yi-Coder is a series of open-source code language models that delivers state-of-the-art coding performance with fewer than 10 billion parameters.</li> <li>Codestral is Mistral AI’s first-ever code model designed for code generation tasks.</li> <li>Falcon2 is an 11B parameters causal decoder-only model built by TII and trained over 5T tokens.</li> <li>Stable Code 3B is a coding model with instruct and code completion variants on par with models such as Code Llama 7B that are 2.5x larger.</li> <li>StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters.</li> <li>DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.</li> <li>CodeQwen1.5 is a large language model pretrained on a large amount of code data.</li> <li>Mistral Large 2 is Mistral's new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages.</li> <li>open-orca-platypus2: Merge of the Open Orca OpenChat model and the Garage-bAInd Platypus 2 model. Designed for chat and code generation.</li> <li>CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following.</li> </ol> <h3 id=embedding>Embedding<a class=headerlink href=#embedding title="Permanent link">&para;</a></h3> <ol> <li>nomic-embed-text: A high-performing open embedding model with a large token context window.</li> <li>mxbai-embed-large</li> <li>snowflake-arctic-embed: A suite of text embedding models by Snowflake, optimized for performance.</li> <li>State-of-the-art large embedding model from mixedbread.ai</li> <li>paraphrase-multilingual: Sentence-transformers (embedding) model that can be used for tasks like clustering or semantic search.</li> </ol> <h3 id=medical>Medical<a class=headerlink href=#medical title="Permanent link">&para;</a></h3> <ol> <li>medllama2: Fine-tuned Llama 2 model to answer medical questions based on an open source medical dataset.</li> <li>meditron: Open-source medical large language model adapted from Llama 2 to the medical domain.</li> </ol> <h3 id=function-calling>Function Calling<a class=headerlink href=#function-calling title="Permanent link">&para;</a></h3> <ol> <li>Nexus Raven is a 13B instruction tuned model for function calling tasks.</li> <li>llama3-groq-tool-use: A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling.</li> <li>firefunction-v2: An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities.</li> </ol> <h3 id=reasoning>Reasoning<a class=headerlink href=#reasoning title="Permanent link">&para;</a></h3> <ol> <li>mathstral: MathΣtral: a 7B model designed for math reasoning and scientific discovery by Mistral AI.</li> <li>Phi-2: a 2.7B language model by Microsoft Research that demonstrates outstanding reasoning and language understanding capabilities.</li> <li>InternLM2.5 is a 7B parameter model tailored for practical scenarios with outstanding reasoning capability.</li> <li>wizardlm2: State of the art large language model from Microsoft AI with improved performance on complex chat, multilingual, reasoning and agent use cases.</li> <li>reflection: A high-performing model trained with a new technique called Reflection-tuning that teaches a LLM to detect mistakes in its reasoning and correct course.</li> <li>Orca 2 is built by Microsoft research, and are a fine-tuned version of Meta's Llama 2 models. The model is designed to excel particularly in reasoning.</li> </ol> <h2 id=question-can-we-integrate-these-hundreds-with-different-ui-like-chatgpt>Question: Can we integrate these hundreds with different UI like ChatGPT?<a class=headerlink href=#question-can-we-integrate-these-hundreds-with-different-ui-like-chatgpt title="Permanent link">&para;</a></h2> <p>Yes, in fact you need NOT to create any new UI. Hundreds of good UI are available which are integrated with these hundreds of LLMs available on Ollama. You can see below some of the popular UI via which Ollama models can be accessed.</p> <ul> <li><a href=https://github.com/open-webui/open-webui>Open WebUI</a></li> <li><a href=https://github.com/AugustDev/enchanted>Enchanted (macOS native)</a></li> <li><a href=https://github.com/fmaclen/hollama>Hollama</a></li> <li><a href=https://github.com/ParisNeo/lollms-webui>Lollms-Webui</a></li> <li><a href=https://github.com/danny-avila/LibreChat>LibreChat</a></li> <li><a href=https://github.com/bionic-gpt/bionic-gpt>Bionic GPT</a></li> <li><a href=https://github.com/rtcfirefly/ollama-ui>HTML UI</a></li> <li><a href=https://github.com/jikkuatwork/saddle>Saddle</a></li> <li><a href=https://github.com/ivanfioravanti/chatbot-ollama>Chatbot UI</a></li> <li><a href=https://github.com/mckaywrigley/chatbot-ui>Chatbot UI v2</a></li> <li><a href="https://github.com/ollama-interface/Ollama-Gui?tab=readme-ov-file">Typescript UI</a></li> <li><a href=https://github.com/richawo/minimal-llm-ui>Minimalistic React UI for Ollama Models</a></li> <li><a href=https://github.com/kevinhermawan/Ollamac>Ollamac</a></li> <li><a href=https://github.com/enricoros/big-AGI/blob/main/docs/config-local-ollama.md>big-AGI</a></li> <li><a href=https://github.com/cheshire-cat-ai/core>Cheshire Cat assistant framework</a></li> <li><a href=https://github.com/semperai/amica>Amica</a></li> <li><a href=https://github.com/BruceMacD/chatd>chatd</a></li> <li><a href=https://github.com/kghandour/Ollama-SwiftUI>Ollama-SwiftUI</a></li> <li><a href=https://github.com/langgenius/dify>Dify.AI</a></li> <li><a href=https://mindmac.app>MindMac</a></li> <li><a href=https://github.com/jakobhoeg/nextjs-ollama-llm-ui>NextJS Web Interface for Ollama</a></li> <li><a href=https://msty.app>Msty</a></li> <li><a href=https://github.com/Bin-Huang/Chatbox>Chatbox</a></li> <li><a href=https://github.com/tgraupmann/WinForm_Ollama_Copilot>WinForm Ollama Copilot</a></li> <li><a href=https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web>NextChat</a> with <a href=https://docs.nextchat.dev/models/ollama>Get Started Doc</a></li> <li><a href=https://github.com/mmo80/alpaca-webui>Alpaca WebUI</a></li> <li><a href=https://github.com/enoch1118/ollamaGUI>OllamaGUI</a></li> <li><a href=https://github.com/InternLM/OpenAOE>OpenAOE</a></li> <li><a href=https://github.com/leonid20000/OdinRunes>Odin Runes</a></li> <li><a href=https://github.com/mrdjohnson/llm-x>LLM-X</a> (Progressive Web App)</li> <li><a href=https://github.com/Mintplex-Labs/anything-llm>AnythingLLM (Docker + MacOs/Windows/Linux native app)</a></li> <li><a href=https://github.com/rapidarchitect/ollama_basic_chat>Ollama Basic Chat: Uses HyperDiv Reactive UI</a></li> <li><a href=https://github.com/drazdra/ollama-chats>Ollama-chats RPG</a></li> <li><a href=https://github.com/reid41/QA-Pilot>QA-Pilot</a> (Chat with Code Repository)</li> <li><a href=https://github.com/sugarforever/chat-ollama>ChatOllama</a> (Open Source Chatbot based on Ollama with Knowledge Bases)</li> <li><a href=https://github.com/Nagi-ovo/CRAG-Ollama-Chat>CRAG Ollama Chat</a> (Simple Web Search with Corrective RAG)</li> <li><a href=https://github.com/infiniflow/ragflow>RAGFlow</a> (Open-source Retrieval-Augmented Generation engine based on deep document understanding)</li> <li><a href=https://github.com/StreamDeploy-DevRel/streamdeploy-llm-app-scaffold>StreamDeploy</a> (LLM Application Scaffold)</li> <li><a href=https://github.com/swuecho/chat>chat</a> (chat web app for teams)</li> <li><a href=https://github.com/lobehub/lobe-chat>Lobe Chat</a> with <a href=https://lobehub.com/docs/self-hosting/examples/ollama>Integrating Doc</a></li> <li><a href=https://github.com/datvodinh/rag-chatbot.git>Ollama RAG Chatbot</a> (Local Chat with multiple PDFs using Ollama and RAG)</li> <li><a href=https://www.nurgo-software.com/products/brainsoup>BrainSoup</a> (Flexible native client with RAG &amp; multi-agent automation)</li> <li><a href=https://github.com/Renset/macai>macai</a> (macOS client for Ollama, ChatGPT, and other compatible API back-ends)</li> <li><a href=https://github.com/Otacon/olpaka>Olpaka</a> (User-friendly Flutter Web App for Ollama)</li> <li><a href=https://github.com/CrazyNeil/OllamaSpring>OllamaSpring</a> (Ollama Client for macOS)</li> <li><a href=https://github.com/kartikm7/llocal>LLocal.in</a> (Easy to use Electron Desktop Client for Ollama)</li> <li><a href=https://github.com/zeyoyt/ailama>AiLama</a> (A Discord User App that allows you to interact with Ollama anywhere in discord )</li> <li><a href=https://github.com/rapidarchitect/ollama_mesop/ >Ollama with Google Mesop</a> (Mesop Chat Client implementation with Ollama)</li> <li><a href=https://github.com/mateuszmigas/painting-droid>Painting Droid</a> (Painting app with AI integrations)</li> <li><a href=https://www.kerlig.com/ >Kerlig AI</a> (AI writing assistant for macOS)</li> <li><a href=https://github.com/MindWorkAI/AI-Studio>AI Studio</a></li> <li><a href=https://github.com/gyopak/sidellama>Sidellama</a> (browser-based LLM client)</li> <li><a href=https://github.com/trypromptly/LLMStack>LLMStack</a> (No-code multi-agent framework to build LLM agents and workflows)</li> <li><a href=https://boltai.com>BoltAI for Mac</a> (AI Chat Client for Mac)</li> <li><a href=https://github.com/av/harbor>Harbor</a> (Containerized LLM Toolkit with Ollama as default backend)</li> <li><a href=https://www.jonathanhecl.com/go-crew/ >Go-CREW</a> (Powerful Offline RAG in Golang)</li> <li><a href=https://github.com/openvmp/partcad/ >PartCAD</a> (CAD model generation with OpenSCAD and CadQuery)</li> <li><a href=https://github.com/ollama4j/ollama4j-web-ui>Ollama4j Web UI</a> - Java-based Web UI for Ollama built with Vaadin, Spring Boot and Ollama4j</li> <li><a href=https://github.com/kspviswa/pyOllaMx>PyOllaMx</a> - macOS application capable of chatting with both Ollama and Apple MLX models.</li> <li><a href=https://github.com/saoudrizwan/claude-dev>Claude Dev</a> - VSCode extension for multi-file/whole-repo coding</li> <li><a href=https://github.com/kangfenmao/cherry-studio>Cherry Studio</a> (Desktop client with Ollama support)</li> <li><a href=https://github.com/1runeberg/confichat>ConfiChat</a> (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)</li> <li><a href=https://github.com/nickthecook/archyve>Archyve</a> (RAG-enabling document library)</li> <li><a href=https://github.com/rapidarchitect/ollama-crew-mesop>crewAI with Mesop</a> (Mesop Web Interface to run crewAI with Ollama)</li> </ul> <p>For mobile UI, you can explore these resources. * <a href=https://github.com/AugustDev/enchanted>Enchanted</a> * <a href=https://github.com/Mobile-Artificial-Intelligence/maid>Maid</a> * <a href=https://github.com/1runeberg/confichat>ConfiChat</a> (Lightweight, standalone, multi-platform, and privacy focused LLM chat interface with optional encryption)</p> <h2 id=question-if-i-want-to-use-all-these-ollama-models-via-jupyter-notebook-then-what-to-do>Question: If I want to use all these Ollama models via Jupyter Notebook then what to do?<a class=headerlink href=#question-if-i-want-to-use-all-these-ollama-models-via-jupyter-notebook-then-what-to-do title="Permanent link">&para;</a></h2> <p>There are dozens of libraries which integrate ollama models. You can pip install and use these libraries in your python code. Some of these popular libraries are: * <a href=https://python.langchain.com/docs/integrations/llms/ollama>LangChain</a> and <a href=https://js.langchain.com/docs/modules/model_io/models/llms/integrations/ollama>LangChain.js</a> with <a href=https://js.langchain.com/docs/use_cases/question_answering/local_retrieval_qa>example</a> * <a href=https://firebase.google.com/docs/genkit/plugins/ollama>Firebase Genkit</a> * <a href=https://github.com/crewAIInc/crewAI>crewAI</a> * <a href=https://github.com/tmc/langchaingo/ >LangChainGo</a> with <a href=https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example>example</a> * <a href=https://github.com/langchain4j/langchain4j>LangChain4j</a> with <a href=https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java>example</a> * <a href=https://github.com/Abraxas-365/langchain-rust>LangChainRust</a> with <a href=https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs>example</a> * <a href=https://gpt-index.readthedocs.io/en/stable/examples/llm/ollama.html>LlamaIndex</a> * <a href=https://github.com/BerriAI/litellm>LiteLLM</a> * <a href=https://github.com/presbrey/ollamafarm>OllamaFarm for Go</a> * <a href=https://github.com/awaescher/OllamaSharp>OllamaSharp for .NET</a> * <a href=https://github.com/gbaptista/ollama-ai>Ollama for Ruby</a> * <a href=https://github.com/pepperoni21/ollama-rs>Ollama-rs for Rust</a> * <a href=https://github.com/jmont-dev/ollama-hpp>Ollama-hpp for C++</a> * <a href=https://github.com/ollama4j/ollama4j>Ollama4j for Java</a> * <a href=https://modelfusion.dev/integration/model-provider/ollama>ModelFusion Typescript Library</a> * <a href=https://github.com/kevinhermawan/OllamaKit>OllamaKit for Swift</a> * <a href=https://github.com/breitburg/dart-ollama>Ollama for Dart</a> * <a href=https://github.com/cloudstudio/ollama-laravel>Ollama for Laravel</a> * <a href=https://github.com/davidmigloz/langchain_dart>LangChainDart</a> * <a href=https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama>Semantic Kernel - Python</a> * <a href=https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md>Haystack</a> * <a href=https://github.com/brainlid/langchain>Elixir LangChain</a> * <a href=https://github.com/JBGruber/rollama>Ollama for R - rollama</a> * <a href=https://github.com/hauselin/ollama-r>Ollama for R - ollama-r</a> * <a href=https://github.com/lebrunel/ollama-ex>Ollama-ex for Elixir</a> * <a href=https://github.com/b-tocs/abap_btocs_ollama>Ollama Connector for SAP ABAP</a> * <a href=https://testcontainers.com/modules/ollama/ >Testcontainers</a> * <a href=https://portkey.ai/docs/welcome/integration-guides/ollama>Portkey</a> * <a href=https://github.com/svilupp/PromptingTools.jl>PromptingTools.jl</a> with an <a href=https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama>example</a> * <a href=https://github.com/Project-Llama/llamascript>LlamaScript</a> * <a href=https://docs.gollm.co/examples/ollama-example>Gollm</a> * <a href=https://github.com/xyproto/ollamaclient>Ollamaclient for Golang</a> * <a href=https://gitlab.com/tozd/go/fun>High-level function abstraction in Go</a> * <a href=https://github.com/ArdaGnsrn/ollama-php>Ollama PHP</a> * <a href=https://github.com/agents-flex/agents-flex>Agents-Flex for Java</a> with <a href=https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama>example</a></p> <h2 id=question-does-ollama-have-plugins-like-github-copilot-can-i-use-those-from-my-visual-code>Question: Does Ollama have plugins like github copilot? Can I use those from my visual code?<a class=headerlink href=#question-does-ollama-have-plugins-like-github-copilot-can-i-use-those-from-my-visual-code title="Permanent link">&para;</a></h2> <p>Yes, there are many plugins like that for different purpose apart from coding. Even for the coding there are dozens of plugin available with different capabilities. And you need not to pay for these plugins like you have to pay monthly to Micorosoft! Some of those plugins are :</p> <ul> <li><a href=https://github.com/ex3ndr/llama-coder>Llama Coder</a> (Copilot alternative using Ollama)</li> <li><a href=https://github.com/bernardo-bruning/ollama-copilot>Ollama Copilot</a> (Proxy that allows you to use ollama as a copilot like Github copilot)</li> <li><a href=https://github.com/logancyang/obsidian-copilot>Copilot for Obsidian plugin</a></li> <li><a href=https://github.com/MassimilianoPasquini97/raycast_ollama>Raycast extension</a></li> <li><a href=https://github.com/mxyng/discollama>Discollama</a> (Discord bot inside the Ollama discord channel)</li> <li><a href=https://github.com/continuedev/continue>Continue</a></li> <li><a href=https://github.com/hinterdupfinger/obsidian-ollama>Obsidian Ollama plugin</a></li> <li><a href=https://github.com/omagdy7/ollama-logseq>Logseq Ollama plugin</a></li> <li><a href=https://github.com/andersrex/notesollama>NotesOllama</a> (Apple Notes Ollama plugin)</li> <li><a href=https://github.com/samalba/dagger-chatbot>Dagger Chatbot</a></li> <li><a href=https://github.com/mekb-turtle/discord-ai-bot>Discord AI Bot</a></li> <li><a href=https://github.com/ruecat/ollama-telegram>Ollama Telegram Bot</a></li> <li><a href=https://github.com/ej52/hass-ollama-conversation>Hass Ollama Conversation</a></li> <li><a href=https://github.com/abrenneke/rivet-plugin-ollama>Rivet plugin</a></li> <li><a href=https://github.com/longy2k/obsidian-bmo-chatbot>Obsidian BMO Chatbot plugin</a></li> <li><a href=https://github.com/herval/cliobot>Cliobot</a> (Telegram bot with Ollama support)</li> <li><a href=https://github.com/pfrankov/obsidian-local-gpt>Obsidian Local GPT plugin</a></li> <li><a href=https://docs.openinterpreter.com/language-model-setup/local-models/ollama>Open Interpreter</a></li> <li><a href=https://github.com/rjmacarthy/twinny>twinny</a> (Copilot and Copilot chat alternative using Ollama)</li> <li><a href=https://github.com/RussellCanfield/wingman-ai>Wingman-AI</a> (Copilot code and chat alternative using Ollama and Hugging Face)</li> <li><a href=https://github.com/n4ze3m/page-assist>Page Assist</a> (Chrome Extension)</li> <li><a href=https://github.com/imoize/plasmoid-ollamacontrol>Plasmoid Ollama Control</a> (KDE Plasma extension that allows you to quickly manage/control Ollama model)</li> <li><a href=https://github.com/tusharhero/aitelegrambot>AI Telegram Bot</a> (Telegram bot using Ollama in backend)</li> <li><a href=https://github.com/yaroslavyaroslav/OpenAI-sublime-text>AI ST Completion</a> (Sublime Text 4 AI assistant plugin with Ollama support)</li> <li><a href=https://github.com/kevinthedang/discord-ollama>Discord-Ollama Chat Bot</a> (Generalized TypeScript Discord Bot w/ Tuning Documentation)</li> <li><a href=https://github.com/rapmd73/Companion>Discord AI chat/moderation bot</a> Chat/moderation bot written in python. Uses Ollama to create personalities.</li> <li><a href=https://github.com/nischalj10/headless-ollama>Headless Ollama</a> (Scripts to automatically install ollama client &amp; models on any OS for apps that depends on ollama server)</li> <li><a href=https://github.com/jk011ru/vnc-lm>vnc-lm</a> (A containerized Discord bot with support for attachments and web links)</li> <li><a href=https://github.com/SilasMarvin/lsp-ai>LSP-AI</a> (Open-source language server for AI-powered functionality)</li> <li><a href=https://github.com/Palm1r/QodeAssist>QodeAssist</a> (AI-powered coding assistant plugin for Qt Creator)</li> <li><a href=https://github.com/ECuiDev/obsidian-quiz-generator>Obsidian Quiz Generator plugin</a></li> </ul> <h2 id=question-what-kind-of-software-are-lm-studio-or-ollama>Question: What kind of software are LM Studio or Ollama?<a class=headerlink href=#question-what-kind-of-software-are-lm-studio-or-ollama title="Permanent link">&para;</a></h2> <p>Their role is to facilitate easy use of these models by providing a platform that supports multiple models, offering features like local deployment, training, and experimentation without needing to deal with the complex setup each model requires.</p> <p>They are platform or interface for LLM: Both Ollama and LM Studio are software tools that allow users to interact with, run, fine-tune, and experiment with multiple large language models. They are more like model management tools or LLM execution environments rather than models themselves.</p> <p>They are Model Hub: These tools serve as hubs where you can load, execute, and work with a variety of pre-trained LLMs. Instead of being limited to one specific model like GPT-4, they allow users to work with models like LLaMA, GPT-3, GPT-4, and others.</p> <p>They are Model Runners: Since they enable the running and execution of multiple models.</p> <p>They are LLM Execution/Management Tools: They manage various models and allow you to deploy them.</p> <p>You can think of them as infrastructure that abstracts away the complexities of working with different LLMs.</p> <h2 id=question-what-is-lm-studio-and-how-different-it-is-from-ollama>Question: What is LM Studio and how different it is from Ollama?<a class=headerlink href=#question-what-is-lm-studio-and-how-different-it-is-from-ollama title="Permanent link">&para;</a></h2> <p><strong>Ollama</strong> is designed for ease of use and running pre-trained models locally, perfect for developers and non-technical users who prioritize simplicity, privacy, and API-based integration. <strong>LM Studio</strong> is a research-oriented tool for AI engineers and researchers who need in-depth control over model fine-tuning, training, and experimentation, with a steeper learning curve but greater flexibility.</p> <p>Here's a detailed comparison of <strong>Ollama</strong> and <strong>LM Studio</strong> in terms of their capabilities:</p> <table> <thead> <tr> <th><strong>Feature/Capability</strong></th> <th><strong>Ollama</strong></th> <th><strong>LM Studio</strong></th> </tr> </thead> <tbody> <tr> <td><strong>Primary Purpose</strong></td> <td>Run and manage multiple LLMs locally</td> <td>Research, experimentation, fine-tuning, and training of LLMs</td> </tr> <tr> <td><strong>Supported Models</strong></td> <td>LLaMA, GPT-3, GPT-4, and other popular LLMs</td> <td>LLaMA, GPT, custom LLMs, and more, with a focus on fine-tuning</td> </tr> <tr> <td><strong>Local Model Execution</strong></td> <td>Supports running models locally without cloud dependencies</td> <td>Allows for local execution, including training and experimentation</td> </tr> <tr> <td><strong>Model Fine-tuning/Training</strong></td> <td>No, typically runs pre-trained models</td> <td>Yes, built for fine-tuning LLMs on custom datasets</td> </tr> <tr> <td><strong>Experimentation Tools</strong></td> <td>Minimal experimentation features, more focused on simple deployment</td> <td>Extensive tools for experimenting with models, datasets, and hyperparameters</td> </tr> <tr> <td><strong>Ease of Use</strong></td> <td>Simple, user-friendly interface for non-technical users</td> <td>More advanced, with a steeper learning curve but richer in functionality for researchers</td> </tr> <tr> <td><strong>Hardware Requirements</strong></td> <td>Optimized for running on GPUs or CPUs locally</td> <td>Requires higher-end hardware (GPUs) for fine-tuning and training</td> </tr> <tr> <td><strong>Privacy</strong></td> <td>Strong privacy due to local model execution</td> <td>Supports local execution for privacy, but also scales to cloud-based setups</td> </tr> <tr> <td><strong>API Integration</strong></td> <td>Yes, offers APIs to integrate LLMs into custom applications</td> <td>Primarily a standalone platform, with some ability for integration into workflows</td> </tr> <tr> <td><strong>Cloud Integration</strong></td> <td>Primarily local execution; not designed for cloud-based workflows</td> <td>Supports both local and cloud-based training environments, useful for large-scale training</td> </tr> <tr> <td><strong>Model Deployment</strong></td> <td>Can be deployed locally or integrated via API into applications</td> <td>Typically used for experimentation, research, and training, with some deployment capabilities</td> </tr> <tr> <td><strong>Pre-Trained Models</strong></td> <td>Easy access to pre-trained models (LLaMA, GPT, etc.)</td> <td>Access to a variety of pre-trained models (hugging face and others), with emphasis on customization and fine-tuning</td> </tr> <tr> <td><strong>Target Audience</strong></td> <td>Developers, non-technical users who want easy local LLM access</td> <td>AI researchers, developers, engineers who require deeper control and experimentation</td> </tr> <tr> <td><strong>Community &amp; Support</strong></td> <td>Developer-focused community</td> <td>Strong research community with contributions from AI developers</td> </tr> </tbody> </table> <h3 id=key-capabilities-of-ollama>Key Capabilities of <strong>Ollama</strong>:<a class=headerlink href=#key-capabilities-of-ollama title="Permanent link">&para;</a></h3> <ol> <li><strong>Run LLMs Locally</strong>: Focuses on running pre-trained models such as GPT-3, GPT-4, and LLaMA on your local machine without requiring cloud dependencies.</li> <li><strong>Simple Setup</strong>: Aimed at developers and non-technical users who want easy access to LLMs.</li> <li><strong>Privacy &amp; Security</strong>: Since models run locally, no data is sent to external servers, enhancing privacy.</li> <li><strong>API Integration</strong>: Provides APIs to integrate models into applications, making it useful for local deployment.</li> <li><strong>Resource Optimization</strong>: Automatically manages local system resources, including CPU and GPU, to run models efficiently.</li> </ol> <h3 id=key-capabilities-of-lm-studio>Key Capabilities of <strong>LM Studio</strong>:<a class=headerlink href=#key-capabilities-of-lm-studio title="Permanent link">&para;</a></h3> <ol> <li><strong>Fine-Tuning LLMs</strong>: Supports fine-tuning pre-trained LLMs on custom datasets, ideal for research and development.</li> <li><strong>Model Training</strong>: Enables the training of LLMs from scratch or with specific hyperparameter configurations.</li> <li><strong>Advanced Experimentation</strong>: Provides tools to run experiments, tweak models, and monitor results for research purposes.</li> <li><strong>Customizable Infrastructure</strong>: Gives more control over hardware resources and configuration, allowing for scaling on cloud or local machines.</li> <li><strong>Open-Source Platform</strong>: Built for researchers, it has a rich ecosystem of community-driven features and tools.</li> </ol> <h2 id=question-what-are-different-formats-to-save-model-specifically-llms>Question: What are different formats to save model, specifically LLMs?<a class=headerlink href=#question-what-are-different-formats-to-save-model-specifically-llms title="Permanent link">&para;</a></h2> <p>Large language models (LLMs) can be stored in various formats, each suited for different purposes and platforms. These formats cater to different needs, from interoperability between frameworks (ONNX) to specific hardware optimizations (OpenVINO, TensorFlow Lite). The choice of format depends on the specific requirements of the deployment environment and the tools being used.</p> <p>Here are some common model formats used for LLMs:</p> <h3 id=1-pytorch-pt-pth><strong>1. PyTorch (<code>.pt</code>, <code>.pth</code>)</strong><a class=headerlink href=#1-pytorch-pt-pth title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: Files with <code>.pt</code> or <code>.pth</code> extensions are commonly used to store PyTorch models. These files contain the model's weights and architecture.</li> <li><strong>Usage</strong>: Typically used with PyTorch frameworks for loading and running models.</li> <li><strong>Example</strong>: Models saved using <code>torch.save(model.state_dict(), 'model.pth')</code>.</li> </ul> <h3 id=2-tensorflow-pb-h5-tf><strong>2. TensorFlow (<code>.pb</code>, <code>.h5</code>, <code>.tf</code>)</strong><a class=headerlink href=#2-tensorflow-pb-h5-tf title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: TensorFlow models can be saved in multiple formats:</li> <li><strong><code>.pb</code> (Protocol Buffers)</strong>: Used for saving the complete model, including weights and architecture.</li> <li><strong><code>.h5</code> (HDF5)</strong>: Used for saving models in Keras (which is a high-level API for TensorFlow).</li> <li><strong><code>.tf</code></strong>: Used for saving TensorFlow models in the SavedModel format.</li> <li><strong>Usage</strong>: Used with TensorFlow for model deployment and inference.</li> <li><strong>Example</strong>: Models saved using <code>model.save('model.h5')</code> or <code>tf.saved_model.save(model, 'saved_model')</code>.</li> </ul> <h3 id=3-onnx-onnx><strong>3. ONNX (<code>.onnx</code>)</strong><a class=headerlink href=#3-onnx-onnx title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: Open Neural Network Exchange (ONNX) is a format for representing deep learning models. It allows interoperability between different deep learning frameworks.</li> <li><strong>Usage</strong>: Enables models trained in one framework (like PyTorch) to be used in another (like TensorFlow).</li> <li><strong>Example</strong>: Models converted to ONNX using <code>torch.onnx.export(model, inputs, 'model.onnx')</code>.</li> </ul> <h3 id=4-openvino-bin-xml><strong>4. OpenVINO (<code>.bin</code>, <code>.xml</code>)</strong><a class=headerlink href=#4-openvino-bin-xml title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: OpenVINO uses <code>.bin</code> and <code>.xml</code> files to represent optimized models for Intel hardware.</li> <li><strong>Usage</strong>: Provides acceleration for inference on Intel devices.</li> <li><strong>Example</strong>: Models optimized with OpenVINO are stored in <code>.xml</code> (model structure) and <code>.bin</code> (weights) files.</li> </ul> <h3 id=5-gguf-gguf><strong>5. GGUF (<code>.gguf</code>)</strong><a class=headerlink href=#5-gguf-gguf title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: Generalized Graph Universal Format (GGUF) is a format used by Meta for storing LLaMA models. It provides a standardized way to store and share large language models.</li> <li><strong>Usage</strong>: <font color=green>Specifically designed for LLaMA models but can be used more broadly for LLMs.</font></li> <li><strong>Example</strong>: Models saved in GGUF format will have the <code>.gguf</code> file extension.</li> </ul> <h3 id=6-savedmodel-savedmodel><strong>6. SavedModel (<code>SavedModel</code>)</strong><a class=headerlink href=#6-savedmodel-savedmodel title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: TensorFlow's SavedModel format includes a directory with serialized model weights, graph definitions, and metadata.</li> <li><strong>Usage</strong>: TensorFlow's recommended format for serving models in production.</li> <li><strong>Example</strong>: SavedModel format directory includes files like <code>saved_model.pb</code> and a variables directory.</li> </ul> <h3 id=7-core-ml-mlmodel><strong>7. Core ML (<code>.mlmodel</code>)</strong><a class=headerlink href=#7-core-ml-mlmodel title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: Apple's Core ML format is used for deploying models on iOS, macOS, watchOS, and tvOS.</li> <li><strong>Usage</strong>: Used for integrating machine learning models into Apple applications.</li> <li><strong>Example</strong>: Models converted to Core ML using tools like <code>coremltools</code>.</li> </ul> <h3 id=8-tensorflow-lite-tflite><strong>8. TensorFlow Lite (<code>.tflite</code>)</strong><a class=headerlink href=#8-tensorflow-lite-tflite title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: A format for deploying TensorFlow models on mobile and edge devices. It provides a smaller, more efficient representation of the model.</li> <li><strong>Usage</strong>: Optimized for mobile and embedded devices.</li> <li><strong>Example</strong>: Models converted to TensorFlow Lite format using <code>tf.lite.TFLiteConverter</code>.</li> </ul> <h3 id=9-hugging-face-bin-configjson-tokenizerjson><strong>9. Hugging Face (<code>.bin</code>, <code>config.json</code>, <code>tokenizer.json</code>)</strong><a class=headerlink href=#9-hugging-face-bin-configjson-tokenizerjson title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: Hugging Face models typically use <code>.bin</code> files for weights and JSON files for configuration and tokenizers. This format is often associated with the Transformers library.</li> <li><strong>Usage</strong>: Used with Hugging Face’s Transformers library for loading and fine-tuning models.</li> <li><strong>Example</strong>: Models from Hugging Face's model hub include <code>.bin</code> files for weights and configuration files.</li> </ul> <h3 id=10-hugging-face-safetensors><strong>10. Hugging Face (<code>.safetensors</code>)</strong><a class=headerlink href=#10-hugging-face-safetensors title="Permanent link">&para;</a></h3> <ul> <li><strong>Description</strong>: SafeTensors (developed recently by hugging face) is a format developed for safely and efficiently storing tensor data, particularly for large language models. It aims to provide secure and consistent handling of model weights.</li> <li><strong>Usage</strong>: Designed to improve safety and integrity in model storage by addressing issues related to file corruption and ensuring the integrity of the model data. It's increasingly used in machine learning and AI communities for its security benefits.</li> <li><strong>Key Features</strong>:</li> <li><strong>Safety</strong>: Ensures data integrity and helps prevent corruption.</li> <li><strong>Efficiency</strong>: Optimized for storage and retrieval of large model weights.</li> <li><strong>Compatibility</strong>: Designed to be used with various frameworks and tools that support tensor-based models.</li> </ul> <h3 id=summary-of-model-formats-including-safetensors>Summary of Model Formats Including SafeTensors:<a class=headerlink href=#summary-of-model-formats-including-safetensors title="Permanent link">&para;</a></h3> <ol> <li><strong>PyTorch (<code>.pt</code>, <code>.pth</code>)</strong></li> <li><strong>TensorFlow (<code>.pb</code>, <code>.h5</code>, <code>.tf</code>)</strong></li> <li><strong>ONNX (<code>.onnx</code>)</strong></li> <li><strong>Hugging Face (<code>.bin</code>, <code>config.json</code>, <code>tokenizer.json</code>)</strong></li> <li><strong>GGUF (<code>.gguf</code>)</strong></li> <li><strong>SavedModel (<code>SavedModel</code>)</strong></li> <li><strong>Core ML (<code>.mlmodel</code>)</strong></li> <li><strong>TensorFlow Lite (<code>.tflite</code>)</strong></li> <li><strong>OpenVINO (<code>.bin</code>, <code>.xml</code>)</strong></li> <li><strong>SafeTensors (<code>.safetensors</code>)</strong></li> </ol> <h2 id=question-what-is-gguf-model-extention>Question: What is gguf model extention?<a class=headerlink href=#question-what-is-gguf-model-extention title="Permanent link">&para;</a></h2> <p>The <strong>GGUF</strong> (Generalized Graph Universal Format) is designed to provide a standardized format for storing and sharing large language models. It aims to facilitate the interoperability of models across different platforms and tools. GGUF is particularly associated with Meta’s LLaMA (Large Language Model Meta AI) series of models. It is used for representing the weights and configurations of these models in a way that can be easily loaded and utilized across different environments.</p> <p>GGUF format aims: - <strong>Standardization</strong>: GGUF aims to standardize how model data is stored and exchanged, making it easier to work with LLaMA models and potentially other models that adopt this format. - <strong>Efficiency</strong>: The format is designed to efficiently handle the large size of modern language models, ensuring that models can be loaded and processed quickly.</p> <h2 id=question-if-i-have-finetuned-my-models-using-clouds-like-aws-sagemaker-vertexai-azure-and-kept-there-then-can-i-use-them-inside-my-ollama-and-lm-studio>Question: If I have finetuned my models using clouds like aws sagemaker, vertexai, azure and kept there then can I use them inside my ollama and LM Studio?<a class=headerlink href=#question-if-i-have-finetuned-my-models-using-clouds-like-aws-sagemaker-vertexai-azure-and-kept-there-then-can-i-use-them-inside-my-ollama-and-lm-studio title="Permanent link">&para;</a></h2> <p>Yes, we can use them </p> <p><strong>Method 1: API integration</strong> <br> - Obtain the endpoint URL and API key from cloud platform (Vertex/AWS/Azure) ML. - Prepare your environment for making HTTP requests. - Send requests to the API endpoint using tools like Python’s requests library. - Integrate the API calls into LM Studio or other tools. - Test and validate the integration to ensure it functions correctly.</p> <p><strong>Method 2: Model conversion and export</strong> <br> Export Models: Export models from the cloud services in formats compatible with Ollama (e.g., ONNX, TensorFlow SavedModel). This might involve transferring the model files. Import into Ollama: If Ollama supports these formats, you can then import the models into Ollama’s environment.</p> <h2 id=references>References<a class=headerlink href=#references title="Permanent link">&para;</a></h2> <ul> <li><a href=https://ollama.com>https://ollama.com</a></li> <li><a href=https://github.com/ollama/ollama>https://github.com/ollama/ollama</a></li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Dr. Hari Thapliyaal </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dasarpai target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://hub.docker.com/r/harithapliyal target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://x.com/dasarpai target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../assets/javascripts/custom.9e5da760.min.js></script> </body> </html>