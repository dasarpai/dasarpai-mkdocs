<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My various blogs on Datascience, Management, Software Engineering, Philosophy, Vedanta, Sanskrit, Current Affair, History. "><meta name=author content="Hari Thapliyaal"><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/What-is-LLM.html><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.11"><title>What is LLM - DasarpAI</title><link rel=stylesheet href=../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","{{ config.extra.GOOGLE_ANALYTICS }}"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","{{ config.extra.GOOGLE_ANALYTICS }}",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id={{ config.extra.GOOGLE_ANALYTICS }}",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><link rel=stylesheet href=../assets/stylesheets/custom.7c86dd97.min.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#what-is-large-language-model class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@squidfunk</strong> on <a rel=me href=https://fosstodon.org/@squidfunk> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </span> <strong>Fosstodon</strong> </a> and <a href=https://x.com/squidfunk> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=DasarpAI class="md-header__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DasarpAI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> What is LLM </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=index.html class=md-tabs__link> Data Science </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/pmlogy-home.html class=md-tabs__link> Project Management </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/wia-home.html class=md-tabs__link> SpiritualDrops </a> </li> <li class=md-tabs__item> <a href=../samskrutyatra/index.html class=md-tabs__link> Samskrut </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=DasarpAI class="md-nav__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> DasarpAI </label> <div class=md-nav__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../index.html class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/aboutme.html class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> <li class=md-nav__item> <a href=../dscourses/index.html class=md-nav__link> <span class=md-ellipsis> DS/AI Courses/Services </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Project/Work Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Project/Work Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/project-index-page.html class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-al-ml-projects.md class=md-nav__link> <span class=md-ellipsis> Business Domain </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-my-technology-stacks.md class=md-nav__link> <span class=md-ellipsis> Technology Stack </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-management-projects.md class=md-nav__link> <span class=md-ellipsis> Project Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../management/index.html class=md-nav__link> <span class=md-ellipsis> PM Courses/Services </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/clients.html class=md-nav__link> <span class=md-ellipsis> Clients </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/testimonials.md class=md-nav__link> <span class=md-ellipsis> Testimonial </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/publications-home.html class=md-nav__link> <span class=md-ellipsis> Publications </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/corpus-home.html class=md-nav__link> <span class=md-ellipsis> History Corpus </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=index.html class="md-nav__link "> <span class=md-ellipsis> Data Science </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Data Science </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dsresources/index.html class=md-nav__link> <span class=md-ellipsis> DS Resources </span> </a> </li> <li class=md-nav__item> <a href=../news/index.html class=md-nav__link> <span class=md-ellipsis> AI and Business News </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-books.md class=md-nav__link> <span class=md-ellipsis> Data Science-Books </span> </a> </li> <li class=md-nav__item> <a href=data-science-cheatsheets.md class=md-nav__link> <span class=md-ellipsis> Data Science Cheatsheets </span> </a> </li> <li class=md-nav__item> <a href=best-youtube-channels-for-ds.md class=md-nav__link> <span class=md-ellipsis> Video Channels to Learn DS </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-interview-resources.md class=md-nav__link> <span class=md-ellipsis> DS Interview Questions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../pmblog/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Project Management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-home.html class=md-nav__link> <span class=md-ellipsis> PMLOGY Home </span> </a> </li> <li class=md-nav__item> <a href=../pmglossary.md class=md-nav__link> <span class=md-ellipsis> PM Glossary </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-tags.md class=md-nav__link> <span class=md-ellipsis> PM Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-tags.md class=md-nav__link> <span class=md-ellipsis> PMBOK6 Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-summary.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 </span> </a> </li> <li class=md-nav__item> <a href=../pmbok6/index.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Explorer </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> PM Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> PM Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmi-templates.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Templates </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/prince2-templates.html class=md-nav__link> <span class=md-ellipsis> PRINCE2 Templates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../pmbok6hi/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management Hindi </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Project Management Hindi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmbok6hi-summary.html class=md-nav__link> <span class=md-ellipsis> PMBoK6 Hindi </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../wiaposts/index.html class="md-nav__link "> <span class=md-ellipsis> SpiritualDrops </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> SpiritualDrops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/wia-home.html class=md-nav__link> <span class=md-ellipsis> WIA Home </span> </a> </li> <li class=md-nav__item> <a href=../quotations/index.html class=md-nav__link> <span class=md-ellipsis> WIA Quotes </span> </a> </li> <li class=md-nav__item> <a href=../gk/index.html class=md-nav__link> <span class=md-ellipsis> GK Blog </span> </a> </li> <li class=md-nav__item> <a href=../booksummary/index.html class=md-nav__link> <span class=md-ellipsis> Book Summary </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../samskrutyatra/index.html class="md-nav__link "> <span class=md-ellipsis> Samskrut </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Samskrut </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/samskrut-home.html class=md-nav__link> <span class=md-ellipsis> SamskrutYatra Home </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#what-is-llm-model class=md-nav__link> <span class=md-ellipsis> What is LLM Model? </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-difference-between-llm-and-transformer-model class=md-nav__link> <span class=md-ellipsis> What is the difference between LLM and Transformer Model </span> </a> </li> <li class=md-nav__item> <a href=#examples-of-transformer-based-llm class=md-nav__link> <span class=md-ellipsis> Examples of Transformer Based LLM </span> </a> </li> <li class=md-nav__item> <a href=#example-of-pathway-based-llm class=md-nav__link> <span class=md-ellipsis> Example of Pathway Based LLM </span> </a> </li> <li class=md-nav__item> <a href=#examples-of-rnn-based-llm class=md-nav__link> <span class=md-ellipsis> Examples of RNN Based LLM </span> </a> </li> <li class=md-nav__item> <a href=#what-are-the-advantages-of-llms class=md-nav__link> <span class=md-ellipsis> What are the advantages of LLMs? </span> </a> </li> <li class=md-nav__item> <a href=#what-are-the-challenges-and-limitations-of-llm class=md-nav__link> <span class=md-ellipsis> What are the challenges and limitations of LLM? </span> </a> </li> <li class=md-nav__item> <a href=#what-are-different-types-of-llm class=md-nav__link> <span class=md-ellipsis> What are different types of LLM? </span> </a> </li> <li class=md-nav__item> <a href=#what-is-palm class=md-nav__link> <span class=md-ellipsis> What is PaLM? </span> </a> </li> <li class=md-nav__item> <a href=#what-is-gpt3 class=md-nav__link> <span class=md-ellipsis> What is GPT3? </span> </a> </li> <li class=md-nav__item> <a href=#what-is-gpt4 class=md-nav__link> <span class=md-ellipsis> What is GPT4? </span> </a> </li> <li class=md-nav__item> <a href=#what-kind-of-hardware-cpu-gpu-ram-is-needed-to-train-llm class=md-nav__link> <span class=md-ellipsis> What kind of hardware (CPU, GPU, RAM) is needed to train LLM? </span> </a> </li> <li class=md-nav__item> <a href=#hardware-for-inference-from-llm class=md-nav__link> <span class=md-ellipsis> Hardware for Inference from LLM </span> </a> </li> <li class=md-nav__item> <a href=#what-is-the-need-of-vram-for-llm class=md-nav__link> <span class=md-ellipsis> What is the Need of VRAM for LLM? </span> </a> </li> <li class=md-nav__item> <a href=#can-i-use-virtual-memory-in-place-of-vram class=md-nav__link> <span class=md-ellipsis> Can I use Virtual Memory in place of VRAM? </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/dasarpai/dasrapai-mkdocs/edit/master/docs/dsblog/What-is-LLM.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg> </a> <a href=https://github.com/dasarpai/dasrapai-mkdocs/raw/master/docs/dsblog/What-is-LLM.md title="View source of this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg> </a> <p><img alt="What is LLM" src=../assets/images/dspost/dsp6087-What-is-LLM.jpg></p> <h1 id=what-is-large-language-model>What is Large Language Model<a class=headerlink href=#what-is-large-language-model title="Permanent link">&para;</a></h1> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">&para;</a></h2> <p>LLM stands for <strong>Large Language Model</strong>. It is a type of artificial intelligence (AI) model that is trained on a massive dataset of text and code. This allows LLMs to learn the statistical relationships between words and phrases, and to generate text that is similar to the text that they were trained on.</p> <p>LLMs are still under development, but they have already been shown to be capable of performing a wide variety of tasks:</p> <ul> <li><strong>Natural language understanding:</strong> LLMs can understand the meaning of text, summarise it, and translate it to other languages.</li> <li><strong>Natural language generation:</strong> LLMs can generate text, translate languages, and write different kinds of creative content.</li> <li><strong>Coding:</strong> LLMs can write and understand code.</li> <li><strong>Commonsense reasoning:</strong> LLMs can reason about the world and answer questions about hypothetical situations.</li> <li><strong>Conversational AI and chatbots</strong></li> <li><strong>Classification and categorization</strong></li> <li><strong>Sentiment analysis</strong></li> </ul> <p>LLMs are a powerful tool that can be used for a variety of tasks. They are still under development, but they have the potential to revolutionize the way we interact with computers.</p> <h2 id=what-is-llm-model>What is LLM Model?<a class=headerlink href=#what-is-llm-model title="Permanent link">&para;</a></h2> <p>Large Language Models are a broader concept that encompasses various architectures and approaches for building models that can understand and generate human language text. These models are trained on massive amounts of text data to learn the statistical patterns, grammar, semantics, and context of language. They are capable of tasks like text completion, language translation, question answering, summarization, and more.</p> <p>There is no clear definition or size limit when a model is called a large language model. It depends on the context and the comparison with other models. For example, some models that were considered large a few years ago may be considered small or medium today, as new models with more parameters and data are developed.</p> <p>Important parameters that can be used to tell whether a model is LLM or not. - The number of parameters: This is the number of weights or variables that the model can learn and adjust during training. The more parameters, the more complex and expressive the model can be, but also the more computationally expensive and prone to overfitting. For example, LSTM has about 100 million parameters, GRU has about 50 million parameters, ByteNet has about 200 million parameters, Switch Transformer has about 1.6 billion parameters, and GShard has about 600 billion parameters. - The number of layers: This is the number of processing units or modules that the model has. Each layer can perform a different function or operation on the input or output data. The more layers, the more hierarchical and abstract the model can be, but also the more difficult to train and optimize. For example, LSTM has 4 layers, GRU has 3 layers, ByteNet has 15 layers for each sub-network, Switch Transformer has 24 layers for each expert*, and GShard has 28 layers for each expert*. - The amount of data: This is the amount of text data that the model is trained on. The more data, the more diverse and generalizable the model can be, but also the more noisy and biased the data may be. For example, LSTM and GRU are trained on Wikipedia articles, ByteNet is trained on WMT datasets for machine translation, Switch Transformer is trained on C4 dataset for natural language understanding, and GShard is trained on WMT’14 En-De dataset for machine translation.</p> <p><strong>Expert:</strong> An expert is a person who has special skill or knowledge in a particular field or area of study. An expert is a neural network module that can process a subset of the input data and produce an output. Each expert has a different attention pattern or head configuration, which means that it can focus on different aspects of the input data. For example, one expert may pay more attention to the syntax of the input, while another expert may pay more attention to the semantics. <strong>Encoder expert</strong> can process a subset of the source tokens and produce an output vector for each token. <strong>Decoder expert</strong> can process a subset of the target tokens and produce an output vector for each token. The output vectors are then combined by a routing network to form the final decoder output. <strong>Attention expert</strong> can perform a different type of attention, such as self-attention, cross-attention, or global attention, on a subset of the input or output tokens. The output vectors are then combined by a routing network to form the final attention output.</p> <p>According to the paper <strong>GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding</strong>, the number of experts that GShard supports depends on the number of shards and the number of experts per shard. The paper reports experiments with different configurations of these parameters, such as:</p> <ul> <li>8 shards, each with 64 experts, for a total of 512 experts.</li> <li>128 shards, each with 64 experts, for a total of 8192 experts.</li> <li>256 shards, each with 256 experts, for a total of 65536 experts.</li> </ul> <p>Gopher (280B) Jurassic-1 (178B)</p> <h2 id=what-is-the-difference-between-llm-and-transformer-model>What is the difference between LLM and Transformer Model<a class=headerlink href=#what-is-the-difference-between-llm-and-transformer-model title="Permanent link">&para;</a></h2> <p>LLM model can be built either using Transformer Architecture or non-Tranformer architecture. When we use huge data to train a model then whatever model is output from the training process that is called LLM. When we are training a Transformer or any other neural network model only small amount of data then output model is not called LLM. LLM can work upon Text, Images, Video, Audio. Some LLMs can accept only text data for example GPT3, some can accept only with image data, some can accpet different kind of data i.e. text, image, audio for example GPT4. Some LLM takes text input and generate text output. Some LLM takes text input generate image output for example DALL-E.</p> <h2 id=examples-of-transformer-based-llm>Examples of Transformer Based LLM<a class=headerlink href=#examples-of-transformer-based-llm title="Permanent link">&para;</a></h2> <p>Transformer architecture is highly parallelizable and can capture long-range dependencies in text, making it effective for tasks like machine translation, text generation, and more. The greatness of any LLM depends upon - How less resources (compute, memory, and harddisk) they need for finetuning, inferencing on the downstream tasks. - How good those finetuned model performs.</p> <table> <thead> <tr> <th>Model Name</th> <th>Company Name</th> <th>Parameters</th> <th>Year of release</th> <th>Model Capabilities</th> </tr> </thead> <tbody> <tr> <td>LaMDA</td> <td>Google</td> <td>1.6 billion</td> <td>2021</td> <td>Conversational AI</td> </tr> <tr> <td>Turing NLG 17B</td> <td>NVIDIA and Microsoft Research</td> <td>17 billion</td> <td>2020</td> <td>Natural Language Generation</td> </tr> <tr> <td>Megatron NLG 530B (MT-NLG)</td> <td>NVIDIA and Microsoft Research</td> <td>530 billion</td> <td>2021</td> <td>Natural Language Generation</td> </tr> <tr> <td>Bard (BART)</td> <td>Facebook AI Research (FAIR) and University College London (UCL) researchers.</td> <td>406 million</td> <td>2019</td> <td>Summarization, Translation, Question Answering</td> </tr> <tr> <td>RoBERTa (Robustly Optimized BERT Pretraining Approach)</td> <td>Facebook AI Research (FAIR), University of Washington and New York University.</td> <td>355 million</td> <td>2019</td> <td>Natural Language Understanding</td> </tr> <tr> <td>ALBERT (A Lite BERT)</td> <td>Google Research Team.</td> <td>12 million</td> <td>2019</td> <td>Natural Language Understanding</td> </tr> <tr> <td>ELECTRA (Efficiently Learning an Encoder that Classifies Token Replacements Accurately)</td> <td>Google Research Team.</td> <td>110 million</td> <td>2020</td> <td>Natural Language Understanding</td> </tr> <tr> <td>FaluBert (Falu Language Model)</td> <td>Falu AI team.</td> <td>24 million</td> <td>2020</td> <td>Chinese language understanding</td> </tr> <tr> <td>Gopher (Go Programming language HelpER) model</td> <td>OpenAI team.</td> <td>125 million</td> <td>2020</td> <td>Code generation for Go programming language</td> </tr> <tr> <td>CodeBERT (Code BERT) model</td> <td>Microsoft Research Asia team.</td> <td>400 million</td> <td>2020</td> <td>Code generation for multiple programming languages</td> </tr> <tr> <td>Chinchilla model</td> <td>OpenAI team.</td> <td>350 million</td> <td>2020</td> <td>Multilingual contextual representations</td> </tr> <tr> <td>DialogGPT</td> <td>Microsoft</td> <td>345 million</td> <td>2019</td> <td>Open-domain conversational agent. Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017</td> </tr> </tbody> </table> <h2 id=example-of-pathway-based-llm>Example of Pathway Based LLM<a class=headerlink href=#example-of-pathway-based-llm title="Permanent link">&para;</a></h2> <ul> <li><strong>PaLM:</strong> Developed by Google AI, PaLM is a large language model with 540 billion parameters. It is designed to be informative and comprehensive, and it can be used for a variety of tasks, including natural language understanding, natural language generation, and machine translation.</li> </ul> <h2 id=examples-of-rnn-based-llm>Examples of RNN Based LLM<a class=headerlink href=#examples-of-rnn-based-llm title="Permanent link">&para;</a></h2> <p>The transformer architecture is the most common architecture for LLMs, but it is not the only one. Other architectures can also be used to create LLMs, and they may have different strengths and weaknesses.</p> <ul> <li> <p><strong>Meena:</strong> This is a conversational neural language model that is developed by Google AI. It is trained on a massive dataset of text and code, and it can engage in open-ended dialogue. Meena is not based on the transformer architecture, but it uses a different neural network architecture called the recurrent neural network (RNN). It has 1.37 billion parameters and can be used to generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc.</p> </li> <li> <p><strong>Seq2Seq:</strong> This is a sequence-to-sequence model that is used for machine translation. It is not based on the transformer architecture, but it uses a different neural network architecture called the recurrent neural network (RNN).</p> </li> </ul> <h2 id=what-are-the-advantages-of-llms>What are the advantages of LLMs?<a class=headerlink href=#what-are-the-advantages-of-llms title="Permanent link">&para;</a></h2> <ul> <li>Extensibility and adaptability. LLMs can serve as a foundation for customized use cases. Additional training on top of an LLM can create a finely tuned model for an organization's specific needs.</li> <li>Flexibility. One LLM can be used for many different tasks and deployments across organizations, users and applications.</li> <li>Performance. Modern LLMs are typically high-performing, with the ability to generate rapid, low-latency responses.</li> <li>Accuracy. As the number of parameters and the volume of trained data grow in an LLM, the transformer model is able to deliver increasing levels of accuracy.</li> <li>Ease of training. Many LLMs are trained on unlabeled data, which helps to accelerate the training process.</li> </ul> <h2 id=what-are-the-challenges-and-limitations-of-llm>What are the challenges and limitations of LLM?<a class=headerlink href=#what-are-the-challenges-and-limitations-of-llm title="Permanent link">&para;</a></h2> <ul> <li>Development costs. To run, LLMs generally require large quantities of expensive graphics processing unit hardware and massive data sets.</li> <li>Operational costs. After the training and development period, the cost of operating an LLM for the host organization can be very high.</li> <li>Bias. A risk with any AI trained on unlabeled data is bias, as it's not always clear that known bias has been removed.</li> <li>Explainability. The ability to explain how an LLM was able to generate a specific result is not easy or obvious for users.</li> <li>Hallucination. AI hallucination occurs when an LLM provides an inaccurate response that is not based on trained data.</li> <li>Complexity. With billions of parameters, modern LLMs are exceptionally complicated technologies that can be particularly complex to troubleshoot.</li> <li>Glitch tokens. Maliciously designed prompts that cause an LLM to malfunction, known as glitch tokens, are part of an emerging trend since 2022.</li> </ul> <h2 id=what-are-different-types-of-llm>What are different types of LLM?<a class=headerlink href=#what-are-different-types-of-llm title="Permanent link">&para;</a></h2> <p>As of 2023 the common types are the following.</p> <ul> <li>Zero-shot model: This is a large, generalized model trained on a generic corpus of data that is able to give a fairly accurate result for general use cases, without the need for additional training. GPT-3 is often considered a zero-shot model.</li> <li>One-shot model: Fine-tuned on domain-specific data with one sample. </li> <li>Few-shot model: Fine-tuned on domain-specific data with less than 100 samples. Additional training on top of a zero-shot model like GPT-3 can lead to a fine-tuned models.</li> <li>Language representation model. One example of a language representation model is Bidirectional Encoder Representations from Transformers (BERT), which makes use of deep learning and transformers well suited for NLP.</li> <li>Multimodal model. Originally LLMs were specifically tuned just for text, but with the multimodal approach it is possible to handle both text and images. GPT4 is multimoda modell.</li> </ul> <h2 id=what-is-palm>What is PaLM?<a class=headerlink href=#what-is-palm title="Permanent link">&para;</a></h2> <p>PaLM stands for Pathways Language Model. It is a large language model (LLM) developed by Google AI. PaLM has 540 billion parameters, making it one of the largest LLMs in the world.</p> <p>There are four different PaLM models:</p> <ul> <li><strong>Gecko:</strong> This is the smallest PaLM model, with 140 billion parameters. It is designed for use on mobile devices and embedded systems. [Image of Gecko PaLM LLM model]</li> <li><strong>Otter:</strong> This model has 280 billion parameters and is designed for use on laptops and desktops. [Image of Otter PaLM LLM model]</li> <li><strong>Bison:</strong> This is the largest PaLM model, with 540 billion parameters. It is designed for use on high-performance computing clusters. [Image of Bison PaLM LLM model]</li> <li><strong>Unicorn:</strong> This model is still under development, but it is expected to have 1.1 trillion parameters. It will be the largest PaLM model ever created. [Image of Unicorn PaLM LLM model]</li> </ul> <p>PaLM is trained on a massive dataset of text and code, including books, articles, code repositories, and websites. This allows PaLM to perform a wide variety of tasks, including:</p> <ul> <li>Natural language understanding: PaLM can understand the meaning of text and translate languages.</li> <li>Natural language generation: PaLM can generate text, translate languages, and write different kinds of creative content.</li> <li>Coding: PaLM can write and understand code.</li> <li>Commonsense reasoning: PaLM can reason about the world and answer questions about hypothetical situations.</li> </ul> <p>PaLM is still under development, but it has the potential to revolutionize the way we interact with computers. It could be used to create new applications for education, healthcare, and customer service. It could also be used to develop new AI-powered tools that help us to be more productive and creative.</p> <h2 id=what-is-gpt3>What is GPT3?<a class=headerlink href=#what-is-gpt3 title="Permanent link">&para;</a></h2> <p>There are many different versions of the GPT-3 model, each with a different number of parameters and capabilities. Here are some of the most notable versions:</p> <ul> <li><strong>GPT-3-small:</strong> This is the smallest version of GPT-3, with 125 million parameters. It is designed for simple tasks and is relatively inexpensive to use.</li> <li><strong>GPT-3-medium:</strong> This version has 1.3 billion parameters and is capable of more complex tasks. It is still relatively inexpensive to use.</li> <li><strong>GPT-3-large:</strong> This version has 175 billion parameters and is the most powerful version of GPT-3. It is also the most expensive to use.</li> <li><strong>GPT-3-XL:</strong> This version has 1.3 trillion parameters and is even more powerful than the GPT-3-large model. It is still under development, but it is expected to be released in the near future.</li> </ul> <p>The size of the GPT-3 models is measured in parameters. A parameter is a variable that is used to learn the relationship between inputs and outputs in a machine learning model. The more parameters a model has, the more complex the relationships it can learn.</p> <p>The size of the GPT-3 models has increased over time as the technology has improved. The first version of GPT-3, released in 2020, had only 125 million parameters. The most recent version, GPT-3-XL, has 1.3 trillion parameters.</p> <p>The size of the GPT-3 models has also had an impact on their capabilities. The larger models are capable of performing more complex tasks and generating more realistic text. However, they are also more expensive to use and require more computing power.</p> <p>The different versions of the GPT-3 model are designed for different purposes. The smaller models are best suited for simple tasks, such as generating text or translating languages. The larger models are best suited for more complex tasks, such as writing creative content or answering questions in an informative way.</p> <p>The GPT-3 models are a powerful tool that can be used for a variety of tasks. They are still under development, but they have the potential to revolutionize the way we interact with computers.</p> <h2 id=what-is-gpt4>What is GPT4?<a class=headerlink href=#what-is-gpt4 title="Permanent link">&para;</a></h2> <p>There are two main versions of the GPT-4 model:</p> <ul> <li><strong>GPT-4 (8,192 tokens)</strong>: This is the standard version of GPT-4. It has 175 billion parameters and can process text prompts up to 8,192 tokens long. [Image of GPT-4 (8,192 tokens) language model]</li> <li><strong>GPT-4 (32,768 tokens)</strong>: This is the extended version of GPT-4. It has 1.3 trillion parameters and can process text prompts up to 32,768 tokens long. [Image of GPT-4 (32,768 tokens) language model]</li> </ul> <p>The main difference between the two versions is the context length. The context length is the length of the prompt plus the maximum number of tokens in the completion. The GPT-4 (8,192 tokens) model can only process prompts that are up to 8,192 tokens long, while the GPT-4 (32,768 tokens) model can process prompts that are up to 32,768 tokens long.</p> <p>The GPT-4 models are still under development, but they have already been shown to be capable of performing a wide variety of tasks, including:</p> <ul> <li>Natural language understanding: GPT-4 can understand the meaning of text and translate languages.</li> <li>Natural language generation: GPT-4 can generate text, translate languages, and write different kinds of creative content.</li> <li>Coding: GPT-4 can write and understand code.</li> <li>Commonsense reasoning: GPT-4 can reason about the world and answer questions about hypothetical situations.</li> </ul> <p>The GPT-4 models are a significant step forward in the development of large language models. They are more powerful and versatile than previous models, and they have the potential to revolutionize the way we interact with computers.</p> <h2 id=what-kind-of-hardware-cpu-gpu-ram-is-needed-to-train-llm>What kind of hardware (CPU, GPU, RAM) is needed to train LLM?<a class=headerlink href=#what-kind-of-hardware-cpu-gpu-ram-is-needed-to-train-llm title="Permanent link">&para;</a></h2> <p>The hardware requirements for inference with the GPT-3 Large model (175 billion parameters) are:</p> <ul> <li><strong>CPU:</strong> A minimum of 16 cores is recommended, but more cores will provide better performance.</li> <li><strong>GPU:</strong> A minimum of 16 GB of VRAM is required, but more VRAM will provide better performance.</li> <li><strong>RAM:</strong> A minimum of 32 GB of RAM is required, but more RAM will provide better performance.</li> </ul> <p>It is also important to have a fast storage system, such as an SSD, to store the model and the data that is being processed.</p> <p>Here are some specific examples of hardware that you could use for inference with the GPT-3 Large model:</p> <ul> <li><strong>CPU:</strong> A server with 16 or more cores, such as the Intel Xeon Silver 4210 or the AMD EPYC 7571.</li> <li><strong>GPU:</strong> A GPU with 16 GB of VRAM, such as the NVIDIA T4 or the AMD Radeon Pro VII.</li> <li><strong>RAM:</strong> 32 GB of RAM.</li> <li><strong>Storage:</strong> A fast SSD, such as the Samsung 980 Pro or the Western Digital SN850.</li> </ul> <p>It is important to note that these are just the minimum requirements for inference with the GPT-3 Large model. If you want to achieve the best possible performance, you will need to use more powerful hardware.</p> <h2 id=hardware-for-inference-from-llm>Hardware for Inference from LLM<a class=headerlink href=#hardware-for-inference-from-llm title="Permanent link">&para;</a></h2> <p>Unfortunately, you cannot use the GPT-3 Medium model for inference without a GPU machine. The GPT-3 Medium model requires a minimum of 8 GB of VRAM, which is not available on most CPUs.</p> <p>There are a few ways to get around this limitation. One way is to use a cloud computing service that provides GPU instances. For example, Google Cloud Platform offers a variety of GPU instances that you can use to run the GPT-3 Medium model.</p> <p>Another way to get around this limitation is to use a smaller model. The GPT-3 Small model only requires 125 million parameters and can be run on a CPU machine. However, the GPT-3 Small model is not as powerful as the GPT-3 Medium model and cannot be used for the same tasks.</p> <p>If you are looking for a way to use the GPT-3 Medium model without a GPU machine, your best option is to use a cloud computing service. This will allow you to get the performance you need without having to invest in a new machine.</p> <h2 id=what-is-the-need-of-vram-for-llm>What is the Need of VRAM for LLM?<a class=headerlink href=#what-is-the-need-of-vram-for-llm title="Permanent link">&para;</a></h2> <p>VRAM stands for Video Random Access Memory. It is a type of memory that is used by graphics cards to store the data that is needed to render images on a display. VRAM is much faster than regular RAM, which is why it is used for graphics processing.</p> <p>VRAM stores the image data that is being displayed on the screen, as well as the data that is being processed by the GPU. This data includes things like textures, shaders, and geometry. VRAM also stores the results of the GPU's calculations, which are then displayed on the screen.</p> <p>The amount of VRAM that a graphics card has determines how much data it can store and process at once. This is important for games and other applications that require a lot of graphics processing. A graphics card with more VRAM will be able to handle more demanding applications without slowing down.</p> <p>The amount of VRAM that you need depends on the type of games and applications that you want to use. For most games, 4GB of VRAM is sufficient. However, some more demanding games may require 6GB or more of VRAM. If you are a serious gamer or you want to use applications that require a lot of graphics processing, you should consider getting a graphics card with 8GB or more of VRAM.</p> <p>Here are some of the benefits of using VRAM:</p> <ul> <li><strong>Faster rendering:</strong> VRAM is much faster than regular RAM, which means that graphics cards can render images much faster. This results in smoother gameplay and better graphics quality.</li> <li><strong>More memory:</strong> VRAM can store more data than regular RAM, which allows graphics cards to process more complex models and textures. This is important for games and applications that require a lot of graphics processing.</li> <li><strong>Less lag:</strong> VRAM can reduce lag by storing the data that is needed to render images on the GPU. This means that the CPU does not have to access the slower main memory as often, which can improve performance.</li> </ul> <p>Here are some of the drawbacks of using VRAM:</p> <ul> <li><strong>More expensive:</strong> VRAM is more expensive than regular RAM. This is because it is a specialized type of memory that is designed for graphics processing.</li> <li><strong>Less accessible:</strong> VRAM is not as accessible as regular RAM. This is because it is located on the graphics card, which is a separate component from the motherboard.</li> <li><strong>More power-hungry:</strong> VRAM is more power-hungry than regular RAM. This is because it is a faster type of memory.</li> </ul> <p>Overall, VRAM is an important part of a graphics card. It allows graphics cards to render images faster and smoother, and it can reduce lag. However, VRAM is more expensive and less accessible than regular RAM.</p> <h2 id=can-i-use-virtual-memory-in-place-of-vram>Can I use Virtual Memory in place of VRAM?<a class=headerlink href=#can-i-use-virtual-memory-in-place-of-vram title="Permanent link">&para;</a></h2> <p>No. <strong>Virtual memory is a technique</strong> that allows each virtual machine to have its own dedicated memory space, even if there is not having enough physical RAM on the host machine. <strong>Virtual RAM is a portion of the hard drive</strong> that is used as temporary memory for virtual machines. </p> <p>Virtual Memory or Vritual RAM is a technique that allows computers to use more memory than they actually have. This is done by using a portion of the hard drive as temporary memory. When the computer needs more memory than it has, it can swap data between the hard drive and the RAM.</p> <p>Virtual RAM is also known as <strong>paging</strong> or <strong>virtual memory</strong>. It is a feature of most operating systems, including Windows, macOS, and Linux.</p> <p>Virtual RAM is used to improve performance by allowing computers to run more programs at once. It can also be used to prevent programs from crashing when they run out of memory.</p> <p>There are a few drawbacks to using virtual RAM. First, it can slow down the computer, especially if the hard drive is slow. Second, it can shorten the lifespan of the hard drive, because it is constantly being written to. Third, it can consume more power.</p> <p>Overall, virtual RAM is a useful technique that can improve the performance of computers. However, it is important to be aware of the drawbacks before using it.</p> <p>Here are some of the benefits of using virtual RAM:</p> <ul> <li><strong>Allows computers to run more programs at once:</strong> Virtual RAM allows computers to run more programs at once by expanding the amount of available memory. This can be helpful for users who like to multitask or who have a lot of programs open at the same time.</li> <li><strong>Prevents programs from crashing:</strong> Virtual RAM can help to prevent programs from crashing by providing a temporary space for data when the computer runs out of physical RAM. This can be helpful for users who are running memory-intensive programs or who have a lot of programs open at the same time.</li> <li><strong>Improves performance:</strong> Virtual RAM can improve the performance of computers by reducing the amount of time that the CPU has to wait for data to be loaded from the hard drive. This can be helpful for users who are running multiple programs or who are playing games.</li> </ul> <p>Here are some of the drawbacks of using virtual RAM:</p> <ul> <li><strong>Slows down the computer:</strong> Virtual RAM can slow down the computer, especially if the hard drive is slow. This is because the data that is stored in virtual RAM has to be swapped back and forth between the hard drive and the RAM.</li> <li><strong>Shortens the lifespan of the hard drive:</strong> Virtual RAM can shorten the lifespan of the hard drive, because it is constantly being written to. This is because the data that is stored in virtual RAM has to be written to the hard drive every time it is changed.</li> <li><strong>Consumes more power:</strong> Virtual RAM can consume more power than physical RAM. This is because the hard drive has to be accessed more often when virtual RAM is used.</li> </ul> <p>Overall, virtual RAM is a useful technique that can improve the performance of computers. However, it cannot be used in place of VRAM.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Dr. Hari Thapliyaal </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dasarpai target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://hub.docker.com/r/harithapliyal target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://x.com/dasarpai target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../assets/javascripts/custom.9e5da760.min.js></script> </body> </html>