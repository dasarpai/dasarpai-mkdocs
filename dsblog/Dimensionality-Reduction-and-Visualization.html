<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My various blogs on Datascience, Management, Software Engineering, Philosophy, Vedanta, Sanskrit, Current Affair, History. "><meta name=author content="Hari Thapliyaal"><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Dimensionality-Reduction-and-Visualization.html><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.11"><title>Dimensionality Reduction and Visualization - DasarpAI</title><link rel=stylesheet href=../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","{{ config.extra.GOOGLE_ANALYTICS }}"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","{{ config.extra.GOOGLE_ANALYTICS }}",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id={{ config.extra.GOOGLE_ANALYTICS }}",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta name=author content="Hari Thapliyaal"><meta name=description content="Explore techniques for reducing data dimensions and creating meaningful visualizations. Learn about PCA, t-SNE, UMAP, and other methods for effective data analysis and representation."><meta name=keywords content="Dimensionality Reduction, Data Visualization, PCA Analysis, t-SNE, UMAP, Feature Selection, Data Analysis Methods, Machine Learning Techniques"><meta property=og:type content=article><meta property=og:locale content=en_US><meta property=og:site_name content=DasarpAI><meta property=og:title content="Dimensionality Reduction and Visualization"><meta property=og:description content="Explore techniques for reducing data dimensions and creating meaningful visualizations. Learn about PCA, t-SNE, UMAP, and other methods for effective data analysis and representation."><meta property=og:url content=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Dimensionality-Reduction-and-Visualization.html><meta property=og:image content=../../assets/images/dspost/dsp6126-Dimensionality-Reduction-and-Visualization.jpg><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=@dasarpai><meta name=twitter:title content="Dimensionality Reduction and Visualization"><meta name=twitter:description content="Explore techniques for reducing data dimensions and creating meaningful visualizations. Learn about PCA, t-SNE, UMAP, and other methods for effective data analysis and representation."><meta name=twitter:image content=../../assets/images/dspost/dsp6126-Dimensionality-Reduction-and-Visualization.jpg><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Dimensionality-Reduction-and-Visualization.html><link rel=stylesheet href=../assets/stylesheets/custom.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#dimensionality-reduction-and-visualization class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@harithapliyal</strong> on <a rel=me href=https://linkedin.com/in/harithapliyal> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </span> <strong>Fosstodon</strong> </a> and <a href=https://x.com/dasarpai> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=DasarpAI class="md-header__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DasarpAI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Dimensionality Reduction and Visualization </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=index.html class=md-tabs__link> Data Science </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/pmlogy-home.html class=md-tabs__link> Project Management </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/wia-home.html class=md-tabs__link> SpiritualDrops </a> </li> <li class=md-tabs__item> <a href=../samskrutyatra/index.html class=md-tabs__link> Samskrut </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=DasarpAI class="md-nav__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> DasarpAI </label> <div class=md-nav__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../index.html class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/aboutme.html class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> <li class=md-nav__item> <a href=../dscourses/index.html class=md-nav__link> <span class=md-ellipsis> DS/AI Courses/Services </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Project/Work Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Project/Work Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/project-index-page.html class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-al-ml-projects.md class=md-nav__link> <span class=md-ellipsis> Business Domain </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-my-technology-stacks.md class=md-nav__link> <span class=md-ellipsis> Technology Stack </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-management-projects.md class=md-nav__link> <span class=md-ellipsis> Project Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../management/index.html class=md-nav__link> <span class=md-ellipsis> PM Courses/Services </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/clients.html class=md-nav__link> <span class=md-ellipsis> Clients </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/testimonials.md class=md-nav__link> <span class=md-ellipsis> Testimonial </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/publications-home.html class=md-nav__link> <span class=md-ellipsis> Publications </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/corpus-home.html class=md-nav__link> <span class=md-ellipsis> History Corpus </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=index.html class="md-nav__link "> <span class=md-ellipsis> Data Science </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Data Science </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dsresources/index.html class=md-nav__link> <span class=md-ellipsis> DS Resources </span> </a> </li> <li class=md-nav__item> <a href=../news/index.html class=md-nav__link> <span class=md-ellipsis> AI and Business News </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-books.md class=md-nav__link> <span class=md-ellipsis> Data Science-Books </span> </a> </li> <li class=md-nav__item> <a href=data-science-cheatsheets.md class=md-nav__link> <span class=md-ellipsis> Data Science Cheatsheets </span> </a> </li> <li class=md-nav__item> <a href=best-youtube-channels-for-ds.md class=md-nav__link> <span class=md-ellipsis> Video Channels to Learn DS </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-interview-resources.md class=md-nav__link> <span class=md-ellipsis> DS Interview Questions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../pmblog/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Project Management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-home.html class=md-nav__link> <span class=md-ellipsis> PMLOGY Home </span> </a> </li> <li class=md-nav__item> <a href=../pmglossary.md class=md-nav__link> <span class=md-ellipsis> PM Glossary </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-tags.md class=md-nav__link> <span class=md-ellipsis> PM Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-tags.md class=md-nav__link> <span class=md-ellipsis> PMBOK6 Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-summary.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 </span> </a> </li> <li class=md-nav__item> <a href=../pmbok6/index.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Explorer </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> PM Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> PM Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmi-templates.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Templates </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/prince2-templates.html class=md-nav__link> <span class=md-ellipsis> PRINCE2 Templates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../pmbok6hi/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management Hindi </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Project Management Hindi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmbok6hi-summary.html class=md-nav__link> <span class=md-ellipsis> PMBoK6 Hindi </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../wiaposts/index.html class="md-nav__link "> <span class=md-ellipsis> SpiritualDrops </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> SpiritualDrops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/wia-home.html class=md-nav__link> <span class=md-ellipsis> WIA Home </span> </a> </li> <li class=md-nav__item> <a href=../quotations/index.html class=md-nav__link> <span class=md-ellipsis> WIA Quotes </span> </a> </li> <li class=md-nav__item> <a href=../gk/index.html class=md-nav__link> <span class=md-ellipsis> GK Blog </span> </a> </li> <li class=md-nav__item> <a href=../booksummary/index.html class=md-nav__link> <span class=md-ellipsis> Book Summary </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../samskrutyatra/index.html class="md-nav__link "> <span class=md-ellipsis> Samskrut </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Samskrut </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/samskrut-home.html class=md-nav__link> <span class=md-ellipsis> SamskrutYatra Home </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#what-are-the-popular-methods-of-dimensionality-reduction class=md-nav__link> <span class=md-ellipsis> What are the popular methods of dimensionality reduction? </span> </a> <nav class=md-nav aria-label="What are the popular methods of dimensionality reduction?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#linear-methods class=md-nav__link> <span class=md-ellipsis> Linear Methods </span> </a> </li> <li class=md-nav__item> <a href=#non-linear-methods class=md-nav__link> <span class=md-ellipsis> Non-Linear Methods </span> </a> </li> <li class=md-nav__item> <a href=#autoencoders class=md-nav__link> <span class=md-ellipsis> Autoencoders </span> </a> </li> <li class=md-nav__item> <a href=#others class=md-nav__link> <span class=md-ellipsis> Others </span> </a> </li> <li class=md-nav__item> <a href=#practical-considerations class=md-nav__link> <span class=md-ellipsis> Practical Considerations </span> </a> </li> <li class=md-nav__item> <a href=#example-implementations class=md-nav__link> <span class=md-ellipsis> Example Implementations </span> </a> <nav class=md-nav aria-label="Example Implementations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pca-example class=md-nav__link> <span class=md-ellipsis> PCA Example </span> </a> </li> <li class=md-nav__item> <a href=#t-sne-example class=md-nav__link> <span class=md-ellipsis> t-SNE Example </span> </a> </li> <li class=md-nav__item> <a href=#umap-example class=md-nav__link> <span class=md-ellipsis> UMAP Example </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#discuss-dimensionality-reduction-using-t-sne class=md-nav__link> <span class=md-ellipsis> Discuss Dimensionality Reduction using t-SNE </span> </a> </li> <li class=md-nav__item> <a href=#what-is-perplexity-in-t-sne class=md-nav__link> <span class=md-ellipsis> What is perplexity in t-SNE? </span> </a> <nav class=md-nav aria-label="What is perplexity in t-SNE?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#perplexity-and-its-role-in-t-sne class=md-nav__link> <span class=md-ellipsis> Perplexity and its Role in t-SNE </span> </a> <nav class=md-nav aria-label="Perplexity and its Role in t-SNE"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#detailed-explanation class=md-nav__link> <span class=md-ellipsis> Detailed Explanation: </span> </a> </li> <li class=md-nav__item> <a href=#practical-implications class=md-nav__link> <span class=md-ellipsis> Practical Implications: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#choosing-the-right-perplexity class=md-nav__link> <span class=md-ellipsis> Choosing the Right Perplexity: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#how-to-set-perplexity-size class=md-nav__link> <span class=md-ellipsis> How to set perplexity size? </span> </a> <nav class=md-nav aria-label="How to set perplexity size?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#why-high-perplexity-can-be-ineffective-for-small-datasets class=md-nav__link> <span class=md-ellipsis> Why High Perplexity Can Be Ineffective for Small Datasets: </span> </a> </li> <li class=md-nav__item> <a href=#practical-example class=md-nav__link> <span class=md-ellipsis> Practical Example: </span> </a> </li> <li class=md-nav__item> <a href=#choosing-perplexity-for-small-datasets class=md-nav__link> <span class=md-ellipsis> Choosing Perplexity for Small Datasets: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#to-visulize-cluster-from-high-dimensional-data-i-can-use-pca-or-t-sne-which-one-make-more-sense class=md-nav__link> <span class=md-ellipsis> To visulize cluster from high dimensional data I can use PCA or t-SNE, which one make more sense? </span> </a> <nav class=md-nav aria-label="To visulize cluster from high dimensional data I can use PCA or t-SNE, which one make more sense?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#principal-component-analysis-pca class=md-nav__link> <span class=md-ellipsis> Principal Component Analysis (PCA) </span> </a> </li> <li class=md-nav__item> <a href=#t-distributed-stochastic-neighbor-embedding-t-sne class=md-nav__link> <span class=md-ellipsis> t-Distributed Stochastic Neighbor Embedding (t-SNE) </span> </a> </li> <li class=md-nav__item> <a href=#when-to-use-each class=md-nav__link> <span class=md-ellipsis> When to Use Each: </span> </a> </li> <li class=md-nav__item> <a href=#combined-approach class=md-nav__link> <span class=md-ellipsis> Combined Approach: </span> </a> </li> <li class=md-nav__item> <a href=#summary class=md-nav__link> <span class=md-ellipsis> Summary: </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#how-will-i-know-my-dataset-of-1000-samples-and-80-features-is-complex-or-simple class=md-nav__link> <span class=md-ellipsis> How will I know my dataset of 1000 samples and 80 features is complex or simple? </span> </a> <nav class=md-nav aria-label="How will I know my dataset of 1000 samples and 80 features is complex or simple?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#exploratory-data-analysis-eda class=md-nav__link> <span class=md-ellipsis> Exploratory Data Analysis (EDA) </span> </a> </li> <li class=md-nav__item> <a href=#applying-different-techniques class=md-nav__link> <span class=md-ellipsis> Applying Different Techniques </span> </a> </li> <li class=md-nav__item> <a href=#specific-methods class=md-nav__link> <span class=md-ellipsis> Specific Methods </span> </a> </li> <li class=md-nav__item> <a href=#practical-steps-with-code-examples class=md-nav__link> <span class=md-ellipsis> Practical Steps with Code Examples </span> </a> <nav class=md-nav aria-label="Practical Steps with Code Examples"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#visualizing-pairwise-relationships class=md-nav__link> <span class=md-ellipsis> Visualizing Pairwise Relationships </span> </a> </li> <li class=md-nav__item> <a href=#correlation-matrix-and-heatmap class=md-nav__link> <span class=md-ellipsis> Correlation Matrix and Heatmap </span> </a> </li> <li class=md-nav__item> <a href=#pca-explained-variance class=md-nav__link> <span class=md-ellipsis> PCA Explained Variance </span> </a> </li> <li class=md-nav__item> <a href=#residual-analysis class=md-nav__link> <span class=md-ellipsis> Residual Analysis </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <article class="md-content__inner md-typeset"> <p><img alt=Dimensionality-Reduction-and-Visualization src=../assets/images/dspost/dsp6126-Dimensionality-Reduction-and-Visualization.jpg></p> <h1 id=dimensionality-reduction-and-visualization>Dimensionality Reduction and Visualization<a class=headerlink href=#dimensionality-reduction-and-visualization title="Permanent link">&para;</a></h1> <h2 id=what-are-the-popular-methods-of-dimensionality-reduction>What are the popular methods of dimensionality reduction?<a class=headerlink href=#what-are-the-popular-methods-of-dimensionality-reduction title="Permanent link">&para;</a></h2> <p>Dimensionality reduction is a crucial step in data preprocessing, particularly when dealing with high-dimensional datasets. It helps in reducing the number of features while retaining the essential information, improving computational efficiency, and facilitating data visualization. Here are some popular methods of dimensionality reduction:</p> <h3 id=linear-methods>Linear Methods<a class=headerlink href=#linear-methods title="Permanent link">&para;</a></h3> <ol> <li><strong>Principal Component Analysis (PCA)</strong>:</li> <li><strong>Description</strong>: PCA transforms the data into a set of linearly uncorrelated components, ordered by the amount of variance they explain.</li> <li><strong>Use Case</strong>: Useful for datasets where the directions of maximum variance are important.</li> <li> <p><strong>Implementation</strong>: <code>sklearn.decomposition.PCA</code></p> </li> <li> <p><strong>Linear Discriminant Analysis (LDA)</strong>:</p> </li> <li><strong>Description</strong>: LDA aims to find a linear combination of features that best separate two or more classes.</li> <li><strong>Use Case</strong>: Supervised learning, particularly in classification tasks.</li> <li> <p><strong>Implementation</strong>: <code>sklearn.discriminant_analysis.LinearDiscriminantAnalysis</code></p> </li> <li> <p><strong>Factor Analysis</strong>:</p> </li> <li><strong>Description</strong>: Assumes that the observed variables are linear combinations of potential factors plus noise.</li> <li><strong>Use Case</strong>: Used for identifying hidden variables that explain observed data.</li> <li><strong>Implementation</strong>: <code>sklearn.decomposition.FactorAnalysis</code></li> </ol> <h3 id=non-linear-methods>Non-Linear Methods<a class=headerlink href=#non-linear-methods title="Permanent link">&para;</a></h3> <ol> <li><strong>t-Distributed Stochastic Neighbor Embedding (t-SNE)</strong>:</li> <li><strong>Description</strong>: A non-linear technique that reduces dimensions while preserving the local structure of the data.</li> <li><strong>Use Case</strong>: Visualization of high-dimensional data, especially for clustering.</li> <li> <p><strong>Implementation</strong>: <code>sklearn.manifold.TSNE</code></p> </li> <li> <p><strong>Uniform Manifold Approximation and Projection (UMAP)</strong>:</p> </li> <li><strong>Description</strong>: A non-linear method that preserves both local and global data structure, often faster than t-SNE.</li> <li><strong>Use Case</strong>: Visualization and understanding of high-dimensional data.</li> <li> <p><strong>Implementation</strong>: <code>umap.UMAP</code></p> </li> <li> <p><strong>Kernel PCA</strong>:</p> </li> <li><strong>Description</strong>: An extension of PCA using kernel methods to capture non-linear relationships.</li> <li><strong>Use Case</strong>: When the data has non-linear relationships that standard PCA cannot capture.</li> <li> <p><strong>Implementation</strong>: <code>sklearn.decomposition.KernelPCA</code></p> </li> <li> <p><strong>Isomap</strong>:</p> </li> <li><strong>Description</strong>: Combines PCA and multi-dimensional scaling (MDS) to preserve global geometric structures.</li> <li><strong>Use Case</strong>: Non-linear dimensionality reduction maintaining global relationships.</li> <li> <p><strong>Implementation</strong>: <code>sklearn.manifold.Isomap</code></p> </li> <li> <p><strong>Locally Linear Embedding (LLE)</strong>:</p> </li> <li><strong>Description</strong>: Preserves local structure by linearizing local patches of the manifold.</li> <li><strong>Use Case</strong>: When the data lies on a non-linear manifold.</li> <li><strong>Implementation</strong>: <code>sklearn.manifold.LocallyLinearEmbedding</code></li> </ol> <h3 id=autoencoders>Autoencoders<a class=headerlink href=#autoencoders title="Permanent link">&para;</a></h3> <ol> <li><strong>Autoencoders</strong>:</li> <li><strong>Description</strong>: Neural networks that learn to compress data into a lower-dimensional representation and then reconstruct it.</li> <li><strong>Use Case</strong>: Complex non-linear relationships in large datasets.</li> <li><strong>Implementation</strong>: Libraries like TensorFlow or PyTorch</li> </ol> <h3 id=others>Others<a class=headerlink href=#others title="Permanent link">&para;</a></h3> <ol> <li><strong>Independent Component Analysis (ICA)</strong>:</li> <li><strong>Description</strong>: Separates a multivariate signal into additive, independent components.</li> <li><strong>Use Case</strong>: Situations where the goal is to find underlying factors that are statistically independent.</li> <li> <p><strong>Implementation</strong>: <code>sklearn.decomposition.FastICA</code></p> </li> <li> <p><strong>Random Projection</strong>:</p> </li> <li><strong>Description</strong>: Projects data to a lower-dimensional space using a random matrix.</li> <li><strong>Use Case</strong>: When computational efficiency is more critical than exact dimensionality reduction.</li> <li> <p><strong>Implementation</strong>: <code>sklearn.random_projection</code></p> </li> <li> <p><strong>Non-negative Matrix Factorization (NMF)</strong>:</p> </li> <li><strong>Description</strong>: Factorizes the data matrix into two matrices with non-negative entries.</li> <li><strong>Use Case</strong>: When the data is non-negative and parts-based representation is meaningful.</li> <li><strong>Implementation</strong>: <code>sklearn.decomposition.NMF</code></li> </ol> <h3 id=practical-considerations>Practical Considerations<a class=headerlink href=#practical-considerations title="Permanent link">&para;</a></h3> <ul> <li><strong>Data Size</strong>: Large datasets might require more computationally efficient methods like PCA or Random Projection.</li> <li><strong>Non-Linearity</strong>: Use non-linear methods like t-SNE, UMAP, or Kernel PCA if the data has complex non-linear relationships.</li> <li><strong>Supervised vs. Unsupervised</strong>: LDA is a supervised method useful for classification, whereas methods like PCA, t-SNE, and UMAP are unsupervised.</li> </ul> <h3 id=example-implementations>Example Implementations<a class=headerlink href=#example-implementations title="Permanent link">&para;</a></h3> <h4 id=pca-example>PCA Example<a class=headerlink href=#pca-example title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.decomposition</span><span class=w> </span><span class=kn>import</span> <span class=n>PCA</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=c1># Assuming X is your data matrix</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=n>pca</span> <span class=o>=</span> <span class=n>PCA</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=n>X_reduced</span> <span class=o>=</span> <span class=n>pca</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></code></pre></div> <h4 id=t-sne-example>t-SNE Example<a class=headerlink href=#t-sne-example title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.manifold</span><span class=w> </span><span class=kn>import</span> <span class=n>TSNE</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=c1># Assuming X is your data matrix</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=n>tsne</span> <span class=o>=</span> <span class=n>TSNE</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>perplexity</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>n_iter</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=n>X_reduced</span> <span class=o>=</span> <span class=n>tsne</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></code></pre></div> <h4 id=umap-example>UMAP Example<a class=headerlink href=#umap-example title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=kn>import</span><span class=w> </span><span class=nn>umap</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=c1># Assuming X is your data matrix</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=n>umap_reducer</span> <span class=o>=</span> <span class=n>umap</span><span class=o>.</span><span class=n>UMAP</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=n>X_reduced</span> <span class=o>=</span> <span class=n>umap_reducer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></code></pre></div> <p>Selecting the appropriate dimensionality reduction technique depends on the specific requirements of your analysis, such as the size and nature of the data, computational resources, and the intended use of the reduced dimensions (e.g., visualization, further modeling).</p> <h2 id=discuss-dimensionality-reduction-using-t-sne>Discuss Dimensionality Reduction using t-SNE<a class=headerlink href=#discuss-dimensionality-reduction-using-t-sne title="Permanent link">&para;</a></h2> <p>tsne = TSNE(n_components=2, random_state=42, n_iter=5000, perplexity=5)</p> <p>The <code>TSNE</code> function is from the <code>scikit-learn</code> library and stands for t-distributed Stochastic Neighbor Embedding. It is used for dimensionality reduction, particularly for the visualization of high-dimensional data. Here's the explanation of each parameter:</p> <ol> <li> <p><strong><code>n_components</code></strong>: This parameter determines the number of dimensions in the embedded space. In this case, <code>n_components=2</code> means that the data will be reduced to 2 dimensions, which is suitable for 2D visualization.</p> </li> <li> <p><strong><code>random_state</code></strong>: This parameter sets the seed for the random number generator. Providing a fixed <code>random_state=42</code> ensures that the results are reproducible, meaning you will get the same output each time you run the code with this seed.</p> </li> <li> <p><strong><code>n_iter</code></strong>: This parameter specifies the number of iterations for optimization. The default value is usually 1000, but here it is set to <code>5000</code>, which means the optimization process will run for 5000 iterations. More iterations can lead to a more accurate embedding but will take more time.</p> </li> <li> <p><strong><code>perplexity</code></strong>: This parameter is related to the number of nearest neighbors that is used in other manifold learning algorithms. It is a measure of the effective number of neighbors. A lower perplexity like <code>5</code> might be useful for smaller datasets, while higher values are suitable for larger datasets.</p> </li> </ol> <p>So, this line of code configures the t-SNE algorithm to reduce the data to 2 dimensions, with a fixed random seed for reproducibility, performing 5000 iterations of optimization, and considering 5 nearest neighbors for the perplexity parameter.</p> <h2 id=what-is-perplexity-in-t-sne>What is perplexity in t-SNE?<a class=headerlink href=#what-is-perplexity-in-t-sne title="Permanent link">&para;</a></h2> <h3 id=perplexity-and-its-role-in-t-sne>Perplexity and its Role in t-SNE<a class=headerlink href=#perplexity-and-its-role-in-t-sne title="Permanent link">&para;</a></h3> <p>Perplexity is a parameter in t-SNE that balances the attention between local and global aspects of your data. It is related to the number of nearest neighbors considered when computing the pairwise similarities in the high-dimensional space.</p> <h4 id=detailed-explanation>Detailed Explanation:<a class=headerlink href=#detailed-explanation title="Permanent link">&para;</a></h4> <ol> <li><strong>Probabilistic Interpretation</strong>:</li> <li>In t-SNE, each data point <span class=arithmatex>\( i \)</span> has a probability distribution over all other points <span class=arithmatex>\( j \)</span>, indicating how likely it is that <span class=arithmatex>\( j \)</span> is a neighbor of <span class=arithmatex>\( i \)</span>.</li> <li> <p>Perplexity is a measure of how concentrated this distribution is, which directly impacts how many neighbors influence the positioning of each point in the embedded space.</p> </li> <li> <p><strong>Mathematical Definition</strong>:</p> </li> <li>Perplexity <span class=arithmatex>\( P \)</span> is defined as <span class=arithmatex>\( 2^{H(P_i)} \)</span>, where <span class=arithmatex>\( H(P_i) \)</span> is the Shannon entropy of the probability distribution <span class=arithmatex>\( P_i \)</span> over other points.</li> <li>Shannon entropy <span class=arithmatex>\( H(P_i) = - \sum_{j} P_{ij} \log P_{ij} \)</span>.</li> <li> <p>In simpler terms, perplexity can be thought of as a smooth measure of the effective number of neighbors for each point.</p> </li> <li> <p><strong>Effect on Embedding</strong>:</p> </li> <li><strong>Low Perplexity (e.g., 5)</strong>:<ul> <li>The algorithm focuses more on local structure.</li> <li>Each point considers fewer neighbors.</li> <li>Useful for small datasets or when you want to capture fine-grained local relationships.</li> </ul> </li> <li><strong>High Perplexity (e.g., 30-50)</strong>:<ul> <li>The algorithm takes into account a broader neighborhood.</li> <li>Each point considers more neighbors.</li> <li>Suitable for larger datasets or when you want to preserve more global structure.</li> </ul> </li> </ol> <h4 id=practical-implications>Practical Implications:<a class=headerlink href=#practical-implications title="Permanent link">&para;</a></h4> <ul> <li><strong>Smaller Datasets</strong>:</li> <li>Fewer data points mean each point has fewer potential neighbors. A lower perplexity (e.g., 5) ensures that t-SNE captures the local structure well without being too influenced by distant points.</li> <li><strong>Larger Datasets</strong>:</li> <li>More data points mean more potential neighbors. A higher perplexity (e.g., 30-50) helps in capturing the global structure by considering a wider neighborhood around each point, preventing the embedding from being too noisy.</li> </ul> <h3 id=choosing-the-right-perplexity>Choosing the Right Perplexity:<a class=headerlink href=#choosing-the-right-perplexity title="Permanent link">&para;</a></h3> <ul> <li>There is no one-size-fits-all value for perplexity; it often requires some experimentation.</li> <li>Common practice is to try a few different values (e.g., 5, 10, 30, 50) and visually inspect the resulting embeddings to choose the best one.</li> <li>The default value in many implementations is around 30, which generally works well for medium-sized datasets.</li> </ul> <p>In summary, perplexity in t-SNE is a crucial parameter that controls the balance between local and global structure in the data. Lower perplexity values emphasize local relationships, while higher values help in capturing more global patterns.</p> <h2 id=how-to-set-perplexity-size>How to set perplexity size?<a class=headerlink href=#how-to-set-perplexity-size title="Permanent link">&para;</a></h2> <p><strong>I have small dataset of 1000 samples and I keep perplexity high (like 70) then the embedding or generated new records from t-sne algorithm will not have effective embedding of those 1000 records?</strong></p> <p>Yes, that's correct. If you have a small dataset of 1000 records and set the perplexity to a high value like 70, the t-SNE embedding might not be as effective. Here's why:</p> <h3 id=why-high-perplexity-can-be-ineffective-for-small-datasets>Why High Perplexity Can Be Ineffective for Small Datasets:<a class=headerlink href=#why-high-perplexity-can-be-ineffective-for-small-datasets title="Permanent link">&para;</a></h3> <ol> <li><strong>Overly Broad Neighborhoods</strong>:</li> <li>Perplexity of 70 implies considering a neighborhood of around 70 points for each data point.</li> <li>In a dataset with only 1000 points, each point's neighborhood would encompass a significant fraction of the entire dataset.</li> <li> <p>This dilutes the local structure, as the algorithm tries to consider too many points as neighbors, which can lead to less meaningful embeddings.</p> </li> <li> <p><strong>Reduced Sensitivity to Local Differences</strong>:</p> </li> <li>High perplexity values make t-SNE focus more on global structure.</li> <li>For small datasets, the algorithm might not adequately capture fine-grained local patterns because it averages over too many points.</li> <li> <p>This can cause points that are locally distinct to be embedded too closely together, losing important details.</p> </li> <li> <p><strong>Potential for Overlap and Clustering Issues</strong>:</p> </li> <li>With high perplexity, the embedding might become too smoothed out.</li> <li>Points that should be distinct clusters could overlap, making it harder to distinguish different groups within the data.</li> </ol> <h3 id=practical-example>Practical Example:<a class=headerlink href=#practical-example title="Permanent link">&para;</a></h3> <p>Imagine you have a dataset of 1000 customer records, each with several features. You want to visualize these customers to understand different segments (clusters) based on their behavior.</p> <ul> <li><strong>Low Perplexity (e.g., 5-10)</strong>:</li> <li>Each customer is compared with a smaller number of neighbors.</li> <li>Clusters representing different segments are more likely to be distinct.</li> <li> <p>Fine details and local variations are preserved.</p> </li> <li> <p><strong>High Perplexity (e.g., 70)</strong>:</p> </li> <li>Each customer is compared with many other customers.</li> <li>Clusters may blur together, making it hard to identify distinct segments.</li> <li>Local differences might be lost, and the visualization could be less informative.</li> </ul> <h3 id=choosing-perplexity-for-small-datasets>Choosing Perplexity for Small Datasets:<a class=headerlink href=#choosing-perplexity-for-small-datasets title="Permanent link">&para;</a></h3> <p>For a small dataset like 1000 records, it's usually better to start with a lower perplexity, such as 5, 10, or 20. This helps ensure that the local structure is captured well, and distinct clusters are identifiable. You can experiment with different values and visually inspect the results to find the most meaningful embedding.</p> <p>In summary, setting a high perplexity value for a small dataset can lead to less effective embeddings, as it can obscure local patterns and make clusters less distinct. For small datasets, lower perplexity values are generally more appropriate to capture the local structure effectively.</p> <h2 id=to-visulize-cluster-from-high-dimensional-data-i-can-use-pca-or-t-sne-which-one-make-more-sense>To visulize cluster from high dimensional data I can use PCA or t-SNE, which one make more sense?<a class=headerlink href=#to-visulize-cluster-from-high-dimensional-data-i-can-use-pca-or-t-sne-which-one-make-more-sense title="Permanent link">&para;</a></h2> <p>Both PCA (Principal Component Analysis) and t-SNE (t-distributed Stochastic Neighbor Embedding) are commonly used techniques for visualizing high-dimensional data, but they serve different purposes and have different strengths. Choosing between PCA and t-SNE depends on the specific characteristics of your data and the goals of your analysis. Here's a comparison to help you decide which one makes more sense for your situation:</p> <h3 id=principal-component-analysis-pca>Principal Component Analysis (PCA)<a class=headerlink href=#principal-component-analysis-pca title="Permanent link">&para;</a></h3> <p><strong>Advantages:</strong> 1. <strong>Linear Transformations</strong>: - PCA reduces dimensionality by finding the principal components, which are linear combinations of the original features. This means PCA is good for capturing the global structure and variance in the data. 2. <strong>Speed and Simplicity</strong>: - PCA is computationally less intensive compared to t-SNE. It can handle large datasets quickly. 3. <strong>Interpretability</strong>: - The principal components can be interpreted as the directions of maximum variance. This makes it easier to understand the relationship between the original features and the reduced dimensions. 4. <strong>Deterministic</strong>: - PCA produces the same result every time it is run on the same dataset (it is not dependent on a random seed).</p> <p><strong>Disadvantages:</strong> 1. <strong>Captures Only Linear Relationships</strong>: - PCA may not perform well if the data has complex, non-linear relationships. 2. <strong>Less Effective for Complex Structures</strong>: - For visualizing complex manifolds or clusters in high-dimensional space, PCA might not be very effective.</p> <h3 id=t-distributed-stochastic-neighbor-embedding-t-sne>t-Distributed Stochastic Neighbor Embedding (t-SNE)<a class=headerlink href=#t-distributed-stochastic-neighbor-embedding-t-sne title="Permanent link">&para;</a></h3> <p><strong>Advantages:</strong> 1. <strong>Captures Non-Linear Relationships</strong>: - t-SNE is designed to capture complex, non-linear relationships in the data. It excels at preserving the local structure of the data, making it very effective for visualizing clusters. 2. <strong>Good for Clustering</strong>: - t-SNE tends to produce clear, well-separated clusters, which is particularly useful for visualizing distinct groups within the data.</p> <p><strong>Disadvantages:</strong> 1. <strong>Computationally Intensive</strong>: - t-SNE is more computationally expensive and slower, especially for large datasets. 2. <strong>Non-Deterministic</strong>: - The results of t-SNE can vary between runs unless the random seed is fixed. 3. <strong>Interpretability</strong>: - The resulting dimensions from t-SNE are not easily interpretable in terms of the original features. 4. <strong>Parameter Sensitivity</strong>: - t-SNE has several hyperparameters (like perplexity, learning rate) that can significantly affect the results and may require tuning.</p> <h3 id=when-to-use-each>When to Use Each:<a class=headerlink href=#when-to-use-each title="Permanent link">&para;</a></h3> <p><strong>Use PCA When:</strong> - You want a quick and computationally efficient way to reduce dimensionality. - You are interested in understanding the global variance structure of your data. - Your data likely has linear relationships.</p> <p><strong>Use t-SNE When:</strong> - You are primarily interested in visualizing clusters and the local structure of the data. - Your data has complex, non-linear relationships. - You are working with smaller datasets (typically up to a few thousand points) or can afford the computational cost.</p> <h3 id=combined-approach>Combined Approach:<a class=headerlink href=#combined-approach title="Permanent link">&para;</a></h3> <p>Sometimes, a combined approach can be useful: 1. <strong>PCA for Initial Reduction</strong>: - Use PCA to reduce the dimensionality to a manageable level (e.g., from thousands of dimensions to 50 or 100). 2. <strong>t-SNE for Final Visualization</strong>: - Then apply t-SNE on the reduced dimensions for detailed visualization. This can improve the performance and effectiveness of t-SNE.</p> <h3 id=summary>Summary:<a class=headerlink href=#summary title="Permanent link">&para;</a></h3> <ul> <li><strong>PCA</strong> is generally more suitable for capturing global structures and is computationally efficient, making it a good first step for dimensionality reduction or when dealing with very large datasets.</li> <li><strong>t-SNE</strong> is more effective for visualizing clusters and capturing non-linear relationships, making it a powerful tool for detailed exploration of complex datasets, especially for visualizing clusters.</li> </ul> <p>In many practical cases, starting with PCA and then using t-SNE on the reduced data can combine the strengths of both methods for effective visualization.</p> <h2 id=how-will-i-know-my-dataset-of-1000-samples-and-80-features-is-complex-or-simple>How will I know my dataset of 1000 samples and 80 features is complex or simple?<a class=headerlink href=#how-will-i-know-my-dataset-of-1000-samples-and-80-features-is-complex-or-simple title="Permanent link">&para;</a></h2> <p>Determining whether your dataset has complex, non-linear relationships or is relatively simple and linear can be approached through a combination of exploratory data analysis and applying different techniques to see how well they perform. Here are some steps and methods you can use to assess the complexity of your dataset:</p> <h3 id=exploratory-data-analysis-eda>Exploratory Data Analysis (EDA)<a class=headerlink href=#exploratory-data-analysis-eda title="Permanent link">&para;</a></h3> <ol> <li><strong>Visualizing Pairwise Relationships</strong>:</li> <li>Use scatter plots or pair plots to visualize the relationships between pairs of variables. Libraries like Seaborn (<code>sns.pairplot()</code>) can be helpful for this.</li> <li> <p>Look for patterns that are not linear, such as curves or clusters that are not well-separated by straight lines.</p> </li> <li> <p><strong>Correlation Matrix</strong>:</p> </li> <li>Calculate the correlation matrix of your variables. Strong linear correlations (close to 1 or -1) suggest linear relationships.</li> <li> <p>Use heatmaps to visualize the correlation matrix (<code>sns.heatmap()</code> in Seaborn).</p> </li> <li> <p><strong>Non-Linear Visualization</strong>:</p> </li> <li>Apply non-linear visualization techniques like t-SNE or UMAP and see if they reveal structure or clusters that were not apparent with linear techniques like PCA.</li> </ol> <h3 id=applying-different-techniques>Applying Different Techniques<a class=headerlink href=#applying-different-techniques title="Permanent link">&para;</a></h3> <ol> <li><strong>PCA Analysis</strong>:</li> <li>Apply PCA to your data and plot the explained variance ratio for the principal components.</li> <li> <p>If a few components explain a large portion of the variance, your data might have a simpler structure. If you need many components to explain the variance, the data might be more complex.</p> </li> <li> <p><strong>Residual Analysis</strong>:</p> </li> <li>Fit a linear model (e.g., linear regression) to the data and analyze the residuals.</li> <li> <p>Large or systematic patterns in the residuals suggest non-linear relationships.</p> </li> <li> <p><strong>Model Performance</strong>:</p> </li> <li>Fit both linear and non-linear models (e.g., linear regression vs. decision trees or random forests) to your data.</li> <li>Compare their performance metrics (e.g., R^2, mean squared error) on a validation set. If non-linear models perform significantly better, it indicates non-linear relationships.</li> </ol> <h3 id=specific-methods>Specific Methods<a class=headerlink href=#specific-methods title="Permanent link">&para;</a></h3> <ol> <li><strong>Kernel PCA</strong>:</li> <li>Apply Kernel PCA, which can capture non-linear structures by using kernel functions.</li> <li> <p>Compare the results with standard PCA to see if Kernel PCA provides a significantly better embedding.</p> </li> <li> <p><strong>t-SNE</strong>:</p> </li> <li>Apply t-SNE directly to your data and examine the resulting plot.</li> <li> <p>Clear clusters or complex structures in the t-SNE plot suggest non-linear relationships.</p> </li> <li> <p><strong>UMAP (Uniform Manifold Approximation and Projection)</strong>:</p> </li> <li>Similar to t-SNE but often faster and can capture both local and global structure.</li> <li>Visualize the data using UMAP and see if it reveals more structure compared to PCA.</li> </ol> <h3 id=practical-steps-with-code-examples>Practical Steps with Code Examples<a class=headerlink href=#practical-steps-with-code-examples title="Permanent link">&para;</a></h3> <h4 id=visualizing-pairwise-relationships>Visualizing Pairwise Relationships<a class=headerlink href=#visualizing-pairwise-relationships title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=c1># Assuming df is your DataFrame with 80 variables</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=n>sns</span><span class=o>.</span><span class=n>pairplot</span><span class=p>(</span><span class=n>df</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=mi>200</span><span class=p>))</span>  <span class=c1># sample if the dataset is large for visualization</span>
</span></code></pre></div> <h4 id=correlation-matrix-and-heatmap>Correlation Matrix and Heatmap<a class=headerlink href=#correlation-matrix-and-heatmap title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>import</span><span class=w> </span><span class=nn>seaborn</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>sns</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=n>correlation_matrix</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>corr</span><span class=p>()</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>10</span><span class=p>))</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>correlation_matrix</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;coolwarm&#39;</span><span class=p>)</span>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <h4 id=pca-explained-variance>PCA Explained Variance<a class=headerlink href=#pca-explained-variance title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.decomposition</span><span class=w> </span><span class=kn>import</span> <span class=n>PCA</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=kn>import</span><span class=w> </span><span class=nn>matplotlib.pyplot</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>plt</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a><span class=n>pca</span> <span class=o>=</span> <span class=n>PCA</span><span class=p>()</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=n>pca</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=n>pca</span><span class=o>.</span><span class=n>explained_variance_ratio_</span><span class=p>))</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Number of Components&#39;</span><span class=p>)</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Explained Variance&#39;</span><span class=p>)</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <h4 id=residual-analysis>Residual Analysis<a class=headerlink href=#residual-analysis title="Permanent link">&para;</a></h4> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>LinearRegression</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>mean_squared_error</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=n>X</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>drop</span><span class=p>(</span><span class=s1>&#39;target&#39;</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># assuming &#39;target&#39; is your target variable</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=n>y</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=s1>&#39;target&#39;</span><span class=p>]</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=n>model</span> <span class=o>=</span> <span class=n>LinearRegression</span><span class=p>()</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a><span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a><span class=n>residuals</span> <span class=o>=</span> <span class=n>y</span> <span class=o>-</span> <span class=n>predictions</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a><span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>predictions</span><span class=p>,</span> <span class=n>residuals</span><span class=p>)</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predictions&#39;</span><span class=p>)</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Residuals&#39;</span><span class=p>)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></code></pre></div> <p>By following these steps, you can get a good sense of whether your dataset exhibits complex, non-linear relationships or if it is simpler and more linear. This will guide you in choosing the appropriate dimensionality reduction technique and other analysis methods.</p> <p><strong>Author</strong> <br> Dr Hari Thapliyaal <br> dasarpai.com <br> linkedin.com/in/harithapliyal </p> <div class=author-bio style="margin-top: 2rem; display: flex; gap: 1rem;"> <img src=../assets/images/myphotos/Profilephoto1.jpg alt="Hari Thapliyaal" style="border-radius: 50%; width: 80px; height: 80px;"> <div> <strong>Dr. Hari Thapliyaal</strong><br> <small>Dr. Hari Thapliyal is a prolific blogger and seasoned professional with an extensive background in Data Science, Project Management, and Advait-Vedanta Philosophy. He holds a Doctorate in AI/NLP from SSBM, Geneva, along with Masters degrees in Computers, Business Management, Data Science, and Economics. With over three decades of experience in management and leadership, Hari has extensive expertise in training, consulting, and coaching within the technology sector. His specializations include Data Science, AI, Computer Vision, NLP, and machine learning. Hari is also passionate about meditation and nature, often retreating to secluded places for reflection and peace.</small> </div> </div> <div class=share-buttons style="margin-top: 2rem;"> <strong>Share this article:</strong><br> <a href="https://twitter.com/intent/tweet?text=Dimensionality%20Reduction%20and%20Visualization&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Dimensionality-Reduction-and-Visualization.html" target=_blank>Twitter</a> | <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Dimensionality-Reduction-and-Visualization.html" target=_blank>Facebook</a> | <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Dimensionality-Reduction-and-Visualization.html" target=_blank>LinkedIn</a> </div> <div id=comments style="margin-top: 3rem;"> <script src=https://giscus.app/client.js data-repo=dasarpai/dasarpai-comments data-repo-id=R_kgDOOGVFpA data-category=General data-category-id=DIC_kwDOOGVFpM4CnzHR data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async>
        </script> </div> </article> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Dr. Hari Thapliyaal </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dasarpai target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://hub.docker.com/r/harithapliyal target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://x.com/dasarpai target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../assets/javascripts/custom.js></script> </body> </html>