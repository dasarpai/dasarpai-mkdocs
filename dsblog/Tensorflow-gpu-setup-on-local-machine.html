<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="My various blogs on Datascience, Management, Software Engineering, Philosophy, Vedanta, Sanskrit, Current Affair, History. "><meta name=author content="Hari Thapliyaal"><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Tensorflow-gpu-setup-on-local-machine.html><link rel=icon href=../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.11"><title>Tensorflow GPU Setup on Local Machine - DasarpAI</title><link rel=stylesheet href=../assets/stylesheets/main.4af4bdda.min.css><link rel=stylesheet href=../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../stylesheets/extra.css><script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","{{ config.extra.GOOGLE_ANALYTICS }}"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","{{ config.extra.GOOGLE_ANALYTICS }}",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id={{ config.extra.GOOGLE_ANALYTICS }}",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta name=author content="Hari Thapliyaal"><meta name=description content="A comprehensive guide to setting up TensorFlow with GPU support on your local machine. Learn about CUDA, Docker configuration, and essential steps for optimizing deep learning performance."><meta name=keywords content="TensorFlow GPU Setup, CUDA Installation, Deep Learning Environment, Docker Configuration, GPU Computing, NVIDIA Drivers, Development Setup, Machine Learning Tools"><meta property=og:type content=article><meta property=og:locale content=en_US><meta property=og:site_name content=DasarpAI><meta property=og:title content="Tensorflow GPU Setup on Local Machine"><meta property=og:description content="A comprehensive guide to setting up TensorFlow with GPU support on your local machine. Learn about CUDA, Docker configuration, and essential steps for optimizing deep learning performance."><meta property=og:url content=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Tensorflow-gpu-setup-on-local-machine.html><meta property=og:image content=../../assets/images/dspost/dsp6140-Tensorflow-gpu-setup-on-local-machine.jpg><meta property=og:image:width content=1200><meta property=og:image:height content=630><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=@dasarpai><meta name=twitter:title content="Tensorflow GPU Setup on Local Machine"><meta name=twitter:description content="A comprehensive guide to setting up TensorFlow with GPU support on your local machine. Learn about CUDA, Docker configuration, and essential steps for optimizing deep learning performance."><meta name=twitter:image content=../../assets/images/dspost/dsp6140-Tensorflow-gpu-setup-on-local-machine.jpg><link rel=canonical href=https://dasarpai.github.io/dasarpai-mkdocs/dsblog/Tensorflow-gpu-setup-on-local-machine.html><link rel=stylesheet href=../assets/stylesheets/custom.css></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#tensorflow-gpu-setup-on-local-machine class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <button class="md-banner__button md-icon" aria-label="Don't show this again"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> For updates follow <strong>@harithapliyal</strong> on <a rel=me href=https://linkedin.com/in/harithapliyal> <span class="twemoji mastodon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg> </span> <strong>Fosstodon</strong> </a> and <a href=https://x.com/dasarpai> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> <strong>Twitter</strong> </a> </div> <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=.. title=DasarpAI class="md-header__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DasarpAI </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Tensorflow GPU Setup on Local Machine </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media=(prefers-color-scheme) data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1M8 13h8v-2H8zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4a5 5 0 0 0 5-5 5 5 0 0 0-5-5"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_2 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to system preference" type=radio name=__palette id=__palette_2> <label class="md-header__button md-icon" title="Switch to system preference" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5M7 15a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../index.html class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=index.html class=md-tabs__link> Data Science </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/pmlogy-home.html class=md-tabs__link> Project Management </a> </li> <li class=md-tabs__item> <a href=../insiders-pages/wia-home.html class=md-tabs__link> SpiritualDrops </a> </li> <li class=md-tabs__item> <a href=../samskrutyatra/index.html class=md-tabs__link> Samskrut </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=.. title=DasarpAI class="md-nav__button md-logo" aria-label=DasarpAI data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 89 89"> <path d=M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z /> <path d=M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z style="fill-opacity: 0.5"/> <path d=M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z /> <path d=M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z style="fill-opacity: 0.25"/> </svg> </a> DasarpAI </label> <div class=md-nav__source> <a href=https://github.com/dasarpai/dasrapai-mkdocs title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> dasarpai/dasrapai-mkdocs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1> <div class="md-nav__link md-nav__container"> <a href=../index.html class="md-nav__link "> <span class=md-ellipsis> Home </span> </a> <label class="md-nav__link " for=__nav_1 id=__nav_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_1_label aria-expanded=false> <label class=md-nav__title for=__nav_1> <span class="md-nav__icon md-icon"></span> Home </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/aboutme.html class=md-nav__link> <span class=md-ellipsis> About Me </span> </a> </li> <li class=md-nav__item> <a href=../dscourses/index.html class=md-nav__link> <span class=md-ellipsis> DS/AI Courses/Services </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_1_4> <label class=md-nav__link for=__nav_1_4 id=__nav_1_4_label tabindex=0> <span class=md-ellipsis> Project/Work Catalog </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_1_4> <span class="md-nav__icon md-icon"></span> Project/Work Catalog </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/project-index-page.html class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-al-ml-projects.md class=md-nav__link> <span class=md-ellipsis> Business Domain </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-my-technology-stacks.md class=md-nav__link> <span class=md-ellipsis> Technology Stack </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/summary-of-management-projects.md class=md-nav__link> <span class=md-ellipsis> Project Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../management/index.html class=md-nav__link> <span class=md-ellipsis> PM Courses/Services </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/clients.html class=md-nav__link> <span class=md-ellipsis> Clients </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/testimonials.md class=md-nav__link> <span class=md-ellipsis> Testimonial </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/publications-home.html class=md-nav__link> <span class=md-ellipsis> Publications </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/corpus-home.html class=md-nav__link> <span class=md-ellipsis> History Corpus </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <div class="md-nav__link md-nav__container"> <a href=index.html class="md-nav__link "> <span class=md-ellipsis> Data Science </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Data Science </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../dsresources/index.html class=md-nav__link> <span class=md-ellipsis> DS Resources </span> </a> </li> <li class=md-nav__item> <a href=../news/index.html class=md-nav__link> <span class=md-ellipsis> AI and Business News </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-books.md class=md-nav__link> <span class=md-ellipsis> Data Science-Books </span> </a> </li> <li class=md-nav__item> <a href=data-science-cheatsheets.md class=md-nav__link> <span class=md-ellipsis> Data Science Cheatsheets </span> </a> </li> <li class=md-nav__item> <a href=best-youtube-channels-for-ds.md class=md-nav__link> <span class=md-ellipsis> Video Channels to Learn DS </span> </a> </li> <li class=md-nav__item> <a href=ds-ai-ml-interview-resources.md class=md-nav__link> <span class=md-ellipsis> DS Interview Questions </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <div class="md-nav__link md-nav__container"> <a href=../pmblog/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management </span> </a> <label class="md-nav__link " for=__nav_3 id=__nav_3_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Project Management </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-home.html class=md-nav__link> <span class=md-ellipsis> PMLOGY Home </span> </a> </li> <li class=md-nav__item> <a href=../pmglossary.md class=md-nav__link> <span class=md-ellipsis> PM Glossary </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmlogy-tags.md class=md-nav__link> <span class=md-ellipsis> PM Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-tags.md class=md-nav__link> <span class=md-ellipsis> PMBOK6 Topics </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/pmbok6-summary.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 </span> </a> </li> <li class=md-nav__item> <a href=../pmbok6/index.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Explorer </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_8> <label class=md-nav__link for=__nav_3_8 id=__nav_3_8_label tabindex=0> <span class=md-ellipsis> PM Resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_8_label aria-expanded=false> <label class=md-nav__title for=__nav_3_8> <span class="md-nav__icon md-icon"></span> PM Resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmi-templates.html class=md-nav__link> <span class=md-ellipsis> PMBOK6 Templates </span> </a> </li> <li class=md-nav__item> <a href=../insiders-pages/prince2-templates.html class=md-nav__link> <span class=md-ellipsis> PRINCE2 Templates </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_9> <div class="md-nav__link md-nav__container"> <a href=../pmbok6hi/index.html class="md-nav__link "> <span class=md-ellipsis> Project Management Hindi </span> </a> <label class="md-nav__link " for=__nav_3_9 id=__nav_3_9_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_9_label aria-expanded=false> <label class=md-nav__title for=__nav_3_9> <span class="md-nav__icon md-icon"></span> Project Management Hindi </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/pmbok6hi-summary.html class=md-nav__link> <span class=md-ellipsis> PMBoK6 Hindi </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <div class="md-nav__link md-nav__container"> <a href=../wiaposts/index.html class="md-nav__link "> <span class=md-ellipsis> SpiritualDrops </span> </a> <label class="md-nav__link " for=__nav_4 id=__nav_4_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> SpiritualDrops </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/wia-home.html class=md-nav__link> <span class=md-ellipsis> WIA Home </span> </a> </li> <li class=md-nav__item> <a href=../quotations/index.html class=md-nav__link> <span class=md-ellipsis> WIA Quotes </span> </a> </li> <li class=md-nav__item> <a href=../gk/index.html class=md-nav__link> <span class=md-ellipsis> GK Blog </span> </a> </li> <li class=md-nav__item> <a href=../booksummary/index.html class=md-nav__link> <span class=md-ellipsis> Book Summary </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../samskrutyatra/index.html class="md-nav__link "> <span class=md-ellipsis> Samskrut </span> </a> <label class="md-nav__link " for=__nav_5 id=__nav_5_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Samskrut </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../insiders-pages/samskrut-home.html class=md-nav__link> <span class=md-ellipsis> SamskrutYatra Home </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#introduction class=md-nav__link> <span class=md-ellipsis> Introduction </span> </a> </li> <li class=md-nav__item> <a href=#enabling-gpu-for-tensorflow class=md-nav__link> <span class=md-ellipsis> Enabling GPU for tensorflow </span> </a> <nav class=md-nav aria-label="Enabling GPU for tensorflow"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#highlevel-instructions class=md-nav__link> <span class=md-ellipsis> Highlevel instructions </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#basic-terms class=md-nav__link> <span class=md-ellipsis> Basic Terms </span> </a> </li> <li class=md-nav__item> <a href=#what-are-different-options-for-tensorflow-installation class=md-nav__link> <span class=md-ellipsis> What are different options for Tensorflow Installation? </span> </a> </li> <li class=md-nav__item> <a href=#installation-using-docker class=md-nav__link> <span class=md-ellipsis> Installation using Docker </span> </a> </li> <li class=md-nav__item> <a href=#installation-on-wsllinux class=md-nav__link> <span class=md-ellipsis> Installation on WSL/Linux </span> </a> <nav class=md-nav aria-label="Installation on WSL/Linux"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-ensure-compatible-gpu-drivers-are-installed class=md-nav__link> <span class=md-ellipsis> 1. Ensure Compatible GPU Drivers are Installed </span> </a> </li> <li class=md-nav__item> <a href=#2-install-cuda-toolkit class=md-nav__link> <span class=md-ellipsis> 2. Install CUDA Toolkit </span> </a> </li> <li class=md-nav__item> <a href=#3-install-cudnn-cuda-deep-neural-network-library class=md-nav__link> <span class=md-ellipsis> 3. Install cuDNN (CUDA Deep Neural Network Library) </span> </a> </li> <li class=md-nav__item> <a href=#4-install-gpu-compatible-python-libraries class=md-nav__link> <span class=md-ellipsis> 4. Install GPU-Compatible Python Libraries </span> </a> </li> <li class=md-nav__item> <a href=#5-verify-gpu-availability-in-your-environment class=md-nav__link> <span class=md-ellipsis> 5. Verify GPU Availability in Your Environment </span> </a> </li> <li class=md-nav__item> <a href=#6-common-troubleshooting-tips class=md-nav__link> <span class=md-ellipsis> 6. Common Troubleshooting Tips </span> </a> </li> <li class=md-nav__item> <a href=#example-setting-up-tensorflow-with-gpu class=md-nav__link> <span class=md-ellipsis> Example: Setting Up TensorFlow with GPU </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#important-commands class=md-nav__link> <span class=md-ellipsis> Important Commands </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <article class="md-content__inner md-typeset"> <p><img alt="Tensorflow GPU Setup on Local Machine" src=../assets/images/dspost/dsp6140-Tensorflow-gpu-setup-on-local-machine.jpg></p> <h1 id=tensorflow-gpu-setup-on-local-machine>Tensorflow GPU Setup on Local Machine<a class=headerlink href=#tensorflow-gpu-setup-on-local-machine title="Permanent link">&para;</a></h1> <h2 id=introduction>Introduction<a class=headerlink href=#introduction title="Permanent link">&para;</a></h2> <p>Tensorflow, pytorch are deep learning libraries or packages. Tensorflow is developed by google and pytorch is developed by Meta. There are some other but these are the most popular one among Machine Learning and Deep Learning Engineers. If you are doing anything significant in NLP, computer vision, voice processing you must have used this library. But the power of the these libraries lies in parallel metrics/tensor computation. For that they use hardwardes like GPU or TPU which has thousands of core and they designed purely for metrics/tensor processing. Intially they were used for gaming purpose but with the surge of AI these machines are in high use and used for model training and inference purpose.</p> <p>To install any python libraries we can use pip or conda commands so we can use the same for these libraries. But the problem is many of learners do not have the GPU hardware machines. So even if you install it on cpu machine processing is very slow even with powerful machines. That is where google colab and kaggle come as handy tool for use. Google colab and kaggle provides us free hardware with limited hours GPU which can use used for experimenting or model training. Because these tools are designed for deep learning model training therefore by default they have tensorflow and pytorch installed. But these machines cannot be used for serious business purpose unless you pay them good money. The solution for that is you have your own dedicated GPU machine.</p> <p>Now the actually trouble starts, you cannot install tensorflow or pytorch on the gpu machine as you were doing non-gpu machine. You need to make sure gpu hardware is available and being used within the development environemnt. But how do you do that? This article is about that!</p> <h2 id=enabling-gpu-for-tensorflow>Enabling GPU for tensorflow<a class=headerlink href=#enabling-gpu-for-tensorflow title="Permanent link">&para;</a></h2> <p>Question: When I am using packages like tensorflow or pytorch on my local GPU machine then how to install it so that it is available for the development or deployment environment?</p> <h3 id=highlevel-instructions>Highlevel instructions<a class=headerlink href=#highlevel-instructions title="Permanent link">&para;</a></h3> <p>When installing packages that support GPU, ensuring that the GPU is available and utilized in the development environment during model training involves several key steps. These steps ensure that your setup can take full advantage of the GPU for faster computations, especially in deep learning and machine learning tasks</p> <ul> <li>First you can decide which version of tensorflow or pytorch you want to use.</li> <li>You need to use gpu compatable version of these libraries NOT the cpu version of the library.</li> <li>Then check compatibility of tensorflow. <a href=https://www.tensorflow.org/guide/versions>https://www.tensorflow.org/guide/versions</a></li> <li>Install GPU drivers, CUDA, cuDNN, and the deep learning library (tensorflow, pytorch etc) are compatible. Mismatched versions can lead to errors or inefficient GPU usage. It is time consuming and frustrating if you are just playing with random versions, therefore to avoid this pain do your research and make decision.</li> <li>Use nvidia-smi to check whether GPU is being used or not.</li> <li>Launch jupyter notebook and write small code to check whether gpu is available within the jupyter environment or not.</li> </ul> <h2 id=basic-terms>Basic Terms<a class=headerlink href=#basic-terms title="Permanent link">&para;</a></h2> <p><strong>What is GPU?</strong> <br> The term "GPU" traditionally stands for "Graphics Processing Unit," primarily used for rendering graphics. However, modern GPUs, especially those from NVIDIA, have evolved to handle more than just graphics—they can perform general-purpose computing tasks as well, which is referred to as GPGPU (General-Purpose computing on Graphics Processing Units). With the help of GPGPU, CUDA extends the capabilities of GPUs beyond graphics. It allows developers to write programs that can run on the GPU, making use of its parallel processing power for tasks such as scientific calculations, machine learning, and deep learning.</p> <p><strong>What is the difference between Library and API?</strong> <br> A library is a collection of pre-written code that provides specific functionalities you can directly use in your programs, like functions or classes. An API (Application Programming Interface) is a set of rules and protocols that defines how software components should interact, specifying how to use the functions and classes in a library without providing the actual implementation. Pandas, Numpy are library. In the context of NVIDIA cuBLAS (CUDA Basic Linear Algebra Subroutines) or cuDNN (CUDA Deep Neural Network) are libraries.</p> <p><strong>What is NVIDIA Driver</strong>? <br> It acts as a bridge between the operating system and the NVIDIA GPU hardware. It allows the OS and applications to utilize the GPU for computing and rendering tasks. Both CUDA and cuDNN require the NVIDIA driver to function, as it provides the basic communication and control capabilities with the GPU.</p> <p><strong>What is CUDA (Compute Unified Device Architecture)</strong> <br> A parallel computing platform and programming model developed by NVIDIA. It enables developers to use NVIDIA GPUs for general-purpose processing (GPGPU), which significantly accelerates tasks like deep learning. It requires the NVIDIA driver. CUDA provides the necessary tools and libraries for interacting with the GPU and forms the foundation for libraries like cuDNN.</p> <p><strong>What is cuDNN (CUDA Deep Neural Network Library)</strong>? <br> A GPU-accelerated library for deep learning, optimized for running operations common in neural networks, such as convolutions, pooling, normalization, and activation functions. It is created by NVIDIA. It is built on top of CUDA, it requires CUDA to function. cuDNN is specifically tailored to accelerate deep learning workloads and is used by many deep learning frameworks.</p> <p><strong>What is TensorFlow</strong>? <br> An open-source deep learning framework developed by Google. It provides a comprehensive ecosystem for developing, training, and deploying machine learning models, including neural networks. There is another popular deep learning framework PyTorch, it is developed by Meta. TensorFlow can use cuDNN and CUDA for GPU acceleration, which allows TensorFlow to run computations on the GPU for faster processing. TensorFlow relies on cuDNN for optimized deep learning operations and on CUDA for GPU capabilities.</p> <p><strong>What is the relationship between NVIDIA Driver, CUDA, cuDNN, TensorFlow?</strong> <br> - <strong>NVIDIA Driver</strong> is the base layer, enabling communication with the GPU. - <strong>CUDA</strong> leverages the NVIDIA Driver to provide a platform for GPU-accelerated computing. - <strong>cuDNN</strong> is built on top of CUDA to optimize deep learning tasks. - <strong>TensorFlow</strong> uses both cuDNN and CUDA to perform efficient and accelerated deep learning operations on NVIDIA GPUs.</p> <h2 id=what-are-different-options-for-tensorflow-installation>What are different options for Tensorflow Installation?<a class=headerlink href=#what-are-different-options-for-tensorflow-installation title="Permanent link">&para;</a></h2> <ol> <li>Docker : There are dozens of images on dockerhub. Based on your need you can select a docker image from <a href=https://hub.docker.com/r/tensorflow/tensorflow/tags>the Link</a>.</li> <li>Docker in windows. You can install and run the docker in Windows OS.</li> <li>Docker in wsl/linux. You can install and run the docker in WSL/Linux.</li> <li>pip : Another way to use tensorflow is install the binary (compiled program or wheel) of tensorflow on your machine. For this purpose you need to create your own virtual environment first, then activate that environment and then do the pip installation. Which tensorlfow version you want to install you need to decide that first.</li> <li>Windows: This virtual env setting and pip installation can be done on windows os.</li> <li>WSL/ Linux: You can also create virtual env in WSL/linux and do pip instllation in that environment.</li> <li>Source : For this you can clone the tensorflow repository and build the wheel on your local machine and then install. For build you need other program on your machine which can compile the source code. Refer <a href=https://www.tensorflow.org/install/source>Link</a>. You need to install Bazel, Bazelisk is an easy way to install Bazel and automatically downloads the correct Bazel version for TensorFlow. Then Install Clang. Clang is a C/C++/Objective-C compiler that is compiled in C++ based on LLVM. If LLVM is not installed you need to install that as well. Some of these installation are just download, unzip, copy, paste and sometime you may need to install them properly.</li> <li>Windows</li> <li>WSL/Linux</li> </ol> <h2 id=installation-using-docker>Installation using Docker<a class=headerlink href=#installation-using-docker title="Permanent link">&para;</a></h2> <ol> <li>Install docker desktop.</li> <li>Install GPU support</li> <li>Install NVIDIA Container Toolket. <a href=https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html>https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html</a></li> <li>Configure docker engine</li> <li>Configure containerd (for kubernetes)<ol> <li>Configure container runtime</li> <li>Configuring podman</li> </ol> </li> <li>Run docker</li> <li>sudo systemctl restart docker</li> <li>Pull image from dockerhug Let's assume you select tensorflow:latest-gpu-jupyter you can pull that image from dockerhub into your docker image, using following command. <div class="language-text highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a>docker pull tensorflow/tensorflow:latest-gpu-jupyter
</span></code></pre></div></li> <li>Run image in a container</li> </ol> <h2 id=installation-on-wsllinux>Installation on WSL/Linux<a class=headerlink href=#installation-on-wsllinux title="Permanent link">&para;</a></h2> <p>When installing packages that support GPU, ensuring that the GPU is available and utilized in the development environment during model training involves several key steps. These steps ensure that your setup can take full advantage of the GPU for faster computations, especially in deep learning and machine learning tasks. Here’s what you need to consider:</p> <h3 id=1-ensure-compatible-gpu-drivers-are-installed>1. <strong>Ensure Compatible GPU Drivers are Installed</strong><a class=headerlink href=#1-ensure-compatible-gpu-drivers-are-installed title="Permanent link">&para;</a></h3> <p>Before using GPU-enabled packages, make sure that the appropriate GPU drivers are installed. For NVIDIA GPUs, you need the NVIDIA driver that matches your GPU hardware.</p> <ul> <li><strong>Check Your GPU</strong>: Identify your GPU using: <div class="language-bash highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>nvidia-smi
</span></code></pre></div> This command should list the GPU details if the drivers are correctly installed.</li> </ul> <p>Example output </p> <div class="language-text highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a>hari@Hari-MSI:/mnt/c/Users/hari_$ nvidia-smi
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>Tue Aug 27 17:21:37 2024
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>+-----------------------------------------------------------------------------------------+
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>| NVIDIA-SMI 560.35.03              Driver Version: 560.81         CUDA Version: 12.6     |
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a>|-----------------------------------------+------------------------+----------------------+
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>|                                         |                        |               MIG M. |
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a>|=========================================+========================+======================|
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>|   0  NVIDIA GeForce RTX 4070 ...    On  |   00000000:01:00.0 Off |                  N/A |
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>| N/A   53C    P8              2W /   80W |    7926MiB /   8188MiB |      0%      Default |
</span><span id=__span-2-13><a id=__codelineno-2-13 name=__codelineno-2-13 href=#__codelineno-2-13></a>|                                         |                        |                  N/A |
</span><span id=__span-2-14><a id=__codelineno-2-14 name=__codelineno-2-14 href=#__codelineno-2-14></a>+-----------------------------------------+------------------------+----------------------+
</span><span id=__span-2-15><a id=__codelineno-2-15 name=__codelineno-2-15 href=#__codelineno-2-15></a>
</span><span id=__span-2-16><a id=__codelineno-2-16 name=__codelineno-2-16 href=#__codelineno-2-16></a>+-----------------------------------------------------------------------------------------+
</span><span id=__span-2-17><a id=__codelineno-2-17 name=__codelineno-2-17 href=#__codelineno-2-17></a>| Processes:                                                                              |
</span><span id=__span-2-18><a id=__codelineno-2-18 name=__codelineno-2-18 href=#__codelineno-2-18></a>|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
</span><span id=__span-2-19><a id=__codelineno-2-19 name=__codelineno-2-19 href=#__codelineno-2-19></a>|        ID   ID                                                               Usage      |
</span><span id=__span-2-20><a id=__codelineno-2-20 name=__codelineno-2-20 href=#__codelineno-2-20></a>|=========================================================================================|
</span><span id=__span-2-21><a id=__codelineno-2-21 name=__codelineno-2-21 href=#__codelineno-2-21></a>|    0   N/A  N/A        75      C   /python3.11                                 N/A      |
</span><span id=__span-2-22><a id=__codelineno-2-22 name=__codelineno-2-22 href=#__codelineno-2-22></a>|    0   N/A  N/A       315      C   /python3.11                                 N/A      |
</span><span id=__span-2-23><a id=__codelineno-2-23 name=__codelineno-2-23 href=#__codelineno-2-23></a>+-----------------------------------------------------------------------------------------+
</span></code></pre></div> <ul> <li><strong>Install the Latest Drivers</strong>: Download and install the latest NVIDIA drivers from the <a href=https://www.nvidia.com/Download/index.aspx>NVIDIA website</a>. Make sure to select the correct driver version for your GPU model.</li> </ul> <p><strong>This will ask you type of NVIDIA GPU (GeForce, Titan, GRID, Networking, NVIDIA RTX/Quadro, NVS, ION etc). It also you Notebooks series (RTX20, RTX30, RTX40, MX500 etc), laptop GPU (RTX 4050, RTX4060, RTX 4070 etc), OS (Windows 11, linux 64bit, FreeBDS x64 etc). After it will show available GeForce Game Ready Driver and NVIDIA Studio Driver page. You can select and download NVIDIA graphics driver.</strong></p> <h3 id=2-install-cuda-toolkit>2. <strong>Install CUDA Toolkit</strong><a class=headerlink href=#2-install-cuda-toolkit title="Permanent link">&para;</a></h3> <p>CUDA (Compute Unified Device Architecture) is a parallel computing platform and API model created by NVIDIA. Many deep learning libraries use CUDA to access GPU capabilities.</p> <ul> <li><strong>Download CUDA</strong>: Install the CUDA toolkit that matches your NVIDIA driver version. This can be done from the <a href=https://developer.nvidia.com/cuda-toolkit-archive>CUDA Toolkit Archive</a>.</li> <li><strong>Set Environment Variables</strong>: Ensure that CUDA paths are set in your environment variables. For example, on Linux:</li> </ul> <div class="language-bash highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=nb>export</span><span class=w> </span><span class=nv>PATH</span><span class=o>=</span>/usr/local/cuda-11.2/bin<span class=si>${</span><span class=nv>PATH</span><span class=p>:+:</span><span class=si>${</span><span class=nv>PATH</span><span class=si>}}</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=nb>export</span><span class=w> </span><span class=nv>LD_LIBRARY_PATH</span><span class=o>=</span>/usr/local/cuda-11.2/lib64<span class=se>\</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a><span class=w>                        </span><span class=si>${</span><span class=nv>LD_LIBRARY_PATH</span><span class=p>:+:</span><span class=si>${</span><span class=nv>LD_LIBRARY_PATH</span><span class=si>}}</span>
</span></code></pre></div> <h3 id=3-install-cudnn-cuda-deep-neural-network-library>3. <strong>Install cuDNN (CUDA Deep Neural Network Library)</strong><a class=headerlink href=#3-install-cudnn-cuda-deep-neural-network-library title="Permanent link">&para;</a></h3> <p>cuDNN is a GPU-accelerated library for deep neural networks, providing highly tuned implementations for standard routines such as forward and backward convolution, pooling, normalization, and activation layers.</p> <ul> <li> <p><strong>Download cuDNN</strong>: You can download it from the <a href=https://developer.nvidia.com/cudnn>NVIDIA cuDNN page</a>.</p> </li> <li> <p><strong>Install cuDNN</strong>: Follow the installation instructions for your operating system. This usually involves copying certain files to the CUDA toolkit directories.</p> </li> </ul> <h3 id=4-install-gpu-compatible-python-libraries>4. <strong>Install GPU-Compatible Python Libraries</strong><a class=headerlink href=#4-install-gpu-compatible-python-libraries title="Permanent link">&para;</a></h3> <p>When using deep learning frameworks like TensorFlow, PyTorch, or others, you need to install the GPU-compatible versions of these libraries. Here's how to do this for some common libraries:</p> <ul> <li><strong>TensorFlow</strong>: Install the GPU version of TensorFlow using:</li> </ul> <div class="language-bash highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a>pip<span class=w> </span>install<span class=w> </span>tensorflow-gpu
</span></code></pre></div> <ul> <li><strong>PyTorch</strong>: Visit the <a href=https://pytorch.org/get-started/locally/ >PyTorch website</a> and select your preferences (OS, package manager, Python version, CUDA version). For example:</li> </ul> <div class="language-bash highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a>pip<span class=w> </span>install<span class=w> </span>torch<span class=w> </span>torchvision<span class=w> </span>torchaudio<span class=w> </span>--index-url<span class=w> </span>https://download.pytorch.org/whl/cu117
</span></code></pre></div> <p>This command installs PyTorch with CUDA 11.7 support.</p> <h3 id=5-verify-gpu-availability-in-your-environment>5. <strong>Verify GPU Availability in Your Environment</strong><a class=headerlink href=#5-verify-gpu-availability-in-your-environment title="Permanent link">&para;</a></h3> <p>Once all installations are complete, it’s crucial to verify that the GPU is detected and utilized by your deep learning framework:</p> <ul> <li><strong>TensorFlow</strong>: Check if TensorFlow can access the GPU with:</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>import</span><span class=w> </span><span class=nn>tensorflow</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>tf</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Num GPUs Available: &quot;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>list_physical_devices</span><span class=p>(</span><span class=s1>&#39;GPU&#39;</span><span class=p>)))</span>
</span></code></pre></div> <ul> <li><strong>PyTorch</strong>: Verify GPU availability in PyTorch:</li> </ul> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Is CUDA available?&quot;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>())</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;CUDA Device Name:&quot;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></code></pre></div> <h3 id=6-common-troubleshooting-tips>6. <strong>Common Troubleshooting Tips</strong><a class=headerlink href=#6-common-troubleshooting-tips title="Permanent link">&para;</a></h3> <ul> <li> <p><strong>Version Compatibility</strong>: Ensure the versions of your GPU drivers, CUDA, cuDNN, and the deep learning library are compatible. Mismatched versions can lead to errors or inefficient GPU usage.</p> </li> <li> <p><strong>Environment Variables</strong>: Double-check that CUDA and cuDNN environment variables are correctly set and point to the appropriate directories.</p> </li> <li> <p><strong>Check Dependencies</strong>: Use <code>nvidia-smi</code> to monitor GPU usage and ensure that your application is utilizing the GPU during model training.</p> </li> </ul> <h3 id=example-setting-up-tensorflow-with-gpu>Example: Setting Up TensorFlow with GPU<a class=headerlink href=#example-setting-up-tensorflow-with-gpu title="Permanent link">&para;</a></h3> <p>Here’s a step-by-step example for setting up TensorFlow with GPU:</p> <ol> <li><strong>Install NVIDIA Driver</strong>:</li> <li> <p>Download and install the latest driver from the NVIDIA website suitable for your GPU model.</p> </li> <li> <p><strong>Install CUDA Toolkit</strong>:</p> </li> <li> <p>Download CUDA 11.2 (if using TensorFlow 2.6) and follow the installation instructions.</p> </li> <li> <p><strong>Install cuDNN</strong>:</p> </li> <li> <p>Download cuDNN for CUDA 11.2, extract the files, and copy them to the CUDA directories (e.g., <code>/usr/local/cuda-11.2/lib64</code>).</p> </li> <li> <p><strong>Install TensorFlow-GPU</strong>:</p> </li> <li> <p>Install TensorFlow with GPU support using <code>pip</code>: <div class="language-bash highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a>pip<span class=w> </span>install<span class=w> </span>tensorflow-gpu<span class=o>==</span><span class=m>2</span>.6.0
</span></code></pre></div></p> </li> <li> <p><strong>Verify Setup</strong>:</p> </li> <li>Run a simple TensorFlow script to check if the GPU is recognized: <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>import</span><span class=w> </span><span class=nn>tensorflow</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>tf</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Num GPUs Available: &quot;</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>list_physical_devices</span><span class=p>(</span><span class=s1>&#39;GPU&#39;</span><span class=p>)))</span>
</span></code></pre></div></li> </ol> <p>By following these steps, you can ensure that your development environment is correctly set up to leverage the GPU for model training, thereby speeding up computations and improving performance.</p> <h2 id=important-commands>Important Commands<a class=headerlink href=#important-commands title="Permanent link">&para;</a></h2> <h1 id=how-to-know-which-ubunto-version-on-my-wsl>How to know which ubunto version on my wsl?<a class=headerlink href=#how-to-know-which-ubunto-version-on-my-wsl title="Permanent link">&para;</a></h1> <div class="language-text highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a>hari@Hari-MSI:/mnt/c/Users/hari_$ lsb_release -a
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>Output
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    No LSB modules are available.
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>    Distributor ID: Ubuntu
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    Description:    Ubuntu 22.04.3 LTS
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    Release:        22.04
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>    Codename:       jammy
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>hari@Hari-MSI:/mnt/c/Users/hari_$ cat /etc/os-release
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>output
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>    PRETTY_NAME=&quot;Ubuntu 22.04.3 LTS&quot;
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>    NAME=&quot;Ubuntu&quot;
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>    VERSION_ID=&quot;22.04&quot;
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>    VERSION=&quot;22.04.3 LTS (Jammy Jellyfish)&quot;
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>    VERSION_CODENAME=jammy
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>    ID=ubuntu
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>    ID_LIKE=debian
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>    HOME_URL=&quot;https://www.ubuntu.com/&quot;
</span><span id=__span-10-21><a id=__codelineno-10-21 name=__codelineno-10-21 href=#__codelineno-10-21></a>    SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;
</span><span id=__span-10-22><a id=__codelineno-10-22 name=__codelineno-10-22 href=#__codelineno-10-22></a>    BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;
</span><span id=__span-10-23><a id=__codelineno-10-23 name=__codelineno-10-23 href=#__codelineno-10-23></a>    PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;
</span><span id=__span-10-24><a id=__codelineno-10-24 name=__codelineno-10-24 href=#__codelineno-10-24></a>    UBUNTU_CODENAME=jammy
</span></code></pre></div> <h2 id=how-to-install-cuda-118-and-cudnn-81-for-tensorflow-2170-gpu>How to install CUDA 11.8 and cuDNN 8.1 for tensorflow-2.17.0-gpu?<a class=headerlink href=#how-to-install-cuda-118-and-cudnn-81-for-tensorflow-2170-gpu title="Permanent link">&para;</a></h2> <h3 id=1-use-a-compatible-tensorflow-docker-image>1. Use a Compatible TensorFlow Docker Image<a class=headerlink href=#1-use-a-compatible-tensorflow-docker-image title="Permanent link">&para;</a></h3> <p>To ensure compatibility, it's easiest to start with a TensorFlow Docker image that already includes the correct versions of CUDA and cuDNN. TensorFlow provides pre-built Docker images with specific versions of CUDA and cuDNN.</p> <ul> <li><strong>Pull the TensorFlow Docker Image</strong>: Use a TensorFlow Docker image that is known to support CUDA 11.8 and cuDNN 8.1. The <code>tensorflow/tensorflow:2.17.0-gpu</code> tag typically comes with a compatible version of CUDA, but to specifically get CUDA 11.8, you might need to specify a tag like <code>tensorflow/tensorflow:2.17.0-gpu-cuda11.8</code>.</li> </ul> <div class="language-bash highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a>docker<span class=w> </span>pull<span class=w> </span>tensorflow/tensorflow:2.17.0-gpu-cuda11.8
</span></code></pre></div> <h3 id=2-verify-cuda-and-cudnn-versions-inside-the-container>2. Verify CUDA and cuDNN Versions Inside the Container<a class=headerlink href=#2-verify-cuda-and-cudnn-versions-inside-the-container title="Permanent link">&para;</a></h3> <p>After pulling the Docker image, run the container and verify the CUDA and cuDNN versions:</p> <ul> <li><strong>Run the Docker Container</strong>:</li> </ul> <div class="language-bash highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a>docker<span class=w> </span>run<span class=w> </span>--gpus<span class=w> </span>all<span class=w> </span>-it<span class=w> </span>--rm<span class=w> </span>-p<span class=w> </span><span class=m>9999</span>:8888<span class=w> </span>tensorflow/tensorflow:2.17.0-gpu-cuda11.8<span class=w> </span>bash
</span></code></pre></div> <div class="language-text highlight"><pre><span></span><code>This command starts an interactive bash session inside the container.
</code></pre></div> <ul> <li><strong>Check CUDA Version</strong>:</li> </ul> <p>Inside the container, check the CUDA version:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a>nvcc<span class=w> </span>--version
</span></code></pre></div> <p>This should show CUDA 11.8.</p> <p>hari@Hari-MSI:/mnt/c/Users/hari_$ nvcc --version</p> <p>nvcc: NVIDIA (R) Cuda compiler driver <br> Copyright &copy; 2005-2022 NVIDIA Corporation <br> Built on Wed_Sep_21_10:33:58_PDT_2022 <br> Cuda compilation tools, release 11.8, V11.8.89 <br> Build cuda_11.8.r11.8/compiler.31833905_0 </p> <p>This was the default cuda with my docker. <br> nvcc: NVIDIA (R) Cuda compiler driver <br> Copyright &copy; 2005-2023 NVIDIA Corporation <br> Built on Wed_Nov_22_10:17:15_PST_2023 <br> Cuda compilation tools, release 12.3, V12.3.107 <br> Build cuda_12.3.r12.3/compiler.33567101_0 </p> <ul> <li> <p><strong>Check cuDNN Version</strong>:</p> <p>To check the installed cuDNN version, you can use the following commands inside the container:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a>cat<span class=w> </span>/usr/local/cuda/include/cudnn_version.h<span class=w> </span><span class=p>|</span><span class=w> </span>grep<span class=w> </span>CUDNN_MAJOR<span class=w> </span>-A<span class=w> </span><span class=m>2</span>
</span></code></pre></div> <p>This should confirm cuDNN 8.1.</p> </li> </ul> <h3 id=3-manually-install-cudnn-81-if-needed>3. Manually Install cuDNN 8.1 (if needed)<a class=headerlink href=#3-manually-install-cudnn-81-if-needed title="Permanent link">&para;</a></h3> <p>If you find that the cuDNN version isn't 8.1 (though it should be with the right Docker image), you can manually install it:</p> <ol> <li><strong>Download cuDNN 8.1</strong>: Go to the <a href=https://developer.nvidia.com/cudnn>NVIDIA cuDNN download page</a> and download the cuDNN version 8.1 for CUDA 11.8.</li> </ol> <div class="language-text highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a># following the above link to download cuDNN I got this link commands below.
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a>https://developer.nvidia.com/cudnn-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=20.04&amp;target_type=deb_local
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>    wget https://developer.download.nvidia.com/compute/cudnn/9.3.0/local_installers/cudnn-local-repo-ubuntu2004-9.3.0_1.0-1_amd64.deb
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>    sudo dpkg -i cudnn-local-repo-ubuntu2004-9.3.0_1.0-1_amd64.deb
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>    sudo cp /var/cudnn-local-repo-ubuntu2004-9.3.0/cudnn-*-keyring.gpg /usr/share/keyrings/
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a>    sudo apt-get update
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>    sudo apt-get -y install cudnn
</span></code></pre></div> <ol> <li><strong>Transfer the cuDNN File into the Docker Container</strong>:</li> </ol> <div class="language-bash highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a>docker<span class=w> </span>cp<span class=w> </span>/path/to/cudnn-linux-x86_64-8.1.x.x-cuda11.8-archive.tar.xz<span class=w> </span>&lt;container_id&gt;:/root/
</span></code></pre></div> <ol> <li><strong>Install cuDNN Inside the Docker Container</strong>:</li> </ol> <div class="language-bash highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>tar<span class=w> </span>-xzvf<span class=w> </span>cudnn-linux-x86_64-8.1.x.x-cuda11.8-archive.tar.xz
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>cp<span class=w> </span>cudnn-linux-x86_64-8.1.x.x-cuda11.8-archive/include/*<span class=w> </span>/usr/local/cuda/include/
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>cp<span class=w> </span>cudnn-linux-x86_64-8.1.x.x-cuda11.8-archive/lib/*<span class=w> </span>/usr/local/cuda/lib64/
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>ldconfig
</span></code></pre></div> <h3 id=4-run-jupyter-notebook>4. Run Jupyter Notebook<a class=headerlink href=#4-run-jupyter-notebook title="Permanent link">&para;</a></h3> <p>Finally, start Jupyter Notebook in the container:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a>jupyter<span class=w> </span>notebook<span class=w> </span>--ip<span class=o>=</span><span class=m>0</span>.0.0.0<span class=w> </span>--allow-root
</span></code></pre></div> <p>You should be able to access Jupyter at <code>http://localhost:9999</code>.</p> <h3 id=summary>Summary<a class=headerlink href=#summary title="Permanent link">&para;</a></h3> <ul> <li>Use a TensorFlow Docker image with CUDA 11.8 support.</li> <li>Verify the CUDA and cuDNN versions inside the container.</li> <li>Manually install cuDNN 8.1 if it's not already included.</li> <li>Run Jupyter Notebook to start your development.</li> </ul> <h1 id=nvcc-version>nvcc --version<a class=headerlink href=#nvcc-version title="Permanent link">&para;</a></h1> <div class="language-text highlight"><pre><span></span><code>nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Wed_Nov_22_10:17:15_PST_2023
Cuda compilation tools, release 12.3, V12.3.107
Build cuda_12.3.r12.3/compiler.33567101_0
</code></pre></div> <p><strong>Note:</strong> Check TensorFlow's Compatibility: Visit the official TensorFlow compatibility guide to verify which CUDA and cuDNN versions are supported by TensorFlow 2.17.0. As of recent releases, TensorFlow 2.17.0 is generally compatible with:</p> <p>CUDA: 11.2, 11.3, 11.4, 11.5, 11.6, 11.7, 11.8 cuDNN: 8.1 and later versions</p> <h2 id=how-to-install-jupyter-in-docker-container>How to install Jupyter in docker container?<a class=headerlink href=#how-to-install-jupyter-in-docker-container title="Permanent link">&para;</a></h2> <h3 id=steps-to-ensure-jupyter-is-installed-and-accessible>Steps to Ensure Jupyter is Installed and Accessible:<a class=headerlink href=#steps-to-ensure-jupyter-is-installed-and-accessible title="Permanent link">&para;</a></h3> <ol> <li><strong>Start the TensorFlow Container in Interactive Mode:</strong> Run the container with a bash shell so you can install Jupyter:</li> </ol> <div class="language-bash highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>docker<span class=w> </span>run<span class=w> </span>--gpus<span class=w> </span>all<span class=w> </span>-it<span class=w> </span>--rm<span class=w> </span>-p<span class=w> </span><span class=m>9999</span>:8888<span class=w> </span>tensorflow/tensorflow:2.17.0-gpu<span class=w> </span>bash
</span></code></pre></div> <ol> <li><strong>Install Jupyter:</strong> Once inside the container, install Jupyter Notebook using <code>pip</code>:</li> </ol> <div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a>pip<span class=w> </span>install<span class=w> </span>jupyter
</span></code></pre></div> <ol> <li><strong>Verify Jupyter Installation:</strong> After installation, check if Jupyter is in the PATH by running:</li> </ol> <div class="language-bash highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>which<span class=w> </span>jupyter
</span></code></pre></div> <p>If this command returns a path (e.g., <code>/usr/local/bin/jupyter</code>), Jupyter is successfully installed.</p> <ol> <li><strong>Run Jupyter Notebook:</strong> Start the Jupyter Notebook server:</li> </ol> <div class="language-bash highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a>jupyter<span class=w> </span>notebook<span class=w> </span>--ip<span class=o>=</span><span class=m>0</span>.0.0.0<span class=w> </span>--allow-root
</span></code></pre></div> <p>If you see the Jupyter server starting and showing URLs (as before), this means it is working correctly.</p> <ol> <li><strong>Access Jupyter Notebook:</strong></li> <li>Open your browser and go to <a href=http://localhost:9999>http://localhost:9999</a>.</li> <li>Use the token provided by Jupyter to log in.</li> </ol> <h3 id=troubleshooting>Troubleshooting:<a class=headerlink href=#troubleshooting title="Permanent link">&para;</a></h3> <ul> <li> <p><strong>Container Restart:</strong> If you exit the container, any installed packages will be lost because of the <code>--rm</code> flag. For persistent changes, consider building a custom Docker image or running the container without <code>--rm</code> and then committing the changes.</p> </li> <li> <p><strong>Creating a Custom Docker Image (Optional):</strong> If you want a persistent environment, you can create a custom Docker image that includes Jupyter:</p> </li> </ul> <p>Create a <code>Dockerfile</code> with the following content:</p> <div class="language-Dockerfile highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=k>FROM</span><span class=w> </span><span class=s>tensorflow/tensorflow:2.17.0-gpu</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a><span class=k>RUN</span><span class=w> </span>pip<span class=w> </span>install<span class=w> </span>jupyter
</span></code></pre></div> <p>Build and run the Docker image:</p> <div class="language-bash highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a>docker<span class=w> </span>build<span class=w> </span>-t<span class=w> </span>my-tf-jupyter<span class=w> </span>.
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a>docker<span class=w> </span>run<span class=w> </span>--gpus<span class=w> </span>all<span class=w> </span>-it<span class=w> </span>--rm<span class=w> </span>-p<span class=w> </span><span class=m>9999</span>:8888<span class=w> </span>my-tf-jupyter<span class=w> </span>jupyter<span class=w> </span>notebook<span class=w> </span>--ip<span class=o>=</span><span class=m>0</span>.0.0.0<span class=w> </span>--allow-root
</span></code></pre></div> <p>Above command will show one url on the screen, along with port and token. You can go on browser use this information to access the jupyter notebook. </p> <p>You can access this from visual code as well. For that purpose on the kernel when IDE ask you for jupyter server you can give this url information.</p> <h2 id=test-gpu-utilization>Test GPU Utilization<a class=headerlink href=#test-gpu-utilization title="Permanent link">&para;</a></h2> <div class="language-text highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a>import tensorflow as tf
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a>print(&quot;Num GPUs Available: &quot;, len(tf.config.list_physical_devices(&#39;GPU&#39;)))
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a># Simple matrix multiplication to test GPU
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a>with tf.device(&#39;/GPU:0&#39;):
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a>    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a>    c = tf.matmul(a, b)
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a>print(c)
</span></code></pre></div> <h2 id=if-you-want-to-disable-onednn-custom-operations-for-consistency>If you want to disable oneDNN custom operations for consistency:<a class=headerlink href=#if-you-want-to-disable-onednn-custom-operations-for-consistency title="Permanent link">&para;</a></h2> <div class="language-text highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a>export TF_ENABLE_ONEDNN_OPTS=0
</span></code></pre></div> <p>You can set this in your Docker container or your host environment if you're running scripts directly</p> <h2 id=where-should-i-install-cuda-and-cudnn-libaries>Where should I install CUDA and cuDNN libaries<a class=headerlink href=#where-should-i-install-cuda-and-cudnn-libaries title="Permanent link">&para;</a></h2> <ul> <li>If you are using tensorflow from docker then </li> <li>The CUDA and cuDNN libraries must be installed inside the Docker container for TensorFlow to use them.</li> <li>If you are using tensorflow on your windows then <ul> <li>The CUDA and CuDNN libraries must be installed inside windows environment.</li> </ul> </li> <li>If you are using tensorflow on linux/wsl then <ul> <li>it must installed on liux/wsl </li> </ul> </li> </ul> <h2 id=how-to-build-new-docker-or-update-existing-docker>How to build new docker? Or update existing docker.<a class=headerlink href=#how-to-build-new-docker-or-update-existing-docker title="Permanent link">&para;</a></h2> <p>Create a folder and go into that folder <br> Create a Dockerfile. Write all the command in this. <br> go on the command prompt and execute command: docker build -t my-tf-jupyter . </p> <h2 id=what-should-be-the-content-of-dockerfile>What should be the content of Dockerfile?<a class=headerlink href=#what-should-be-the-content-of-dockerfile title="Permanent link">&para;</a></h2> <p>FROM tensorflow/tensorflow:2.17.0-gpu <br> RUN pip install jupyter</p> <p><strong>Author</strong> <br> Dr Hari Thapliyaal <br> dasarpai.com <br> linkedin.com/in/harithapliyal </p> <div class=author-bio style="margin-top: 2rem; display: flex; gap: 1rem;"> <img src=../assets/images/myphotos/Profilephoto1.jpg alt="Hari Thapliyaal" style="border-radius: 50%; width: 80px; height: 80px;"> <div> <strong>Dr. Hari Thapliyaal</strong><br> <small>Dr. Hari Thapliyal is a prolific blogger and seasoned professional with an extensive background in Data Science, Project Management, and Advait-Vedanta Philosophy. He holds a Doctorate in AI/NLP from SSBM, Geneva, along with Master’s degrees in Computers, Business Management, Data Science, and Economics. With over three decades of experience in management and leadership, Hari has extensive expertise in training, consulting, and coaching within the technology sector. His specializations include Data Science, AI, Computer Vision, NLP, and machine learning. Hari is also passionate about meditation and nature, often retreating to secluded places for reflection and peace.</small> </div> </div> <div class=share-buttons style="margin-top: 2rem;"> <strong>Share this article:</strong><br> <a href="https://twitter.com/intent/tweet?text=Tensorflow%20GPU%20Setup%20on%20Local%20Machine&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Tensorflow-gpu-setup-on-local-machine.html" target=_blank>Twitter</a> | <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Tensorflow-gpu-setup-on-local-machine.html" target=_blank>Facebook</a> | <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//dasarpai.github.io/dasarpai-mkdocs/dsblog/Tensorflow-gpu-setup-on-local-machine.html" target=_blank>LinkedIn</a> </div> <div id=comments style="margin-top: 3rem;"> <script src=https://giscus.app/client.js data-repo=dasarpai/dasarpai-comments data-repo-id=R_kgDOOGVFpA data-category=General data-category-id=DIC_kwDOOGVFpM4CnzHR data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async>
        </script> </div> </article> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2016 - 2025 Dr. Hari Thapliyaal </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://github.com/dasarpai target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=https://hub.docker.com/r/harithapliyal target=_blank rel=noopener title=hub.docker.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M349.9 236.3h-66.1v-59.4h66.1zm0-204.3h-66.1v60.7h66.1zm78.2 144.8H362v59.4h66.1zm-156.3-72.1h-66.1v60.1h66.1zm78.1 0h-66.1v60.1h66.1zm276.8 100c-14.4-9.7-47.6-13.2-73.1-8.4-3.3-24-16.7-44.9-41.1-63.7l-14-9.3-9.3 14c-18.4 27.8-23.4 73.6-3.7 103.8-8.7 4.7-25.8 11.1-48.4 10.7H2.4c-8.7 50.8 5.8 116.8 44 162.1 37.1 43.9 92.7 66.2 165.4 66.2 157.4 0 273.9-72.5 328.4-204.2 21.4.4 67.6.1 91.3-45.2 1.5-2.5 6.6-13.2 8.5-17.1zm-511.1-27.9h-66v59.4h66.1v-59.4zm78.1 0h-66.1v59.4h66.1zm78.1 0h-66.1v59.4h66.1zm-78.1-72.1h-66.1v60.1h66.1z"/></svg> </a> <a href=https://x.com/dasarpai target=_blank rel=noopener title=x.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../assets/javascripts/bundle.c8b220af.min.js></script> <script src=../assets/javascripts/custom.js></script> </body> </html>